{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unstructured library aims to simplify and streamline the preprocessing of structured and unstructured documents for downstream tasks. And what that means is no matter where your data is and no matter what format that data is in, Unstructured’s toolkit will transform and preprocess that data into an easily digestable and usable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install \"unstructured[all-docs]\" unstructured-client watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n"
     ]
    }
   ],
   "source": [
    "# Load the watermark extension\n",
    "%load_ext watermark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import JSON display for Jupyter Notebook\n",
    "from IPython.display import JSON\n",
    "\n",
    "# Import json module for working with JSON data\n",
    "import json\n",
    "\n",
    "# Import UnstructuredClient class and shared models from the unstructured_client module\n",
    "from unstructured_client import UnstructuredClient\n",
    "from unstructured_client.models import shared\n",
    "\n",
    "# Import SDKError class from the unstructured_client.models.errors module\n",
    "from unstructured_client.models.errors import SDKError\n",
    "\n",
    "# Import partition_html and partition_pdf functions for partitioning HTML and PDF documents\n",
    "from unstructured.partition.html import partition_html\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "# Import dict_to_elements and elements_to_json functions from the unstructured.staging.base module\n",
    "from unstructured.staging.base import dict_to_elements, elements_to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unstructured       : 0.13.6\n",
      "unstructured_client: 0.22.0\n",
      "json               : 2.0.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the versions of installed packages\n",
    "%watermark --iversions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package unstructured.partition in unstructured:\n",
      "\n",
      "NAME\n",
      "    unstructured.partition\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    api\n",
      "    auto\n",
      "    common\n",
      "    csv\n",
      "    doc\n",
      "    docx\n",
      "    email\n",
      "    epub\n",
      "    html\n",
      "    image\n",
      "    json\n",
      "    lang\n",
      "    md\n",
      "    model_init\n",
      "    msg\n",
      "    odt\n",
      "    org\n",
      "    pdf\n",
      "    pdf_image (package)\n",
      "    ppt\n",
      "    pptx\n",
      "    rst\n",
      "    rtf\n",
      "    strategies\n",
      "    text\n",
      "    text_type\n",
      "    tsv\n",
      "    utils (package)\n",
      "    xlsx\n",
      "    xml\n",
      "\n",
      "FILE\n",
      "    c:\\users\\divak\\anaconda3\\envs\\myenv\\lib\\site-packages\\unstructured\\partition\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the `unstructured.partition` module\n",
    "import unstructured.partition\n",
    "\n",
    "# Print the help documentation for the `unstructured.partition` module\n",
    "help(unstructured.partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the `partition_pdf` function from the `unstructured.partition.pdf` module\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "# Specify the path to your PDF file\n",
    "filename = \"data\\MINIGPT_5.pdf\"\n",
    "\n",
    "# Call the partition_pdf function\n",
    "# Returns a List[Element] present in the pages of the parsed pdf document\n",
    "elements = partition_pdf(filename)\n",
    "\n",
    "# Now, elements is a list of all elements present in the pages of the parsed pdf document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<unstructured.documents.elements.Text at 0x14d158a6790>,\n",
       " <unstructured.documents.elements.Title at 0x14d15639be0>,\n",
       " <unstructured.documents.elements.Text at 0x14d15639cd0>,\n",
       " <unstructured.documents.elements.Text at 0x14d15639d90>,\n",
       " <unstructured.documents.elements.Title at 0x14d156f85e0>,\n",
       " <unstructured.documents.elements.Text at 0x14d15639f70>,\n",
       " <unstructured.documents.elements.Title at 0x14d15639b80>,\n",
       " <unstructured.documents.elements.Title at 0x14d156f8c70>,\n",
       " <unstructured.documents.elements.Title at 0x14d1562f160>,\n",
       " <unstructured.documents.elements.Title at 0x14d1562f340>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1562f430>,\n",
       " <unstructured.documents.elements.Text at 0x14d1562f4c0>,\n",
       " <unstructured.documents.elements.Title at 0x14d1562f610>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1562f700>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1562f7f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1562f8e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1562f880>,\n",
       " <unstructured.documents.elements.Footer at 0x14d1562fa60>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d08a0b6a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158db880>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158db100>,\n",
       " <unstructured.documents.elements.ListItem at 0x14d158db580>,\n",
       " <unstructured.documents.elements.ListItem at 0x14d158db0a0>,\n",
       " <unstructured.documents.elements.ListItem at 0x14d158db9d0>,\n",
       " <unstructured.documents.elements.Title at 0x14d158dbb80>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158dbdf0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158dbee0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158dbeb0>,\n",
       " <unstructured.documents.elements.Footer at 0x14d158db670>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158dcdc0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158dc8e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d10f4d580>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158dcf40>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d10f4da30>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158dc7c0>,\n",
       " <unstructured.documents.elements.Title at 0x14d10f4d880>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158dc6d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158dc760>,\n",
       " <unstructured.documents.elements.Title at 0x14d158dc9d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158dca90>,\n",
       " <unstructured.documents.elements.Title at 0x14d158dcbe0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158dccd0>,\n",
       " <unstructured.documents.elements.Footer at 0x14d158dcb50>,\n",
       " <unstructured.documents.elements.Title at 0x14d158a67c0>,\n",
       " <unstructured.documents.elements.Title at 0x14d14de9b50>,\n",
       " <unstructured.documents.elements.Title at 0x14d15445a90>,\n",
       " <unstructured.documents.elements.Title at 0x14d158a6d60>,\n",
       " <unstructured.documents.elements.Title at 0x14d158a6ac0>,\n",
       " <unstructured.documents.elements.Title at 0x14d158a6dc0>,\n",
       " <unstructured.documents.elements.Title at 0x14d158a6b20>,\n",
       " <unstructured.documents.elements.Title at 0x14d15445dc0>,\n",
       " <unstructured.documents.elements.Title at 0x14d158a6e50>,\n",
       " <unstructured.documents.elements.Title at 0x14d15445f40>,\n",
       " <unstructured.documents.elements.Title at 0x14d15445610>,\n",
       " <unstructured.documents.elements.Title at 0x14d158a65b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15445ac0>,\n",
       " <unstructured.documents.elements.Title at 0x14d158a6af0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d154455e0>,\n",
       " <unstructured.documents.elements.Title at 0x14d0886d520>,\n",
       " <unstructured.documents.elements.Title at 0x14d158a67f0>,\n",
       " <unstructured.documents.elements.Title at 0x14d15445730>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d154450d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15445100>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15445250>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15445340>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158dc610>,\n",
       " <unstructured.documents.elements.Footer at 0x14d15445310>,\n",
       " <unstructured.documents.elements.Title at 0x14d158dc340>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158dc580>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1592edc0>,\n",
       " <unstructured.documents.elements.Title at 0x14d1592e130>,\n",
       " <unstructured.documents.elements.Text at 0x14d1592e460>,\n",
       " <unstructured.documents.elements.Title at 0x14d1512f310>,\n",
       " <unstructured.documents.elements.Text at 0x14d1592e6a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1592ebe0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158e3f70>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158e3790>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158e3340>,\n",
       " <unstructured.documents.elements.Text at 0x14d154f23d0>,\n",
       " <unstructured.documents.elements.Text at 0x14d158d8c40>,\n",
       " <unstructured.documents.elements.Text at 0x14d154f2250>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d154f2280>,\n",
       " <unstructured.documents.elements.Text at 0x14d158e32e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158d8a90>,\n",
       " <unstructured.documents.elements.Title at 0x14d156f8f40>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d156f8cd0>,\n",
       " <unstructured.documents.elements.Footer at 0x14d156f8430>,\n",
       " <unstructured.documents.elements.Text at 0x14d158e3c40>,\n",
       " <unstructured.documents.elements.Text at 0x14d158e3940>,\n",
       " <unstructured.documents.elements.Text at 0x14d154f2f40>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d150ae700>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d150aec10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d150ae3a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d150ae2e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d150ae130>,\n",
       " <unstructured.documents.elements.Text at 0x14d150aedc0>,\n",
       " <unstructured.documents.elements.Title at 0x14d089c39a0>,\n",
       " <unstructured.documents.elements.Title at 0x14d150ae0a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d089c3d90>,\n",
       " <unstructured.documents.elements.Title at 0x14d150ae910>,\n",
       " <unstructured.documents.elements.Title at 0x14d150ae7f0>,\n",
       " <unstructured.documents.elements.Text at 0x14d089c37f0>,\n",
       " <unstructured.documents.elements.Title at 0x14d089c3ac0>,\n",
       " <unstructured.documents.elements.Title at 0x14d089c33d0>,\n",
       " <unstructured.documents.elements.Text at 0x14d089c34c0>,\n",
       " <unstructured.documents.elements.Title at 0x14d089c3e20>,\n",
       " <unstructured.documents.elements.Title at 0x14d15286eb0>,\n",
       " <unstructured.documents.elements.Text at 0x14d08bef790>,\n",
       " <unstructured.documents.elements.Text at 0x14d15426100>,\n",
       " <unstructured.documents.elements.Text at 0x14d152865b0>,\n",
       " <unstructured.documents.elements.Title at 0x14d1592eb50>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1592e6d0>,\n",
       " <unstructured.documents.elements.Footer at 0x14d1592ec40>,\n",
       " <unstructured.documents.elements.Text at 0x14d150aefa0>,\n",
       " <unstructured.documents.elements.Text at 0x14d15426820>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15269f10>,\n",
       " <unstructured.documents.elements.Title at 0x14d15269d60>,\n",
       " <unstructured.documents.elements.Text at 0x14d15269f40>,\n",
       " <unstructured.documents.elements.Text at 0x14d15352100>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158c0520>,\n",
       " <unstructured.documents.elements.Text at 0x14d155e58e0>,\n",
       " <unstructured.documents.elements.Text at 0x14d152fb100>,\n",
       " <unstructured.documents.elements.Text at 0x14d152fb8b0>,\n",
       " <unstructured.documents.elements.Title at 0x14d158c0220>,\n",
       " <unstructured.documents.elements.Title at 0x14d158c0df0>,\n",
       " <unstructured.documents.elements.Title at 0x14d158c0490>,\n",
       " <unstructured.documents.elements.Text at 0x14d158c01c0>,\n",
       " <unstructured.documents.elements.Text at 0x14d158c0100>,\n",
       " <unstructured.documents.elements.Text at 0x14d05f515b0>,\n",
       " <unstructured.documents.elements.Title at 0x14d152fb7c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d05f51280>,\n",
       " <unstructured.documents.elements.ListItem at 0x14d05f51fd0>,\n",
       " <unstructured.documents.elements.ListItem at 0x14d05f51790>,\n",
       " <unstructured.documents.elements.ListItem at 0x14d05f51e20>,\n",
       " <unstructured.documents.elements.ListItem at 0x14d150ae730>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d150aeaf0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d150aeee0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d150ae550>,\n",
       " <unstructured.documents.elements.Footer at 0x14d150aeb20>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1597bee0>,\n",
       " <unstructured.documents.elements.Title at 0x14d1597bbe0>,\n",
       " <unstructured.documents.elements.Title at 0x14d1597bd00>,\n",
       " <unstructured.documents.elements.Title at 0x14d1597bdf0>,\n",
       " <unstructured.documents.elements.Title at 0x14d1597bd90>,\n",
       " <unstructured.documents.elements.Title at 0x14d158e3970>,\n",
       " <unstructured.documents.elements.Title at 0x14d1597beb0>,\n",
       " <unstructured.documents.elements.Title at 0x14d14cff190>,\n",
       " <unstructured.documents.elements.Text at 0x14d14cff280>,\n",
       " <unstructured.documents.elements.Text at 0x14d14cff4c0>,\n",
       " <unstructured.documents.elements.Text at 0x14d14cffa00>,\n",
       " <unstructured.documents.elements.Text at 0x14d14cffdc0>,\n",
       " <unstructured.documents.elements.Text at 0x14d14cff760>,\n",
       " <unstructured.documents.elements.Text at 0x14d14cff370>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d08b8f250>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d14cff7f0>,\n",
       " <unstructured.documents.elements.Title at 0x14d14cff790>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d14cff700>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d14cffa30>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d14cff730>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d14cff4f0>,\n",
       " <unstructured.documents.elements.Footer at 0x14d14cff2e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d0e6162e0>,\n",
       " <unstructured.documents.elements.Title at 0x14d0e616070>,\n",
       " <unstructured.documents.elements.Title at 0x14d0e616190>,\n",
       " <unstructured.documents.elements.Title at 0x14d1536ac40>,\n",
       " <unstructured.documents.elements.Text at 0x14d0e616040>,\n",
       " <unstructured.documents.elements.Text at 0x14d14e4ad00>,\n",
       " <unstructured.documents.elements.Text at 0x14d05e611f0>,\n",
       " <unstructured.documents.elements.Text at 0x14d089ce340>,\n",
       " <unstructured.documents.elements.Text at 0x14d05bfb640>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d05bfbbe0>,\n",
       " <unstructured.documents.elements.Title at 0x14d08a105b0>,\n",
       " <unstructured.documents.elements.Text at 0x14d08a10e80>,\n",
       " <unstructured.documents.elements.Text at 0x14d08a10610>,\n",
       " <unstructured.documents.elements.Text at 0x14d0e637a90>,\n",
       " <unstructured.documents.elements.Title at 0x14d0e637130>,\n",
       " <unstructured.documents.elements.Text at 0x14d0e637250>,\n",
       " <unstructured.documents.elements.Text at 0x14d0e637fa0>,\n",
       " <unstructured.documents.elements.Text at 0x14d0e637d00>,\n",
       " <unstructured.documents.elements.Text at 0x14d0e637b50>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d0e637190>,\n",
       " <unstructured.documents.elements.Title at 0x14d156e56d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d156e5790>,\n",
       " <unstructured.documents.elements.Title at 0x14d156e5460>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d156e52e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d156e53a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d156e50a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d156e5250>,\n",
       " <unstructured.documents.elements.Footer at 0x14d156e5100>,\n",
       " <unstructured.documents.elements.Title at 0x14d10f4e790>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d10f4e430>,\n",
       " <unstructured.documents.elements.Title at 0x14d10f4e6a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d10f4e340>,\n",
       " <unstructured.documents.elements.Title at 0x14d10f4ec40>,\n",
       " <unstructured.documents.elements.Title at 0x14d10f4ea00>,\n",
       " <unstructured.documents.elements.Title at 0x14d10f4e910>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d10f4e0d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d10f4ef70>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d10f4e250>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d0e64b550>,\n",
       " <unstructured.documents.elements.Title at 0x14d10f4e640>,\n",
       " <unstructured.documents.elements.Title at 0x14d10f4ee80>,\n",
       " <unstructured.documents.elements.Title at 0x14d14ff5850>,\n",
       " <unstructured.documents.elements.Title at 0x14d10f4ebb0>,\n",
       " <unstructured.documents.elements.Title at 0x14d158c0160>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d10f4ed00>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d10f4e520>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d10f4ecd0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d10f4ea60>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1536a490>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d154450a0>,\n",
       " <unstructured.documents.elements.Footer at 0x14d1501bfd0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15070f70>,\n",
       " <unstructured.documents.elements.Title at 0x14d15070f40>,\n",
       " <unstructured.documents.elements.Title at 0x14d15070ee0>,\n",
       " <unstructured.documents.elements.Title at 0x14d15070df0>,\n",
       " <unstructured.documents.elements.Title at 0x14d15070ca0>,\n",
       " <unstructured.documents.elements.Text at 0x14d07aee6a0>,\n",
       " <unstructured.documents.elements.Text at 0x14d15070c70>,\n",
       " <unstructured.documents.elements.Text at 0x14d1592e550>,\n",
       " <unstructured.documents.elements.ListItem at 0x14d15426eb0>,\n",
       " <unstructured.documents.elements.ListItem at 0x14d15426460>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15426f40>,\n",
       " <unstructured.documents.elements.Title at 0x14d154263a0>,\n",
       " <unstructured.documents.elements.Title at 0x14d15426be0>,\n",
       " <unstructured.documents.elements.Title at 0x14d154266d0>,\n",
       " <unstructured.documents.elements.Text at 0x14d15426f10>,\n",
       " <unstructured.documents.elements.Text at 0x14d15426c70>,\n",
       " <unstructured.documents.elements.Text at 0x14d15426fa0>,\n",
       " <unstructured.documents.elements.Text at 0x14d15426dc0>,\n",
       " <unstructured.documents.elements.Text at 0x14d154260d0>,\n",
       " <unstructured.documents.elements.Text at 0x14d15426370>,\n",
       " <unstructured.documents.elements.Text at 0x14d153827c0>,\n",
       " <unstructured.documents.elements.Text at 0x14d153829a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158e3430>,\n",
       " <unstructured.documents.elements.Title at 0x14d153823a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15382670>,\n",
       " <unstructured.documents.elements.Title at 0x14d153825b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15382c10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15382280>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158d89d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15382be0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d153828e0>,\n",
       " <unstructured.documents.elements.Footer at 0x14d15382c70>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d05f7d160>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d05f7d8e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d05f7dfa0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d05f7da00>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d150aecd0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158efdf0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158efbe0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158ef580>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158ef910>,\n",
       " <unstructured.documents.elements.Title at 0x14d158efa60>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158efaf0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158efcd0>,\n",
       " <unstructured.documents.elements.Title at 0x14d158ef850>,\n",
       " <unstructured.documents.elements.Title at 0x14d158effd0>,\n",
       " <unstructured.documents.elements.Title at 0x14d158ef160>,\n",
       " <unstructured.documents.elements.Text at 0x14d158eff40>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158ef790>,\n",
       " <unstructured.documents.elements.Text at 0x14d158ef040>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158ef700>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158ef880>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15684eb0>,\n",
       " <unstructured.documents.elements.Title at 0x14d15684f40>,\n",
       " <unstructured.documents.elements.Text at 0x14d15684070>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15684250>,\n",
       " <unstructured.documents.elements.Title at 0x14d156843d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15684430>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15684520>,\n",
       " <unstructured.documents.elements.Footer at 0x14d156845b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d14fbc4f0>,\n",
       " <unstructured.documents.elements.Title at 0x14d14fbcc70>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d14fbcaf0>,\n",
       " <unstructured.documents.elements.Text at 0x14d14fbc970>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d14fbcdc0>,\n",
       " <unstructured.documents.elements.Title at 0x14d05d61df0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d14fbcf40>,\n",
       " <unstructured.documents.elements.Title at 0x14d0d860e20>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d14f82c10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d14f7aa30>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d14f7ac10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d14f7a850>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d14f7a6d0>,\n",
       " <unstructured.documents.elements.Title at 0x14d14f7ad30>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d14de9ca0>,\n",
       " <unstructured.documents.elements.Title at 0x14d089bd130>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d089bd0a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d14e367f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d14e36970>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d0898d430>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d14e36b80>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d14ed4ac0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d14ed4d90>,\n",
       " <unstructured.documents.elements.Footer at 0x14d14ed4b80>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158f9b80>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158f96a0>,\n",
       " <unstructured.documents.elements.Title at 0x14d158e87f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158ce8b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158cea90>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d14dd0b50>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158cedf0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158cec70>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158ced00>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158ceee0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158cef70>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158cefa0>,\n",
       " <unstructured.documents.elements.Title at 0x14d1554b940>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1554bd30>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1554b4c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1554ba30>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1554bee0>,\n",
       " <unstructured.documents.elements.Footer at 0x14d1554b430>,\n",
       " <unstructured.documents.elements.Title at 0x14d0e669d30>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d0e669e20>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d0e669f40>,\n",
       " <unstructured.documents.elements.Title at 0x14d15525310>,\n",
       " <unstructured.documents.elements.Title at 0x14d15525be0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15525820>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15525730>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15525f10>,\n",
       " <unstructured.documents.elements.Title at 0x14d15525a90>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15525670>,\n",
       " <unstructured.documents.elements.Footer at 0x14d15525cd0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1567d550>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1567db80>,\n",
       " <unstructured.documents.elements.ListItem at 0x14d0e65abe0>,\n",
       " <unstructured.documents.elements.ListItem at 0x14d0e65a9d0>,\n",
       " <unstructured.documents.elements.ListItem at 0x14d0e65a580>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1567dee0>,\n",
       " <unstructured.documents.elements.Title at 0x14d1567d3d0>,\n",
       " <unstructured.documents.elements.Title at 0x14d08b63850>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d0e65ac10>,\n",
       " <unstructured.documents.elements.Title at 0x14d0e65a730>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d0e65a7c0>,\n",
       " <unstructured.documents.elements.Title at 0x14d0e65aeb0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d0e65ae20>,\n",
       " <unstructured.documents.elements.Footer at 0x14d0e65ad30>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1569eb50>,\n",
       " <unstructured.documents.elements.Title at 0x14d1569eb80>,\n",
       " <unstructured.documents.elements.Text at 0x14d1569ecd0>,\n",
       " <unstructured.documents.elements.Text at 0x14d1569edc0>,\n",
       " <unstructured.documents.elements.Text at 0x14d1569ebb0>,\n",
       " <unstructured.documents.elements.Title at 0x14d1569ee80>,\n",
       " <unstructured.documents.elements.Text at 0x14d1569ef70>,\n",
       " <unstructured.documents.elements.Text at 0x14d05da07c0>,\n",
       " <unstructured.documents.elements.Text at 0x14d05da0fd0>,\n",
       " <unstructured.documents.elements.Text at 0x14d0e4b9be0>,\n",
       " <unstructured.documents.elements.Text at 0x14d153dc220>,\n",
       " <unstructured.documents.elements.Title at 0x14d08970be0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1567db20>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d08970400>,\n",
       " <unstructured.documents.elements.Footer at 0x14d08970520>,\n",
       " <unstructured.documents.elements.Title at 0x14d15639220>,\n",
       " <unstructured.documents.elements.Title at 0x14d156393a0>,\n",
       " <unstructured.documents.elements.Title at 0x14d156395e0>,\n",
       " <unstructured.documents.elements.Title at 0x14d15639790>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d156398b0>,\n",
       " <unstructured.documents.elements.Title at 0x14d15639a00>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15639910>,\n",
       " <unstructured.documents.elements.Title at 0x14d0e4b9820>,\n",
       " <unstructured.documents.elements.Title at 0x14d0e4b97c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d0e4b9910>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d0e4b9130>,\n",
       " <unstructured.documents.elements.Footer at 0x14d0e4b9580>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d7f944220>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d152acf40>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d152ace50>,\n",
       " <unstructured.documents.elements.Footer at 0x14d152ac190>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1536a4c0>,\n",
       " <unstructured.documents.elements.Title at 0x14d156e5d00>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15297550>,\n",
       " <unstructured.documents.elements.Title at 0x14d152975b0>,\n",
       " <unstructured.documents.elements.Title at 0x14d1100b100>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1100b190>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1100b1c0>,\n",
       " <unstructured.documents.elements.Footer at 0x14d1100b1f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d153e5850>,\n",
       " <unstructured.documents.elements.Title at 0x14d153e50d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15907fd0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d153e5df0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d089c3ee0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d153e5130>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15907850>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15525850>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d153e5d00>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d153e5a00>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d05ea1c10>,\n",
       " <unstructured.documents.elements.Title at 0x14d159073a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d155259a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d153e5d60>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d153e5640>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d153e5310>,\n",
       " <unstructured.documents.elements.Text at 0x14d14e36880>,\n",
       " <unstructured.documents.elements.Footer at 0x14d14e36af0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1569e4c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1569e6d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1569e610>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1569e670>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1569e3d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1569ea00>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1569e850>,\n",
       " <unstructured.documents.elements.Text at 0x14d1569e910>,\n",
       " <unstructured.documents.elements.Footer at 0x14d1569e9a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d0e65edc0>,\n",
       " <unstructured.documents.elements.Title at 0x14d0e5ca670>,\n",
       " <unstructured.documents.elements.Title at 0x14d0e5ca5b0>,\n",
       " <unstructured.documents.elements.Title at 0x14d0e65edf0>,\n",
       " <unstructured.documents.elements.Title at 0x14d0e5ca370>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d0e5ca280>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d0e5ca4c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d0e5ca070>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d0e5ca790>,\n",
       " <unstructured.documents.elements.Title at 0x14d0e5ca8b0>,\n",
       " <unstructured.documents.elements.Text at 0x14d0e65eeb0>,\n",
       " <unstructured.documents.elements.Footer at 0x14d0e65ed60>]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "417"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"f2aea0911b6c158a5bd75b1fba564c40\",\n",
      "    \"text\": \"4 2 0 2\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            16.34,\n",
      "            207.81999999999994\n",
      "          ],\n",
      "          [\n",
      "            16.34,\n",
      "            247.81999999999994\n",
      "          ],\n",
      "          [\n",
      "            36.34,\n",
      "            247.81999999999994\n",
      "          ],\n",
      "          [\n",
      "            36.34,\n",
      "            207.81999999999994\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"71c8fbf6ab2f71ab6175c659f493093f\",\n",
      "    \"text\": \"r a\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            16.34,\n",
      "            252.82000000000005\n",
      "          ],\n",
      "          [\n",
      "            16.34,\n",
      "            268.36\n",
      "          ],\n",
      "          [\n",
      "            36.34,\n",
      "            268.36\n",
      "          ],\n",
      "          [\n",
      "            36.34,\n",
      "            252.82000000000005\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"a680916a03590cca8e93d38d425dc674\",\n",
      "    \"text\": \"M 5 1\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            16.34,\n",
      "            268.36\n",
      "          ],\n",
      "          [\n",
      "            16.34,\n",
      "            311.14\n",
      "          ],\n",
      "          [\n",
      "            36.34,\n",
      "            311.14\n",
      "          ],\n",
      "          [\n",
      "            36.34,\n",
      "            268.36\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"71c8fbf6ab2f71ab6175c659f493093f\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"00b482ff56c227e79862f00fb606b1ca\",\n",
      "    \"text\": \"]\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            16.34,\n",
      "            321.14\n",
      "          ],\n",
      "          [\n",
      "            16.34,\n",
      "            327.8\n",
      "          ],\n",
      "          [\n",
      "            36.34,\n",
      "            327.8\n",
      "          ],\n",
      "          [\n",
      "            36.34,\n",
      "            321.14\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"71c8fbf6ab2f71ab6175c659f493093f\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"81c7e38a879ec5884fbdba2d9203f143\",\n",
      "    \"text\": \"V C . s c [\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            16.34,\n",
      "            327.8\n",
      "          ],\n",
      "          [\n",
      "            16.34,\n",
      "            383.9\n",
      "          ],\n",
      "          [\n",
      "            36.34,\n",
      "            383.9\n",
      "          ],\n",
      "          [\n",
      "            36.34,\n",
      "            327.8\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"8eaef72dc9047894f486548177d3c2e1\",\n",
      "    \"text\": \"3 v 9 3 2 2 0 . 0 1 3 2 : v i X r a\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            16.34,\n",
      "            393.9\n",
      "          ],\n",
      "          [\n",
      "            16.34,\n",
      "            560.0\n",
      "          ],\n",
      "          [\n",
      "            36.34,\n",
      "            560.0\n",
      "          ],\n",
      "          [\n",
      "            36.34,\n",
      "            393.9\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"81c7e38a879ec5884fbdba2d9203f143\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"8b85b4d3309ef2b2e5b9cc564666fd18\",\n",
      "    \"text\": \"MINIGPT-5: INTERLEAVED VISION-AND-LANGUAGE GENERATION VIA GENERATIVE VOKENS\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.43,\n",
      "            80.20912640000006\n",
      "          ],\n",
      "          [\n",
      "            108.43,\n",
      "            117.34952639999995\n",
      "          ],\n",
      "          [\n",
      "            503.57744590000004,\n",
      "            117.34952639999995\n",
      "          ],\n",
      "          [\n",
      "            503.57744590000004,\n",
      "            80.20912640000006\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"98db9a5c2fe439a1805cbca3fb006b34\",\n",
      "    \"text\": \"Kaizhi Zheng\\u2217, Xuehai He\\u2217 , and Xin Eric Wang\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            208.47800000000007,\n",
      "            140.4751172\n",
      "          ],\n",
      "          [\n",
      "            208.47800000000007,\n",
      "            151.86392160000003\n",
      "          ],\n",
      "          [\n",
      "            401.28051680000004,\n",
      "            151.86392160000003\n",
      "          ],\n",
      "          [\n",
      "            401.28051680000004,\n",
      "            140.4751172\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"5634a6be47d9f1d51b74efd195c9b246\",\n",
      "    \"text\": \"University of California, Santa Cruz https://github.com/eric-ai-lab/MiniGPT-5\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            186.82200000000006,\n",
      "            162.8223216\n",
      "          ],\n",
      "          [\n",
      "            186.82200000000006,\n",
      "            183.05650219999995\n",
      "          ],\n",
      "          [\n",
      "            427.41879000000023,\n",
      "            183.05650219999995\n",
      "          ],\n",
      "          [\n",
      "            427.41879000000023,\n",
      "            162.8223216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"ff78f0fb4697a85b5f870b816686a385\",\n",
      "    \"text\": \"ABSTRACT\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            278.28800000000007,\n",
      "            216.72312320000003\n",
      "          ],\n",
      "          [\n",
      "            278.28800000000007,\n",
      "            228.67832320000002\n",
      "          ],\n",
      "          [\n",
      "            333.7221671000001,\n",
      "            228.67832320000002\n",
      "          ],\n",
      "          [\n",
      "            333.7221671000001,\n",
      "            216.72312320000003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"c9ab3d1bcdaac52044e61ef3b1fdbacd\",\n",
      "    \"text\": \"The effectiveness of Multimodal Large Language Models (MLLMs) demonstrates a profound capability in multimodal understanding. However, the simultaneous generation of images with coherent texts is still underdeveloped. Addressing this, we introduce a novel interleaved vision-and-language generation method, centered around the concept of \\u201cgenerative vokens\\u201d. These vokens serve as piv- otal elements contributing to coherent image-text outputs. Our method is marked by a unique two-stage training strategy for description-free multimodal genera- tion, which does not necessitate extensive descriptions of images. We integrate classifier-free guidance to enhance the alignment of generated images and texts, ensuring more seamless and contextually relevant multimodal interactions. Our model, MiniGPT-5, exhibits substantial improvement over the baseline models on multimodal generation datasets, including MMDialog and VIST. The human eval- uation shows MiniGPT-5 is better than the baseline model on more than 56% cases for multimodal generation, highlighting its efficacy across diverse benchmarks.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            143.8650000000001,\n",
      "            243.69132159999992\n",
      "          ],\n",
      "          [\n",
      "            143.8650000000001,\n",
      "            396.1199215999999\n",
      "          ],\n",
      "          [\n",
      "            468.1376674000002,\n",
      "            396.1199215999999\n",
      "          ],\n",
      "          [\n",
      "            468.1376674000002,\n",
      "            243.69132159999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"ff78f0fb4697a85b5f870b816686a385\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"31ea14d0c65a9f67bb7ac920f6dbc3fb\",\n",
      "    \"text\": \"1\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.29900000000009,\n",
      "            421.58312319999993\n",
      "          ],\n",
      "          [\n",
      "            108.29900000000009,\n",
      "            433.5383231999999\n",
      "          ],\n",
      "          [\n",
      "            114.27660000000009,\n",
      "            433.5383231999999\n",
      "          ],\n",
      "          [\n",
      "            114.27660000000009,\n",
      "            421.58312319999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"ff78f0fb4697a85b5f870b816686a385\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"7eeb78346f0ef5b624bcb88941ac6226\",\n",
      "    \"text\": \"INTRODUCTION\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            126.82956000000009,\n",
      "            421.58312319999993\n",
      "          ],\n",
      "          [\n",
      "            126.82956000000009,\n",
      "            433.5383231999999\n",
      "          ],\n",
      "          [\n",
      "            205.9888518000001,\n",
      "            433.5383231999999\n",
      "          ],\n",
      "          [\n",
      "            205.9888518000001,\n",
      "            421.58312319999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"98ed37adea12a78c338d75026ac0316f\",\n",
      "    \"text\": \"The development of large-scale vision-and-language models is significantly impacting a wide range of fields like automated dialogue systems and digital content creation. With the surge in research and development in this domain, the current state-of-the-art Large Language Models (LLMs) (OpenAI, 2023; Chiang et al., 2023; Ouyang et al., 2022) and vision-and-language models such as (Wu et al., 2023a; Li et al., 2023c; Tsimpoukelli et al., 2021; Alayrac et al., 2022) fall short in generating coherent multimodal outputs. This limitation becomes particularly evident in tasks that demand an integrated handling of vision and language, essential for the next generation Large Language Models (LLMs).\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0000000000001,\n",
      "            447.9283215999999\n",
      "          ],\n",
      "          [\n",
      "            108.0000000000001,\n",
      "            534.6029216\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999995,\n",
      "            534.6029216\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999995,\n",
      "            447.9283215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"OpenAI\",\n",
      "          \"url\": \"cite.openai2023gpt4\",\n",
      "          \"start_index\": 286\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.openai2023gpt4\",\n",
      "          \"start_index\": 294\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Chiangetal .,\",\n",
      "          \"url\": \"cite.vicuna2023\",\n",
      "          \"start_index\": 300\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.vicuna2023\",\n",
      "          \"start_index\": 315\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Ouyangetal .,\",\n",
      "          \"url\": \"cite.training_lm\",\n",
      "          \"start_index\": 321\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022\",\n",
      "          \"url\": \"cite.training_lm\",\n",
      "          \"start_index\": 336\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Wuetal\",\n",
      "          \"url\": \"cite.visualchatgpt\",\n",
      "          \"start_index\": 382\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023a\",\n",
      "          \"url\": \"cite.visualchatgpt\",\n",
      "          \"start_index\": 393\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Lietal .,\",\n",
      "          \"url\": \"cite.li2023blip\",\n",
      "          \"start_index\": 400\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023c\",\n",
      "          \"url\": \"cite.li2023blip\",\n",
      "          \"start_index\": 411\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Tsimpoukellietal .,\",\n",
      "          \"url\": \"cite.frozen\",\n",
      "          \"start_index\": 418\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.frozen\",\n",
      "          \"start_index\": 439\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Alayracetal .,\",\n",
      "          \"url\": \"cite.alayrac2022flamingo\",\n",
      "          \"start_index\": 445\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022\",\n",
      "          \"url\": \"cite.alayrac2022flamingo\",\n",
      "          \"start_index\": 461\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"7eeb78346f0ef5b624bcb88941ac6226\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"e08a9ea6d8efa5ae18f851013659a2b9\",\n",
      "    \"text\": \"Our work, as illustrated in Fig. 1, seeks to address these shortcomings by enhancing the integration of text and image generation in LLMs. The challenges in developing a multimodal LLM capable of interleaved vision and language generation are manifold. First, LLMs typically lack mechanisms to directly produce images, prompting us to introduce \\u201cgenerative vokens\\u201d that bridge the gap be- tween textual and visual feature spaces. Second, the constraint of data scarcity, especially in vision- and-language tasks (Sharma et al., 2018) lacking extensive detailed descriptions of images (Huang et al., 2016), is countered by our unique description-free training approach. Third, maintaining both image-text and image-image consistency poses a significant challenge, which we address through dual-loss strategies. Finally, as we push forward the boundaries with LLMs, the large memory re- quirements urge us to devise more efficient end-to-end strategies and create an efficient training pipeline accessible for the community, especially in downstream tasks.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0000000000001,\n",
      "            541.5773216\n",
      "          ],\n",
      "          [\n",
      "            108.0000000000001,\n",
      "            661.1289216\n",
      "          ],\n",
      "          [\n",
      "            504.0033874000001,\n",
      "            661.1289216\n",
      "          ],\n",
      "          [\n",
      "            504.0033874000001,\n",
      "            541.5773216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"1\",\n",
      "          \"url\": \"figure.caption.1\",\n",
      "          \"start_index\": 33\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Sharmaetal .,\",\n",
      "          \"url\": \"cite.sharma2018conceptual\",\n",
      "          \"start_index\": 513\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2018\",\n",
      "          \"url\": \"cite.sharma2018conceptual\",\n",
      "          \"start_index\": 528\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"(\",\n",
      "          \"url\": \"cite.huang2016visual\",\n",
      "          \"start_index\": 584\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"etal .,\",\n",
      "          \"url\": \"cite.huang2016visual\",\n",
      "          \"start_index\": 591\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2016\",\n",
      "          \"url\": \"cite.huang2016visual\",\n",
      "          \"start_index\": 599\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"7eeb78346f0ef5b624bcb88941ac6226\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"dde78b7eb7141c8a38f6589b2daa948e\",\n",
      "    \"text\": \"Specifically, to overcome these challenges, we present MiniGPT-5, a novel approach for interleaved vision-and-language generation. By combing the Stable Diffusion with LLMs through special vi- sual tokens (Tan & Bansal, 2020) \\u2013 \\u201cgenerative vokens\\u201d, we develop a new approach for multimodal generation. Our two-stage training methodology emphasizes a description-free foundational phase,\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0000000000001,\n",
      "            668.1023216\n",
      "          ],\n",
      "          [\n",
      "            108.0000000000001,\n",
      "            710.9419216\n",
      "          ],\n",
      "          [\n",
      "            504.0033874000002,\n",
      "            710.9419216\n",
      "          ],\n",
      "          [\n",
      "            504.0033874000002,\n",
      "            668.1023216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Tan & Bansal\",\n",
      "          \"url\": \"cite.tan2020vokenization\",\n",
      "          \"start_index\": 205\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2020\",\n",
      "          \"url\": \"cite.tan2020vokenization\",\n",
      "          \"start_index\": 219\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"7eeb78346f0ef5b624bcb88941ac6226\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"5e64a16834b19b26f2e4e0c31cc02c07\",\n",
      "    \"text\": \"\\u2217These authors contributed equally to this work.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            119.822,\n",
      "            721.2350544\n",
      "          ],\n",
      "          [\n",
      "            119.822,\n",
      "            731.7987424\n",
      "          ],\n",
      "          [\n",
      "            292.96734560000004,\n",
      "            731.7987424\n",
      "          ],\n",
      "          [\n",
      "            292.96734560000004,\n",
      "            721.2350544\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 1,\n",
      "      \"parent_id\": \"7eeb78346f0ef5b624bcb88941ac6226\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Footer\",\n",
      "    \"element_id\": \"78df9189033644bc330debf9314f1a30\",\n",
      "    \"text\": \"1\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            303.509,\n",
      "            751.9393216\n",
      "          ],\n",
      "          [\n",
      "            303.509,\n",
      "            761.9019216\n",
      "          ],\n",
      "          [\n",
      "            308.4903,\n",
      "            761.9019216\n",
      "          ],\n",
      "          [\n",
      "            308.4903,\n",
      "            751.9393216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 1,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"40b1d42ffca8d0b2eaf26c6d4f60f3ff\",\n",
      "    \"text\": \"enabling effective model training even with limited caption-grounded images. This strategy, dis- tinct from existing works, pivots on generic stages free from image annotations. To ensure that the generated text and images are in harmony, our dual-loss strategy comes into play, further enhanced by our innovative generative voken approach and classifier-free guidance. Our parameter-efficient fine-tuning strategy optimizes training efficiency and addresses memory constraints.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            84.01332159999993\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            137.81192159999978\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999995,\n",
      "            137.81192159999978\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999995,\n",
      "            84.01332159999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 2,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"23a3fdcf5d772b447f7f138778dc956a\",\n",
      "    \"text\": \"As shown in Fig. 2, leveraging ViT (Vision Transformer) and Qformer (Li et al., 2023c), alongside Large Language Models, we adapt multimodal inputs into generative vokens, seamlessly combined with the high-resolution Stable Diffusion 2.1 model (Rombach et al., 2022b) for context-aware im- Incorporating images as auxiliary input with instruction tuning approaches and age generation. pioneering both the text and image generation loss, we amplify the synergy between text and visu- als. We experiment on the CC3M (Sharma et al., 2018), VIST (Huang et al., 2016), and MMDi- alog (Feng et al., 2022) datasets. Notably, MiniGPT-5 shows superior performance across the two multimodal generation datasets.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            144.78532159999975\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            231.46092159999944\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            231.46092159999944\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            144.78532159999975\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2\",\n",
      "          \"url\": \"figure.caption.2\",\n",
      "          \"start_index\": 17\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Lietal .,\",\n",
      "          \"url\": \"cite.li2023blip\",\n",
      "          \"start_index\": 69\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023c\",\n",
      "          \"url\": \"cite.li2023blip\",\n",
      "          \"start_index\": 80\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Rombachetal .,\",\n",
      "          \"url\": \"cite.rombach2021highresolution\",\n",
      "          \"start_index\": 245\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022b\",\n",
      "          \"url\": \"cite.rombach2021highresolution\",\n",
      "          \"start_index\": 261\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Sharmaetal .,\",\n",
      "          \"url\": \"cite.sharma2018conceptual\",\n",
      "          \"start_index\": 515\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2018\",\n",
      "          \"url\": \"cite.sharma2018conceptual\",\n",
      "          \"start_index\": 530\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Huangetal .,\",\n",
      "          \"url\": \"cite.huang2016visual\",\n",
      "          \"start_index\": 543\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2016\",\n",
      "          \"url\": \"cite.huang2016visual\",\n",
      "          \"start_index\": 557\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Fengetal .,\",\n",
      "          \"url\": \"cite.feng2022mmdialog\",\n",
      "          \"start_index\": 580\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022\",\n",
      "          \"url\": \"cite.feng2022mmdialog\",\n",
      "          \"start_index\": 593\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"0f814157daafb5b1dc5ec5f2740cdd00\",\n",
      "    \"text\": \"In summary, our contributions are primarily threefold:\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            238.4343215999994\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            248.39692159999947\n",
      "          ],\n",
      "          [\n",
      "            323.8098412000001,\n",
      "            248.39692159999947\n",
      "          ],\n",
      "          [\n",
      "            323.8098412000001,\n",
      "            238.4343215999994\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 2,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"af238bc316c40935886d51e1cd6f997d\",\n",
      "    \"text\": \"We introduce a novel framework that leverages \\u201cgenerative vokens\\u201d to unify LLMs with Stable Diffusion, facilitating interleaved vision-and-language generation without relying on detailed image descriptions. We bridge the modality gap and improve the generation quality by using the loss of the latent diffusion model, the text generation loss, and the caption alignment loss together during training.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            135.397,\n",
      "            259.37432159999946\n",
      "          ],\n",
      "          [\n",
      "            135.397,\n",
      "            313.1729215999994\n",
      "          ],\n",
      "          [\n",
      "            504.00323739999976,\n",
      "            313.1729215999994\n",
      "          ],\n",
      "          [\n",
      "            504.00323739999976,\n",
      "            259.37432159999946\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 2,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"a56d0e409b30e6afd19ec1a97dcc897f\",\n",
      "    \"text\": \"We propose a new two-stage training strategy for description-free multimodal generation. The first stage focuses on extracting high-quality text-aligned visual features from large text-image pairs, while the second stage ensures optimal coordination between visual and textual prompts during generation. The inclusion of classifier-free guidance during training enhances the overall generation quality.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            135.397,\n",
      "            318.19132159999947\n",
      "          ],\n",
      "          [\n",
      "            135.397,\n",
      "            371.98992159999943\n",
      "          ],\n",
      "          [\n",
      "            504.0032373999998,\n",
      "            371.98992159999943\n",
      "          ],\n",
      "          [\n",
      "            504.0032373999998,\n",
      "            318.19132159999947\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 2,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"f659281827e38a289bee579939ddc602\",\n",
      "    \"text\": \"MiniGPT-5 achieves significant improvements over baseline methods on interleaved vision- and-language datasets, including VIST and MMDialog, and comparable results to the state- of-the-art on the single text-image pair dataset, CC3M. The human evaluation further shows that, compared with the two-stage baseline, MiniGPT-5 can provide better generation in perspectives of appropriate texts (55%), high-quality images (53%), and coherent multi- modal outputs (56%).\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            135.397,\n",
      "            377.0083215999995\n",
      "          ],\n",
      "          [\n",
      "            135.397,\n",
      "            441.76592159999944\n",
      "          ],\n",
      "          [\n",
      "            504.0032373999998,\n",
      "            441.76592159999944\n",
      "          ],\n",
      "          [\n",
      "            504.0032373999998,\n",
      "            377.0083215999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 2,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"0c14beaa16ffa75dd8d24d8003956ed7\",\n",
      "    \"text\": \"2 RELATED WORK\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.29899999999998,\n",
      "            463.1781231999995\n",
      "          ],\n",
      "          [\n",
      "            108.29899999999998,\n",
      "            475.1333231999995\n",
      "          ],\n",
      "          [\n",
      "            211.1957635,\n",
      "            475.1333231999995\n",
      "          ],\n",
      "          [\n",
      "            211.1957635,\n",
      "            463.1781231999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 2,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"9c79167c08ead392b80865732081832d\",\n",
      "    \"text\": \"Large Language Models As Large Language Models (LLMs) become increasingly impactful and accessible, a growing body of research has emerged to extend these pretrained LLMs into the realm of multimodal comprehension tasks (Zhu et al., 2023; Li et al., 2023c; Dai et al., 2023; OpenAI, 2023; Li et al., 2023a; Alayrac et al., 2022; Li et al., 2023b). For example, to reproduce the impres- sive multimodal comprehension ability in GPT-4 (OpenAI, 2023), MiniGPT-4 (Zhu et al., 2023) proposes a projection layer to align pretrained vision component of BLIP-2 (Li et al., 2023c) with an advanced open-source large language model, Vicuna (Chiang et al., 2023). In our work, we utilize the MiniGPT-4 as the base model and extend the model\\u2019s capabilities to multimodal generation.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            492.8405833999995\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            579.5849215999995\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            579.5849215999995\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            492.8405833999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Zhuetal .,\",\n",
      "          \"url\": \"cite.zhu2023minigpt\",\n",
      "          \"start_index\": 221\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.zhu2023minigpt\",\n",
      "          \"start_index\": 233\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Lietal .,\",\n",
      "          \"url\": \"cite.li2023blip\",\n",
      "          \"start_index\": 239\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023c\",\n",
      "          \"url\": \"cite.li2023blip\",\n",
      "          \"start_index\": 250\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Daietal .,\",\n",
      "          \"url\": \"cite.instructblip\",\n",
      "          \"start_index\": 257\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.instructblip\",\n",
      "          \"start_index\": 269\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"OpenAI\",\n",
      "          \"url\": \"cite.openai2023gpt4\",\n",
      "          \"start_index\": 275\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.openai2023gpt4\",\n",
      "          \"start_index\": 283\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Lietal .,\",\n",
      "          \"url\": \"cite.li2023otter\",\n",
      "          \"start_index\": 289\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023a\",\n",
      "          \"url\": \"cite.li2023otter\",\n",
      "          \"start_index\": 300\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Alayracetal .,\",\n",
      "          \"url\": \"cite.alayrac2022flamingo\",\n",
      "          \"start_index\": 307\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022\",\n",
      "          \"url\": \"cite.alayrac2022flamingo\",\n",
      "          \"start_index\": 323\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Lietal .,\",\n",
      "          \"url\": \"cite.li-etal-2023-lavis\",\n",
      "          \"start_index\": 329\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023b\",\n",
      "          \"url\": \"cite.li-etal-2023-lavis\",\n",
      "          \"start_index\": 340\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"OpenAI\",\n",
      "          \"url\": \"cite.openai2023gpt4\",\n",
      "          \"start_index\": 434\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.openai2023gpt4\",\n",
      "          \"start_index\": 442\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Zhuetal .,\",\n",
      "          \"url\": \"cite.zhu2023minigpt\",\n",
      "          \"start_index\": 460\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.zhu2023minigpt\",\n",
      "          \"start_index\": 472\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Lietal .,\",\n",
      "          \"url\": \"cite.li2023blip\",\n",
      "          \"start_index\": 554\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023c\",\n",
      "          \"url\": \"cite.li2023blip\",\n",
      "          \"start_index\": 565\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Chiangetal .,\",\n",
      "          \"url\": \"cite.vicuna2023\",\n",
      "          \"start_index\": 631\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.vicuna2023\",\n",
      "          \"start_index\": 646\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"0c14beaa16ffa75dd8d24d8003956ed7\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"afb342fe16c7cee9dec12264909f5e79\",\n",
      "    \"text\": \"Text-to-Image Generation To transform textual descriptions into their corresponding visual repre- sentations, text-to-image models (Reed et al., 2016; Dhariwal & Nichol, 2021; Saharia et al., 2022; Rombach et al., 2022b;a; Gu et al., 2023; Nichol et al., 2021; Ramesh et al., 2021; Yu et al., 2022; Chang et al., 2023) employ complex architectures and sophisticated algorithms, bridging the gap be- tween textual information and visual content. These models are adept at interpreting the semantics of input text and translating them into coherent and pertinent images. A notable recent contribution in this field is Stable Diffusion V2 (Rombach et al., 2022b), which employs a diffusion process to generate conditional image features and subsequently reconstructs images from these features. Our research aims to leverage this pretrained model, enhancing its capabilities to accommodate both multimodal input and output.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            590.9725833999995\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            699.6349215999995\n",
      "          ],\n",
      "          [\n",
      "            504.0033874,\n",
      "            699.6349215999995\n",
      "          ],\n",
      "          [\n",
      "            504.0033874,\n",
      "            590.9725833999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Reedetal .,\",\n",
      "          \"url\": \"cite.reed2016generative\",\n",
      "          \"start_index\": 132\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2016\",\n",
      "          \"url\": \"cite.reed2016generative\",\n",
      "          \"start_index\": 145\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Dhariwal & Nichol\",\n",
      "          \"url\": \"cite.dhariwal2021diffusion\",\n",
      "          \"start_index\": 151\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.dhariwal2021diffusion\",\n",
      "          \"start_index\": 170\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Sahariaetal .,\",\n",
      "          \"url\": \"cite.saharia2022photorealistic\",\n",
      "          \"start_index\": 176\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022\",\n",
      "          \"url\": \"cite.saharia2022photorealistic\",\n",
      "          \"start_index\": 192\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Rombachetal .,\",\n",
      "          \"url\": \"cite.rombach2021highresolution\",\n",
      "          \"start_index\": 198\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022b\",\n",
      "          \"url\": \"cite.rombach2021highresolution\",\n",
      "          \"start_index\": 214\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"a\",\n",
      "          \"url\": \"cite.rombach2022high\",\n",
      "          \"start_index\": 220\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Guetal .,\",\n",
      "          \"url\": \"cite.gu2023photoswap\",\n",
      "          \"start_index\": 223\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.gu2023photoswap\",\n",
      "          \"start_index\": 234\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Nicholetal .,\",\n",
      "          \"url\": \"cite.nichol2021glide\",\n",
      "          \"start_index\": 240\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.nichol2021glide\",\n",
      "          \"start_index\": 255\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Rameshetal .,\",\n",
      "          \"url\": \"cite.ramesh2021zero\",\n",
      "          \"start_index\": 261\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.ramesh2021zero\",\n",
      "          \"start_index\": 276\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Yuetal .,\",\n",
      "          \"url\": \"cite.yu2022scaling\",\n",
      "          \"start_index\": 282\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022\",\n",
      "          \"url\": \"cite.yu2022scaling\",\n",
      "          \"start_index\": 293\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Changetal .,\",\n",
      "          \"url\": \"cite.chang2023muse\",\n",
      "          \"start_index\": 299\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.chang2023muse\",\n",
      "          \"start_index\": 313\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Rombachetal .,\",\n",
      "          \"url\": \"cite.rombach2021highresolution\",\n",
      "          \"start_index\": 636\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022b\",\n",
      "          \"url\": \"cite.rombach2021highresolution\",\n",
      "          \"start_index\": 652\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"0c14beaa16ffa75dd8d24d8003956ed7\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"d307caa554ede48925e736acfb2b2321\",\n",
      "    \"text\": \"Multimodal Generation with Large Language Models To augment the LLM\\u2019s capabilities in seamlessly integrating vision and language generation, recent studies have introduced a variety of\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000001,\n",
      "            711.0225833999996\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000001,\n",
      "            732.0139215999995\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            732.0139215999995\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            711.0225833999996\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 2,\n",
      "      \"parent_id\": \"0c14beaa16ffa75dd8d24d8003956ed7\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Footer\",\n",
      "    \"element_id\": \"62ab308f47f0c91f963a686502c134af\",\n",
      "    \"text\": \"2\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            303.509,\n",
      "            751.9383215999995\n",
      "          ],\n",
      "          [\n",
      "            303.509,\n",
      "            761.9009215999995\n",
      "          ],\n",
      "          [\n",
      "            308.4903,\n",
      "            761.9009215999995\n",
      "          ],\n",
      "          [\n",
      "            308.4903,\n",
      "            751.9383215999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 2,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"83402dc2eb7617991fe9b628f018255e\",\n",
      "    \"text\": \"My sister arrivedearly to help mewith the familybar bq.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.86287199999992\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            304.053\n",
      "          ],\n",
      "          [\n",
      "            504.0036,\n",
      "            304.053\n",
      "          ],\n",
      "          [\n",
      "            504.0036,\n",
      "            81.86287199999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 3,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"f31df6d6a5f90198c014911ddb5ddb42\",\n",
      "    \"text\": \"What should happen then?\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.86287199999992\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            304.053\n",
      "          ],\n",
      "          [\n",
      "            504.0036,\n",
      "            304.053\n",
      "          ],\n",
      "          [\n",
      "            504.0036,\n",
      "            81.86287199999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 3,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"ba09799bcb3027f139e6bc26f315503f\",\n",
      "    \"text\": \"We didn't realizethat there wasmore to be doneand everyonehad their roles.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.86287199999992\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            304.053\n",
      "          ],\n",
      "          [\n",
      "            504.0036,\n",
      "            304.053\n",
      "          ],\n",
      "          [\n",
      "            504.0036,\n",
      "            81.86287199999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 3,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"c8951adac078539f22bd1ed6e7d31856\",\n",
      "    \"text\": \"Every one elsearrived soonafter.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.86287199999992\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            304.053\n",
      "          ],\n",
      "          [\n",
      "            504.0036,\n",
      "            304.053\n",
      "          ],\n",
      "          [\n",
      "            504.0036,\n",
      "            81.86287199999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 3,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"b8f24f898c90c82924153b4b109c903f\",\n",
      "    \"text\": \"We were gladwhen it was overand relaxed alittle bit.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.86287199999992\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            304.053\n",
      "          ],\n",
      "          [\n",
      "            504.0036,\n",
      "            304.053\n",
      "          ],\n",
      "          [\n",
      "            504.0036,\n",
      "            81.86287199999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 3,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"bbbca54206da8e8f9e3326939ecc9dec\",\n",
      "    \"text\": \"Everyone washungry so we gota lot of food.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.86287199999992\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            304.053\n",
      "          ],\n",
      "          [\n",
      "            504.0036,\n",
      "            304.053\n",
      "          ],\n",
      "          [\n",
      "            504.0036,\n",
      "            81.86287199999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 3,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"a3384085d07f4eca15e34adbcd7a2b75\",\n",
      "    \"text\": \"MiniGPT-5Multimodal InputMultimodal Output\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.86287199999992\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            304.053\n",
      "          ],\n",
      "          [\n",
      "            504.0036,\n",
      "            304.053\n",
      "          ],\n",
      "          [\n",
      "            504.0036,\n",
      "            81.86287199999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 3,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"674ae500ca7a22bacd2147253adaae40\",\n",
      "    \"text\": \"Figure 1: MiniGPT-5 is a unified model for interleaved vision-and-language comprehension and generation. Besides the original multimodal comprehension and text generation abilities, MiniGPT- 5 can provide appropriate, coherent multimodal outputs.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            313.8763216\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            345.7569216\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            345.7569216\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            313.8763216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"a3384085d07f4eca15e34adbcd7a2b75\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"70189b2cbfb8903028dd0631c26c9376\",\n",
      "    \"text\": \"innovative methods (Ge et al., 2023; Sun et al., 2021; Koh et al., 2023; Sun et al., 2023b; Yu et al., 2023; Aiello et al., 2023; Wu et al., 2023c). For instance, CM3Leon (Yu et al., 2023) presents a retrieval-augmented, decoder-only architecture designed for both text-to-image and image-to-text applications. Similarly, Emu (Sun et al., 2023b) employs the pretrained EVA-CLIP (Sun et al., 2023a) model to convert images into one-dimensional features and fine-tunes the LLAMA (Touvron et al., 2023) model to generate cohesive text and image features through autoregressive techniques. On the other hand, NextGPT (Wu et al., 2023c), GILL (Koh et al., 2023) and SEED (Ge et al., 2023) explore the concept of mapping vokens into the text feature space of a pretrained Stable Diffusion model; GILL and NextGPT employ an encoder-decoder framework, while SEED utilizes a trainable Q-Former structure. In contrast to these approaches, our model takes a more direct route by aligning voken features with visual information. Additionally, we introduce several training strategies to enhance image quality and contextual coherence.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            369.64232160000006\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            500.15292160000007\n",
      "          ],\n",
      "          [\n",
      "            504.0033874,\n",
      "            500.15292160000007\n",
      "          ],\n",
      "          [\n",
      "            504.0033874,\n",
      "            369.64232160000006\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Geetal .,\",\n",
      "          \"url\": \"cite.ge2023planting\",\n",
      "          \"start_index\": 20\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.ge2023planting\",\n",
      "          \"start_index\": 31\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Sunetal .,\",\n",
      "          \"url\": \"cite.sun2021multimodal\",\n",
      "          \"start_index\": 37\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.sun2021multimodal\",\n",
      "          \"start_index\": 49\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Kohetal .,\",\n",
      "          \"url\": \"cite.koh2023generating\",\n",
      "          \"start_index\": 55\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.koh2023generating\",\n",
      "          \"start_index\": 67\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Sunetal .,\",\n",
      "          \"url\": \"cite.Emu\",\n",
      "          \"start_index\": 73\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023b\",\n",
      "          \"url\": \"cite.Emu\",\n",
      "          \"start_index\": 85\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Yuetal\",\n",
      "          \"url\": \"cite.yu2023scaling\",\n",
      "          \"start_index\": 92\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.yu2023scaling\",\n",
      "          \"start_index\": 103\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Aielloetal .,\",\n",
      "          \"url\": \"cite.aiello2023jointly\",\n",
      "          \"start_index\": 109\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.aiello2023jointly\",\n",
      "          \"start_index\": 124\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Wuetal .,\",\n",
      "          \"url\": \"cite.wu2023nextgpt\",\n",
      "          \"start_index\": 130\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023c\",\n",
      "          \"url\": \"cite.wu2023nextgpt\",\n",
      "          \"start_index\": 141\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Yuetal .,\",\n",
      "          \"url\": \"cite.yu2023scaling\",\n",
      "          \"start_index\": 172\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.yu2023scaling\",\n",
      "          \"start_index\": 183\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Sunetal .,\",\n",
      "          \"url\": \"cite.Emu\",\n",
      "          \"start_index\": 327\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023b\",\n",
      "          \"url\": \"cite.Emu\",\n",
      "          \"start_index\": 339\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Sunetal\",\n",
      "          \"url\": \"cite.sun2023eva\",\n",
      "          \"start_index\": 379\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023a\",\n",
      "          \"url\": \"cite.sun2023eva\",\n",
      "          \"start_index\": 391\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"( etal ., 2023 ) modeltogeneratecohesivetextandimagefeaturesthroughautoregressivetechniques\",\n",
      "          \"url\": \"cite.touvron2023llama\",\n",
      "          \"start_index\": 476\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"etal .,\",\n",
      "          \"url\": \"cite.touvron2023llama\",\n",
      "          \"start_index\": 485\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.touvron2023llama\",\n",
      "          \"start_index\": 493\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Wuetal .,\",\n",
      "          \"url\": \"cite.wu2023nextgpt\",\n",
      "          \"start_index\": 613\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023c\",\n",
      "          \"url\": \"cite.wu2023nextgpt\",\n",
      "          \"start_index\": 624\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Kohetal .,\",\n",
      "          \"url\": \"cite.koh2023generating\",\n",
      "          \"start_index\": 638\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.koh2023generating\",\n",
      "          \"start_index\": 650\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Geetal .,\",\n",
      "          \"url\": \"cite.ge2023planting\",\n",
      "          \"start_index\": 666\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.ge2023planting\",\n",
      "          \"start_index\": 677\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"a3384085d07f4eca15e34adbcd7a2b75\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"77e1c03f47648b8eebbcab89c47352e8\",\n",
      "    \"text\": \"3 METHOD\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.299,\n",
      "            518.2771232000001\n",
      "          ],\n",
      "          [\n",
      "            108.299,\n",
      "            530.2323232000001\n",
      "          ],\n",
      "          [\n",
      "            172.8109394,\n",
      "            530.2323232000001\n",
      "          ],\n",
      "          [\n",
      "            172.8109394,\n",
      "            518.2771232000001\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 3,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"18e4985cd984cb0a9845b3f16957bb55\",\n",
      "    \"text\": \"In order to endow Large Language Models with multimodal generation capabilities, we introduce a new framework that integrates pretrained multimodal Large Language Models and text-to-image generation models. Central to our approach is the introduction of \\u201cgenerative vokens\\u201d, special visual tokens that effectively bridge the textual and visual domains during the training process. Addition- ally, we implement a two-stage training method combined with a classifier-free guidance strategy to enhance the quality and coherence of generated outputs. Fig. 2 provides an overview of our model structure. MiniGPT-5 primarily consists of two modules: the Integrated Vision-Language Encod- ing Module, utilizing the pretrained multimodal large language model (MiniGPT-4) for handling multimodal inputs, and the Multimodal Output Generation module, employing Stable Diffusion for generating visual outputs.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            543.9553216\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            652.5479216000001\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999995,\n",
      "            652.5479216000001\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999995,\n",
      "            543.9553216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \".\",\n",
      "          \"url\": \"figure.caption.2\",\n",
      "          \"start_index\": 549\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"77e1c03f47648b8eebbcab89c47352e8\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"25a9438b92a0db7ff884e5df6880d5a0\",\n",
      "    \"text\": \"3.1 MULTIMODAL UNDERSTANDING MODULE\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.249,\n",
      "            668.3483216000001\n",
      "          ],\n",
      "          [\n",
      "            108.249,\n",
      "            678.3109216000001\n",
      "          ],\n",
      "          [\n",
      "            310.84731350000004,\n",
      "            678.3109216000001\n",
      "          ],\n",
      "          [\n",
      "            310.84731350000004,\n",
      "            668.3483216000001\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 3,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"ef4e75281fa5b37781c601d20052f11c\",\n",
      "    \"text\": \"Recent advancements in multimodal Large Language Models, such as MiniGPT-4 (Zhu et al., 2023), have primarily concentrated on multimodal comprehension, enabling the processing of images as sequential input. The Integrated Vision-Language Encoding Module is designed to extend the capa- bilities of LLMs from mere comprehension to active generation in multimodal contexts. Generative\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000003,\n",
      "            689.1743216000001\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000003,\n",
      "            732.0139216000001\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            732.0139216000001\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            689.1743216000001\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Zhuetal .,\",\n",
      "          \"url\": \"cite.zhu2023minigpt\",\n",
      "          \"start_index\": 76\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.zhu2023minigpt\",\n",
      "          \"start_index\": 88\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 3,\n",
      "      \"parent_id\": \"25a9438b92a0db7ff884e5df6880d5a0\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Footer\",\n",
      "    \"element_id\": \"5d9346f71ee129ef877ee75a0489659c\",\n",
      "    \"text\": \"3\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            303.509,\n",
      "            751.9393216000001\n",
      "          ],\n",
      "          [\n",
      "            303.509,\n",
      "            761.9019216000002\n",
      "          ],\n",
      "          [\n",
      "            308.4903,\n",
      "            761.9019216000002\n",
      "          ],\n",
      "          [\n",
      "            308.4903,\n",
      "            751.9393216000001\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 3,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"e9d191bdd2adb5b9f59898c60f544188\",\n",
      "    \"text\": \"EstimatedNoise\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.86167039999998\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            81.86167039999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 4,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"9da05fc94f387ca290ccd4f921e7cfda\",\n",
      "    \"text\": \"TransformerEncoderFeature Mapper\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.86167039999998\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            81.86167039999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 4,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"d2415cff36a2fa3f0a66aa9cc78c2a1b\",\n",
      "    \"text\": \"TransformerDecoder\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.86167039999998\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            81.86167039999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 4,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"5bab81ba9c6528d197a2e35a68028db7\",\n",
      "    \"text\": \"SD ImageEncoder\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.86167039999998\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            81.86167039999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 4,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"d08f795ba6f5cbd47008eca01dafb070\",\n",
      "    \"text\": \"SDUnet\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.86167039999998\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            81.86167039999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 4,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"11449af0fd27ebd662341bf5c1b12c73\",\n",
      "    \"text\": \"Z\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.86167039999998\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            81.86167039999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 4,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"e2585ecb459bfce115e4648aaf0c1e34\",\n",
      "    \"text\": \"PEFT\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.86167039999998\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            81.86167039999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 4,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"39e45db8e9412fbba242201383a968e8\",\n",
      "    \"text\": \"Output Hidden State\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.86167039999998\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            81.86167039999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 4,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"05a6d9e853ade259fa71a96b8b9bccf8\",\n",
      "    \"text\": \"TextTokenizer\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.86167039999998\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            81.86167039999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 4,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"a3e74207d24cd3e6d83d0bba97487599\",\n",
      "    \"text\": \"Learnable Queries\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.86167039999998\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            81.86167039999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 4,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"6d362a6043ee17311e4967cf4468f531\",\n",
      "    \"text\": \"LLM (Vicuna)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.86167039999998\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            81.86167039999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 4,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"8a794e8124028cc5a0a7b469858d6ab3\",\n",
      "    \"text\": \"VokenPositioningLossVokenAlignmentLossGT Output TextMultimodal InputGT Output Image\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.86167039999998\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            81.86167039999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 4,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"d9d047ffb2075f3d3d90b5a87c0cc3d0\",\n",
      "    \"text\": \"\\\"Why not try getting it down with a soccerball? [IMG 1] ... [IMG n]\\\"\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.86167039999998\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            81.86167039999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"8a794e8124028cc5a0a7b469858d6ab3\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"fd7ea960e0074de42c5ec11cde0d377f\",\n",
      "    \"text\": \"Zt\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.86167039999998\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            81.86167039999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 4,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"0b08711073f62e3649491ddd9914f1c9\",\n",
      "    \"text\": \"\\\"A discus gotstuck up on theroof.\\\"\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.86167039999998\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            81.86167039999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"fd7ea960e0074de42c5ec11cde0d377f\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"6c27c111068128cfadcb3f00bc874c8c\",\n",
      "    \"text\": \"Linear LayerVoken Features\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.86167039999998\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            81.86167039999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 4,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"5344d42643a5451bf8fc03ada279c4c3\",\n",
      "    \"text\": \"Noise\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.86167039999998\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            81.86167039999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 4,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"ba2f3e123a745502b70dcbfe8df8d992\",\n",
      "    \"text\": \"ImageEncoder\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.86167039999998\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            271.78099999999995\n",
      "          ],\n",
      "          [\n",
      "            504.0019831768,\n",
      "            81.86167039999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 4,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"86930e3df565c01153eb6720a1cbd7d4\",\n",
      "    \"text\": \"Figure 2: The overview structure of MiniGPT-5 pipeline. We leverage the pretrained multimodal large language model (MiniGPT-4) and text-to-image generation model (Stable Diffusion 2.1) to create a unified multimodal generation pipeline. The input image encoder includes a ViT, Qformer, and linear layer, pretrained by MiniGPT-4. The orange blocks include learnable parameters, while the blue blocks are fixed during training. More details can be found in Section 3.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            281.60432160000005\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            335.4029216\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999995,\n",
      "            335.4029216\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999995,\n",
      "            281.60432160000005\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"ba2f3e123a745502b70dcbfe8df8d992\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"a73ebb8d135b4c8b485601bf689479f3\",\n",
      "    \"text\": \"vokens play a crucial role in this module, enabling the translation of raw visual inputs into a format that LLMs can process and utilize for subsequent generation tasks.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            372.8603216\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            393.78192160000003\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999996,\n",
      "            393.78192160000003\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999996,\n",
      "            372.8603216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"ba2f3e123a745502b70dcbfe8df8d992\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"63df4b725fbfe4634b517cbb6b008317\",\n",
      "    \"text\": \"Multimodal Encoding Each text token is embedded into a vector etext \\u2208 Rd, while the pretrained visual encoder transforms each input image into the feature eimg \\u2208 R32\\u00d7d. These embeddings are concatenated to create the input prompt features.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            403.8131172000001\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            437.11992160000005\n",
      "          ],\n",
      "          [\n",
      "            504.0029682,\n",
      "            437.11992160000005\n",
      "          ],\n",
      "          [\n",
      "            504.0029682,\n",
      "            403.8131172000001\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"ba2f3e123a745502b70dcbfe8df8d992\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"848a852bbfeead16f9d1907482644030\",\n",
      "    \"text\": \"Generative Vokens Since the original LLM\\u2019s V vocabulary only includes the textual tokens, we need to construct a bridge between the LLM and the generative model. Therefore, we introduce a set of special tokens Vimg = {[IMG1], [IMG2], . . . , [IMGn]} (by default n = 8) as generative vokens into the LLM\\u2019s vocabulary V . The LLM\\u2019s output hidden state for these vokens is harnessed for subsequent image generation, and the positions of these vokens can represent the insertion of the in- terleaved images. With all pretrained weights \\u03b8pretrained in MiniGPT-4 fixed, the trainable parameters include extra input embedding \\u03b8voken input and output embedding \\u03b8voken output.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999994,\n",
      "            448.35714440000004\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999994,\n",
      "            525.1413408000001\n",
      "          ],\n",
      "          [\n",
      "            504.0038015999999,\n",
      "            525.1413408000001\n",
      "          ],\n",
      "          [\n",
      "            504.0038015999999,\n",
      "            448.35714440000004\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"ba2f3e123a745502b70dcbfe8df8d992\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"73ca92748d796951109366a4effbb0c8\",\n",
      "    \"text\": \"Parameter-Efficient Fine-Tuning (PEFT) Parameter-efficient fine-tuning (PEFT) (Houlsby et al., 2019; Hu et al., 2021; Li & Liang, 2021) is critical in training Large Language Models (LLMs), employed to adapt LLMs to downstream tasks without the need for extensive retraining. In PEFT, rather than updating all the parameters of a model, only a small subset of parameters is trained. This subset typically includes task-specific components or lightweight layers added to the original model architecture (Zhang et al., 2021; Houlsby et al., 2019; Hu et al., 2021; Dettmers et al., 2023). We apply PEFT to the MiniGPT-4 (Zhu et al., 2023) encoder, enhancing its ability to process and generate multimodal content based on given instructions or prompts. More specifically, this involves the use of prefix tuning (Li & Liang, 2021) and LoRAHu et al. (2021) over the entire language encoder \\u2013 Vicuna (Chiang et al., 2023) used in MiniGPT-4. Additionally, we implement learnable queries at the input of the transformer decoder, a conventional approach in sequence-to-sequence transformer architectures, to further improve the model\\u2019s multimodal generation capabilities. We also adopted learnable queries at the input of the transformer decoder as a conventional setting for sequence-to-sequence transformer architectures (Vaswani et al., 2017a). Learnable queries in the decoder allow the model to have dynamic, adaptable representations for initiating the generation process. This is particularly useful when the model needs to generate outputs based on a mix of visual and textual inputs. Combined with the instruction tuning (Ouyang et al., 2022), it notably amplifies multimodal generation performance across various datasets.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999994,\n",
      "            535.6795834\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999994,\n",
      "            732.0139216\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999995,\n",
      "            732.0139216\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999995,\n",
      "            535.6795834\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Houlsbyetal\",\n",
      "          \"url\": \"cite.houlsby2019parameter\",\n",
      "          \"start_index\": 76\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2019\",\n",
      "          \"url\": \"cite.houlsby2019parameter\",\n",
      "          \"start_index\": 92\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Huetal .,\",\n",
      "          \"url\": \"cite.hu2021lora\",\n",
      "          \"start_index\": 98\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.hu2021lora\",\n",
      "          \"start_index\": 109\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Li & Liang\",\n",
      "          \"url\": \"cite.li2021prefix\",\n",
      "          \"start_index\": 115\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.li2021prefix\",\n",
      "          \"start_index\": 127\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Zhangetal .,\",\n",
      "          \"url\": \"cite.tip_adapter\",\n",
      "          \"start_index\": 499\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.tip_adapter\",\n",
      "          \"start_index\": 513\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Houlsbyetal .,\",\n",
      "          \"url\": \"cite.houlsby2019parameter\",\n",
      "          \"start_index\": 519\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2019\",\n",
      "          \"url\": \"cite.houlsby2019parameter\",\n",
      "          \"start_index\": 535\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Huetal .,\",\n",
      "          \"url\": \"cite.hu2021lora\",\n",
      "          \"start_index\": 541\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.hu2021lora\",\n",
      "          \"start_index\": 552\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Dettmersetal .,\",\n",
      "          \"url\": \"cite.dettmers2023qlora\",\n",
      "          \"start_index\": 558\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.dettmers2023qlora\",\n",
      "          \"start_index\": 575\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Zhuetal .,\",\n",
      "          \"url\": \"cite.zhu2023minigpt\",\n",
      "          \"start_index\": 614\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.zhu2023minigpt\",\n",
      "          \"start_index\": 626\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Li & Liang\",\n",
      "          \"url\": \"cite.li2021prefix\",\n",
      "          \"start_index\": 803\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.li2021prefix\",\n",
      "          \"start_index\": 815\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"-\",\n",
      "          \"url\": \"cite.hu2021lora\",\n",
      "          \"start_index\": 925\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.hu2021lora\",\n",
      "          \"start_index\": 840\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Chiangetal .,\",\n",
      "          \"url\": \"cite.vicuna2023\",\n",
      "          \"start_index\": 889\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.vicuna2023\",\n",
      "          \"start_index\": 904\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Vaswanietal .,\",\n",
      "          \"url\": \"cite.transformer\",\n",
      "          \"start_index\": 1309\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2017a\",\n",
      "          \"url\": \"cite.transformer\",\n",
      "          \"start_index\": 1325\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Ouyangetal .,\",\n",
      "          \"url\": \"cite.training_lm\",\n",
      "          \"start_index\": 1616\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022\",\n",
      "          \"url\": \"cite.training_lm\",\n",
      "          \"start_index\": 1631\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 4,\n",
      "      \"parent_id\": \"ba2f3e123a745502b70dcbfe8df8d992\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Footer\",\n",
      "    \"element_id\": \"d5175f50113740dc33d9bfda920585bf\",\n",
      "    \"text\": \"4\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            303.50899999999996,\n",
      "            751.9393216000001\n",
      "          ],\n",
      "          [\n",
      "            303.50899999999996,\n",
      "            761.9019216\n",
      "          ],\n",
      "          [\n",
      "            308.49029999999993,\n",
      "            761.9019216\n",
      "          ],\n",
      "          [\n",
      "            308.49029999999993,\n",
      "            751.9393216000001\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 4,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"2cd71c4b2d4835ef12ca139682cc33d4\",\n",
      "    \"text\": \"3.2 MUTIMODAL GENERATION MODULE\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.249,\n",
      "            84.01332159999993\n",
      "          ],\n",
      "          [\n",
      "            108.249,\n",
      "            93.97592159999999\n",
      "          ],\n",
      "          [\n",
      "            287.7643135,\n",
      "            93.97592159999999\n",
      "          ],\n",
      "          [\n",
      "            287.7643135,\n",
      "            84.01332159999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"e8c5c35fa47f517377e60aa432c59a16\",\n",
      "    \"text\": \"To accurately align the generative vokens with the text-to-image generation models, we formulate a compact mapping module for dimension matching and incorporate several supervised losses, includ- ing voken positioning loss and voken alignment loss. The voken positioning loss assists the model in learning the correct positioning of tokens, while the voken alignment loss directly aligns the vo- kens with the appropriate conditional generation features of the diffusion model. Since the gradients of generative vokens\\u2019 features can be directly calculated from images, shown on the right side of Fig. 2, our method does not need comprehensive descriptions of images, leading to description-free learning.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            104.5483215999999\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            191.2229215999996\n",
      "          ],\n",
      "          [\n",
      "            504.0033874,\n",
      "            191.2229215999996\n",
      "          ],\n",
      "          [\n",
      "            504.0033874,\n",
      "            104.5483215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2\",\n",
      "          \"url\": \"figure.caption.2\",\n",
      "          \"start_index\": 601\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"2cd71c4b2d4835ef12ca139682cc33d4\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"c9c34eaf57214b2fd9ea72da3d113cfc\",\n",
      "    \"text\": \"Voken Positioning We first jointly generate both text and vokens in the text space by follow- ing next-word prediction in autoregressive language model (Vaswani et al., 2017b). During the training, we append the vokens Vimg to the positions of ground truth images and train the model to predict vokens within text generation. Specifically, the generated tokens are represented as W = {w1, w2, . . . , wm}, where wi \\u2208 V \\u222a Vimg, and the causal language modeling loss is defined as:\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            202.61058339999954\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            267.4379215999993\n",
      "          ],\n",
      "          [\n",
      "            504.00359760000015,\n",
      "            267.4379215999993\n",
      "          ],\n",
      "          [\n",
      "            504.00359760000015,\n",
      "            202.61058339999954\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Vaswanietal .,\",\n",
      "          \"url\": \"cite.vaswani2017attention\",\n",
      "          \"start_index\": 152\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2017b\",\n",
      "          \"url\": \"cite.vaswani2017attention\",\n",
      "          \"start_index\": 168\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"2cd71c4b2d4835ef12ca139682cc33d4\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"3dced4418deec2b0b1a3626d72880694\",\n",
      "    \"text\": \"Ltext := \\u2212\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            204.91899999999998,\n",
      "            281.81814439999926\n",
      "          ],\n",
      "          [\n",
      "            204.91899999999998,\n",
      "            292.84934079999925\n",
      "          ],\n",
      "          [\n",
      "            246.35291027999995,\n",
      "            292.84934079999925\n",
      "          ],\n",
      "          [\n",
      "            246.35291027999995,\n",
      "            281.81814439999926\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"2320d59ede6a7cdd692e44e86a9a2334\",\n",
      "    \"text\": \"m (cid:88)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            248.01299999999995,\n",
      "            271.7741171999993\n",
      "          ],\n",
      "          [\n",
      "            248.01299999999995,\n",
      "            286.36155999999926\n",
      "          ],\n",
      "          [\n",
      "            262.40397569999993,\n",
      "            286.36155999999926\n",
      "          ],\n",
      "          [\n",
      "            262.40397569999993,\n",
      "            271.7741171999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"3dced4418deec2b0b1a3626d72880694\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"4e10f67a52d01f64bcff85604e80fad6\",\n",
      "    \"text\": \"logp(wi|etext, eimg, w1, . . . , wi\\u22121;\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            264.06399999999996,\n",
      "            281.81814439999926\n",
      "          ],\n",
      "          [\n",
      "            264.06399999999996,\n",
      "            292.84934079999925\n",
      "          ],\n",
      "          [\n",
      "            396.52861028,\n",
      "            292.84934079999925\n",
      "          ],\n",
      "          [\n",
      "            396.52861028,\n",
      "            281.81814439999926\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"a78b036c1d03199e263cc1e4f39ba300\",\n",
      "    \"text\": \"i=1\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            248.75599999999994,\n",
      "            295.98211719999927\n",
      "          ],\n",
      "          [\n",
      "            248.75599999999994,\n",
      "            302.95591719999925\n",
      "          ],\n",
      "          [\n",
      "            261.66160169999995,\n",
      "            302.95591719999925\n",
      "          ],\n",
      "          [\n",
      "            261.66160169999995,\n",
      "            295.98211719999927\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"4e10f67a52d01f64bcff85604e80fad6\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"1271a458d099106495b895add7d20bc9\",\n",
      "    \"text\": \"\\u03b8pretrained, \\u03b8voken input, \\u03b8voken output), where wi \\u2208 V \\u222a Vimg\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            276.933,\n",
      "            306.22614439999927\n",
      "          ],\n",
      "          [\n",
      "            276.933,\n",
      "            331.20434079999995\n",
      "          ],\n",
      "          [\n",
      "            407.08061028,\n",
      "            331.20434079999995\n",
      "          ],\n",
      "          [\n",
      "            407.08061028,\n",
      "            306.22614439999927\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"4e10f67a52d01f64bcff85604e80fad6\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"1ede0888a20cb14010916a97e5c8188e\",\n",
      "    \"text\": \"Voken Alignment for Image Generation Next, we align the output hidden state hvoken, shown in Fig. 2, with the conditional feature space of the text-to-image generation model. To map the voken feature hvoken to a feasible image generation conditional feature etext encoder \\u2208 RL\\u00d7 \\u02c6d (where L is the maximum input length of text-to-image generation text encoder, and \\u02c6d is the dimension of encoder output feature in text-to-image generation model). We construct a feature mapper module, including a two-layer MLP model \\u03b8MLP, a four-layer encoder-decoder transformer model \\u03b8enc-dec, and a learnable decoder feature sequence q. The mapping feature \\u02c6hvoken is then given by:\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            348.59314439999997\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            431.3533408\n",
      "          ],\n",
      "          [\n",
      "            504.0033874,\n",
      "            431.3533408\n",
      "          ],\n",
      "          [\n",
      "            504.0033874,\n",
      "            348.59314439999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"2\",\n",
      "          \"url\": \"figure.caption.2\",\n",
      "          \"start_index\": 98\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"4e10f67a52d01f64bcff85604e80fad6\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"87d0bccc2a260067f350232094461680\",\n",
      "    \"text\": \"\\u02c6hvoken := \\u03b8enc-dec(\\u03b8MLP(hvoken), q) \\u2208 RL\\u00d7 \\u02c6d\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            220.79800000000003,\n",
      "            437.72711720000007\n",
      "          ],\n",
      "          [\n",
      "            220.79800000000003,\n",
      "            452.3023408000001\n",
      "          ],\n",
      "          [\n",
      "            391.9025791000002,\n",
      "            452.3023408000001\n",
      "          ],\n",
      "          [\n",
      "            391.9025791000002,\n",
      "            437.72711720000007\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"4e10f67a52d01f64bcff85604e80fad6\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"b6ea3c3973f009924aceaff556f0426d\",\n",
      "    \"text\": \"To generate appropriate images, the mapping feature \\u02c6hvoken is used as a conditional input in the denoising process. Intuitively, \\u02c6hvoken should represent the corresponding conditional features that conduct the diffusion model to generate the ground truth image. We employ the latent diffusion model (LDM) loss as voken alignment loss for training the image generation module. During the training, the ground truth image is first converted to latent feature z0 through the pretrained VAE (Variational Autoencoder) (Kingma & Welling, 2013). Then, we obtain the noisy latent feature zt by adding noise \\u03f5 to z0. A pretrained U-Net model \\u03f5\\u03b8 is used to calculate the conditional LDM loss as: (cid:20)(cid:13) (cid:13) (cid:13)\\u03f5 \\u2212 \\u03f5\\u03b8\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0000000000002,\n",
      "            464.65514440000004\n",
      "          ],\n",
      "          [\n",
      "            108.0000000000002,\n",
      "            575.8395600000002\n",
      "          ],\n",
      "          [\n",
      "            504.00338740000007,\n",
      "            575.8395600000002\n",
      "          ],\n",
      "          [\n",
      "            504.00338740000007,\n",
      "            464.65514440000004\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Kingma & Welling\",\n",
      "          \"url\": \"cite.vae\",\n",
      "          \"start_index\": 514\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2013\",\n",
      "          \"url\": \"cite.vae\",\n",
      "          \"start_index\": 532\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"4e10f67a52d01f64bcff85604e80fad6\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"27499c7e6caeec5141a20d3cd087470c\",\n",
      "    \"text\": \"(cid:21)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            400.6190000000001,\n",
      "            551.3309600000002\n",
      "          ],\n",
      "          [\n",
      "            400.6190000000001,\n",
      "            561.2935600000003\n",
      "          ],\n",
      "          [\n",
      "            405.8772602800001,\n",
      "            561.2935600000003\n",
      "          ],\n",
      "          [\n",
      "            405.8772602800001,\n",
      "            551.3309600000002\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"4e10f67a52d01f64bcff85604e80fad6\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"b1ccc7ef5a05c3bf7d96f5cc1130a88c\",\n",
      "    \"text\": \"(cid:17)(cid:13) 2 (cid:13) (cid:13) 2\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            384.6650000000001,\n",
      "            553.9209600000002\n",
      "          ],\n",
      "          [\n",
      "            384.6650000000001,\n",
      "            577.6909172000003\n",
      "          ],\n",
      "          [\n",
      "            400.1215791000001,\n",
      "            577.6909172000003\n",
      "          ],\n",
      "          [\n",
      "            400.1215791000001,\n",
      "            553.9209600000002\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"4e10f67a52d01f64bcff85604e80fad6\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"8de31ba6e27477d23204bdc661564865\",\n",
      "    \"text\": \"(cid:16)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            335.0480000000001,\n",
      "            554.3199600000003\n",
      "          ],\n",
      "          [\n",
      "            335.0480000000001,\n",
      "            564.2825600000002\n",
      "          ],\n",
      "          [\n",
      "            340.9976647200001,\n",
      "            564.2825600000002\n",
      "          ],\n",
      "          [\n",
      "            340.9976647200001,\n",
      "            554.3199600000003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"4e10f67a52d01f64bcff85604e80fad6\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"90a2673f6878ca0b9bc92fcb78493c4a\",\n",
      "    \"text\": \"zt, t, \\u02c6hvoken\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            340.9980000000001,\n",
      "            558.7051444000002\n",
      "          ],\n",
      "          [\n",
      "            340.9980000000001,\n",
      "            572.3643408000003\n",
      "          ],\n",
      "          [\n",
      "            384.1667532000001,\n",
      "            572.3643408000003\n",
      "          ],\n",
      "          [\n",
      "            384.1667532000001,\n",
      "            558.7051444000002\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"4e10f67a52d01f64bcff85604e80fad6\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"c8c99f9ebba939e608f24ff22818c0b7\",\n",
      "    \"text\": \"LLDM := E\\u03f5\\u223cN (0,1),t\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            206.12300000000022,\n",
      "            559.4014000000002\n",
      "          ],\n",
      "          [\n",
      "            206.12300000000022,\n",
      "            572.5149172000001\n",
      "          ],\n",
      "          [\n",
      "            295.66510242000015,\n",
      "            572.5149172000001\n",
      "          ],\n",
      "          [\n",
      "            295.66510242000015,\n",
      "            559.4014000000002\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"4e10f67a52d01f64bcff85604e80fad6\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"088901f58a186cbaa35f101da6c19106\",\n",
      "    \"text\": \"To summarize, the voken positioning loss enables the model to learn the accurate placement of tokens. Without this component, the model lacks the essential capability to predict when vokens should be generated during inference. Additionally, the voken alignment loss ensures the direct correspondence between vokens and the appropriate conditional generation characteristics of the diffusion model. In the absence of this loss, the model is unable to learn semantic vokens from images directly. This comprehensive approach ensures a coherent understanding and generation of both textual and visual elements, leveraging the capabilities of pretrained models, specialized tokens, and innovative training techniques.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000006,\n",
      "            588.8093216000002\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000006,\n",
      "            675.4849216000002\n",
      "          ],\n",
      "          [\n",
      "            504.00338740000007,\n",
      "            675.4849216000002\n",
      "          ],\n",
      "          [\n",
      "            504.00338740000007,\n",
      "            588.8093216000002\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"4e10f67a52d01f64bcff85604e80fad6\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"f05220a87241d0ddb5a715efde1af84e\",\n",
      "    \"text\": \"3.3 TRAINING STRATEGY\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.24900000000005,\n",
      "            690.5573216000003\n",
      "          ],\n",
      "          [\n",
      "            108.24900000000005,\n",
      "            700.5199216000002\n",
      "          ],\n",
      "          [\n",
      "            223.60777240000007,\n",
      "            700.5199216000002\n",
      "          ],\n",
      "          [\n",
      "            223.60777240000007,\n",
      "            690.5573216000003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"daf52a9e89ccb0c8925b9d9cbb9cd6ea\",\n",
      "    \"text\": \"Given the non-negligible domain shift between text and image domains, we observe that direct training on a limited interleaved text-and-image dataset can result in misaligning generated texts\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000009,\n",
      "            711.0923216000002\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000009,\n",
      "            732.0139216000002\n",
      "          ],\n",
      "          [\n",
      "            504.0033874,\n",
      "            732.0139216000002\n",
      "          ],\n",
      "          [\n",
      "            504.0033874,\n",
      "            711.0923216000002\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 5,\n",
      "      \"parent_id\": \"f05220a87241d0ddb5a715efde1af84e\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Footer\",\n",
      "    \"element_id\": \"84d4aec4f8dc18991b905ae3e6d09004\",\n",
      "    \"text\": \"5\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            303.50900000000007,\n",
      "            751.9393216000003\n",
      "          ],\n",
      "          [\n",
      "            303.50900000000007,\n",
      "            761.9019216000003\n",
      "          ],\n",
      "          [\n",
      "            308.49030000000005,\n",
      "            761.9019216000003\n",
      "          ],\n",
      "          [\n",
      "            308.49030000000005,\n",
      "            751.9393216000003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"a635ee7eb2c2446793dcd6e31bbe5672\",\n",
      "    \"text\": \"(1)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            492.384,\n",
      "            306.44532159999994\n",
      "          ],\n",
      "          [\n",
      "            492.384,\n",
      "            316.40792159999995\n",
      "          ],\n",
      "          [\n",
      "            504.0003916,\n",
      "            316.40792159999995\n",
      "          ],\n",
      "          [\n",
      "            504.0003916,\n",
      "            306.44532159999994\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"f5b2ee406052c53f53acfd5f79f4b3c5\",\n",
      "    \"text\": \"(2)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            492.38400000000024,\n",
      "            441.4913216000001\n",
      "          ],\n",
      "          [\n",
      "            492.38400000000024,\n",
      "            451.45392160000006\n",
      "          ],\n",
      "          [\n",
      "            504.0003916000002,\n",
      "            451.45392160000006\n",
      "          ],\n",
      "          [\n",
      "            504.0003916000002,\n",
      "            441.4913216000001\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"cca92d3a845e25200b567a01d3fb5358\",\n",
      "    \"text\": \"(3)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            492.38400000000007,\n",
      "            561.5533216000002\n",
      "          ],\n",
      "          [\n",
      "            492.38400000000007,\n",
      "            571.5159216000002\n",
      "          ],\n",
      "          [\n",
      "            504.00039160000006,\n",
      "            571.5159216000002\n",
      "          ],\n",
      "          [\n",
      "            504.00039160000006,\n",
      "            561.5533216000002\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 5,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"25d7a8b4b88fae113b7a00f6bddb05fb\",\n",
      "    \"text\": \"and images and diminished image quality. Consequently, we adopt a two-stage training strategy: an initial pretraining stage focusing on coarse feature alignment for unimodal generation, followed by a fine-tuning stage dedicated to intricate feature learning for multimodal generation. Furthermore, to amplify the effectiveness of the generative tokens throughout the diffusion process, we incorporate the idea of classifier-free guidance (Ho & Salimans, 2022) technique through the whole training process.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            84.01332159999993\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            148.77092159999972\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999995,\n",
      "            148.77092159999972\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999995,\n",
      "            84.01332159999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Ho & Salimans\",\n",
      "          \"url\": \"cite.classifier_free_guidance\",\n",
      "          \"start_index\": 437\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022\",\n",
      "          \"url\": \"cite.classifier_free_guidance\",\n",
      "          \"start_index\": 452\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"40d7178199124808559a661392b2da8e\",\n",
      "    \"text\": \"Two-stage Training Strategy Recognizing the non-trivial domain shift between pure-text gener- ation and text-image generation, we propose a two-stage training strategy: Pretraining Stage and Fine-tuning Stage. Initially, we align the voken feature with image generation features in single text-image pair datasets, such as CC3M, where each data sample only contains one text and one im- age, and the text is usually the caption of the image. During this stage, we utilize captions as LLM input, enabling LLM to generate vokens. Since these datasets include the image descriptive infor- mation, we also introduce an auxiliary loss to aid voken alignment, minimizing the distance between the generative feature \\u02c6hvoken and the caption feature from the text encoder \\u03c4\\u03b8 in the text-to-image generation model:\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            160.15858339999966\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            259.60392159999935\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999984,\n",
      "            259.60392159999935\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999984,\n",
      "            160.15858339999966\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 6,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"72a0368dadab91565bdc43189bf16af6\",\n",
      "    \"text\": \"LCAP := MSE(\\u02c6hvoken, \\u03c4\\u03b8(c)) The pretraining stage loss is expressed as LPretrain = \\u03bb1 \\u2217Ltext +\\u03bb2 \\u2217LLDM +\\u03bb3 \\u2217LCAP, with selected values \\u03bb1 = 0.01, \\u03bb2 = 1, \\u03bb3 = 0.1 to rescale the loss into a similar numerical range.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999989,\n",
      "            261.37214439999923\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999989,\n",
      "            302.6589171999993\n",
      "          ],\n",
      "          [\n",
      "            504.0032313999999,\n",
      "            302.6589171999993\n",
      "          ],\n",
      "          [\n",
      "            504.0032313999999,\n",
      "            261.37214439999923\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 6,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"2b41e75f585ead4e3fbef0b0ecc9bd46\",\n",
      "    \"text\": \"After the pretraining stage, the model is capable of generating images for single text descriptions but struggles with interleaved vision-and-language generation, which includes multiple text-image pairs and requires complicated reasoning for both text and image generation. To address this, in the fine-tuning stage, we further fine-tune our model with PEFT parameters by interleaved vision- and-language datasets, such as VIST, where the data sample has several steps with text-image and texts are sequentially relevant. During this stage, we construct three types of tasks from the dataset, encompassing (1) text-only generation: given the next image, generating the related text; (2) image- only generation: given the next text, generating the related image, and (3) multimodal generation: generating text-image pair by given context. The fine-tuning stage loss is given by LFine-tune = \\u03bb1 \\u2217 Ltext + \\u03bb2 \\u2217 LLDM. More implementation details can be found in Appendix A.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999989,\n",
      "            308.9373215999992\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999989,\n",
      "            418.3793407999993\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            418.3793407999993\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            308.9373215999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"multimodalgeneration generatingtext - imagepairbygivencontext . Thefine - tuningstagelossisgivenbyLFine - tune \\u03bb1 \\u2217 Ltext + \\u03bb2 \\u2217 LLDM . MoreimplementationdetailscanbefoundinAppendixA\",\n",
      "          \"url\": \"appendix.A\",\n",
      "          \"start_index\": 769\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"e7079e540f84d09f704a8305e3f6fcb1\",\n",
      "    \"text\": \"Classifier-Free Guidance (CFG) To enhance the coherence between the generated text and im- ages, we first leverage the idea of Classifier-free Guidance for multimodal generation. Classifier- free guidance is introduced in the text-to-image diffusion process. This method observes that the generation model P\\u03b8 can achieve improved conditional results by training on both conditional and unconditional generation with conditioning dropout. In our context, we want the model to focus directly on the output features hvoken from LLM. Instead of using original stable diffusion uncondi- tional distributions (dropping \\u02c6hvoken), the whole feature mapper also needs to be included during the unconditional process. Therefore, our objective is to accentuate the trainable condition hvoken and the generation model is fixed. During training, we replace hvoken with zero features h0 \\u2208 0n\\u00d7d with a 10% probability, obtaining the unconditional feature \\u02c6h0 = \\u03b8enc-dec(\\u03b8MLP(h0), q). During inference, \\u02c6h0 serves as negative prompting, and the refined denoising process is:\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999989,\n",
      "            428.9175833999993\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999989,\n",
      "            554.7939171999992\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            554.7939171999992\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            428.9175833999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 6,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"29694eb0b1f471e22d1376a34e74ea7e\",\n",
      "    \"text\": \"(cid:16)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            221.11500000000007,\n",
      "            559.7389599999992\n",
      "          ],\n",
      "          [\n",
      "            221.11500000000007,\n",
      "            569.7015599999993\n",
      "          ],\n",
      "          [\n",
      "            227.06466472000005,\n",
      "            569.7015599999993\n",
      "          ],\n",
      "          [\n",
      "            227.06466472000005,\n",
      "            559.7389599999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 6,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"9fd2cf1c747d094608f55edd496018c7\",\n",
      "    \"text\": \"\\u03f5t | zt+1, \\u02c6hvoken, \\u02c6h0 (cid:17) (cid:16)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            227.06500000000005,\n",
      "            564.1241443999993\n",
      "          ],\n",
      "          [\n",
      "            227.06500000000005,\n",
      "            591.6195599999993\n",
      "          ],\n",
      "          [\n",
      "            306.25766472,\n",
      "            591.6195599999993\n",
      "          ],\n",
      "          [\n",
      "            306.25766472,\n",
      "            564.1241443999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 6,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"82e6445b842146a38dfed4c65aca5803\",\n",
      "    \"text\": \"log (cid:99)P\\u03b8 (cid:16)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            193.63800000000006,\n",
      "            566.7531443999992\n",
      "          ],\n",
      "          [\n",
      "            193.63800000000006,\n",
      "            591.6195599999993\n",
      "          ],\n",
      "          [\n",
      "            218.79160000000007,\n",
      "            591.6195599999993\n",
      "          ],\n",
      "          [\n",
      "            218.79160000000007,\n",
      "            566.7531443999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 6,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"a2c2dd191d5e91d523298d68804ca8d5\",\n",
      "    \"text\": \"\\u03f5t | zt+1, \\u02c6hvoken\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            238.72599999999994,\n",
      "            586.0421443999993\n",
      "          ],\n",
      "          [\n",
      "            238.72599999999994,\n",
      "            599.7013407999992\n",
      "          ],\n",
      "          [\n",
      "            299.80975319999993,\n",
      "            599.7013407999992\n",
      "          ],\n",
      "          [\n",
      "            299.80975319999993,\n",
      "            586.0421443999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 6,\n",
      "      \"parent_id\": \"82e6445b842146a38dfed4c65aca5803\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"2ee22b0cca3edcafb425aa8be77d769b\",\n",
      "    \"text\": \"\\u03b3\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            191.97799999999995,\n",
      "            588.6711443999993\n",
      "          ],\n",
      "          [\n",
      "            191.97799999999995,\n",
      "            598.6337443999993\n",
      "          ],\n",
      "          [\n",
      "            197.13563801999996,\n",
      "            598.6337443999993\n",
      "          ],\n",
      "          [\n",
      "            197.13563801999996,\n",
      "            588.6711443999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 6,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"32fd259ca815a900a57b9e076e640622\",\n",
      "    \"text\": \"log P\\u03b8\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            205.29899999999995,\n",
      "            588.6711443999993\n",
      "          ],\n",
      "          [\n",
      "            205.29899999999995,\n",
      "            599.5479171999992\n",
      "          ],\n",
      "          [\n",
      "            230.40244457999995,\n",
      "            599.5479171999992\n",
      "          ],\n",
      "          [\n",
      "            230.40244457999995,\n",
      "            588.6711443999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 6,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"0018f1ff115835b9bef28aa0d1a63c61\",\n",
      "    \"text\": \"(cid:17)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            303.28400000000005,\n",
      "            559.7389599999992\n",
      "          ],\n",
      "          [\n",
      "            303.28400000000005,\n",
      "            569.7015599999993\n",
      "          ],\n",
      "          [\n",
      "            309.23366472000004,\n",
      "            569.7015599999993\n",
      "          ],\n",
      "          [\n",
      "            309.23366472000004,\n",
      "            559.7389599999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 6,\n",
      "      \"parent_id\": \"32fd259ca815a900a57b9e076e640622\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"941b2a884f778df4120cb610dc5d2d7c\",\n",
      "    \"text\": \"= log P\\u03b8 (cid:16)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            312.00200000000007,\n",
      "            566.7531443999992\n",
      "          ],\n",
      "          [\n",
      "            312.00200000000007,\n",
      "            591.6195599999993\n",
      "          ],\n",
      "          [\n",
      "            351.86166472,\n",
      "            591.6195599999993\n",
      "          ],\n",
      "          [\n",
      "            351.86166472,\n",
      "            566.7531443999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 6,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"e03d2e699c8662c9dbd4991455c5a3d2\",\n",
      "    \"text\": \"\\u2212 log P\\u03b8\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            308.472,\n",
      "            588.6711443999993\n",
      "          ],\n",
      "          [\n",
      "            308.472,\n",
      "            599.5479171999992\n",
      "          ],\n",
      "          [\n",
      "            343.53844458000003,\n",
      "            599.5479171999992\n",
      "          ],\n",
      "          [\n",
      "            343.53844458000003,\n",
      "            588.6711443999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 6,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"6217e48b00f8855de60b3fb49efd470e\",\n",
      "    \"text\": \"(cid:16)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            349.994,\n",
      "            559.7389599999992\n",
      "          ],\n",
      "          [\n",
      "            349.994,\n",
      "            569.7015599999993\n",
      "          ],\n",
      "          [\n",
      "            355.94366472,\n",
      "            569.7015599999993\n",
      "          ],\n",
      "          [\n",
      "            355.94366472,\n",
      "            559.7389599999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 6,\n",
      "      \"parent_id\": \"e03d2e699c8662c9dbd4991455c5a3d2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"01589fe0fe4c177e830302a3bf2d66c0\",\n",
      "    \"text\": \"\\u03f5t | zt+1, \\u02c6h0\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            355.944,\n",
      "            564.1241443999993\n",
      "          ],\n",
      "          [\n",
      "            355.944,\n",
      "            577.6299171999992\n",
      "          ],\n",
      "          [\n",
      "            404.16557909999995,\n",
      "            577.6299171999992\n",
      "          ],\n",
      "          [\n",
      "            404.16557909999995,\n",
      "            564.1241443999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 6,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"5c09aa0e9850db129929a7b5f62a0f7c\",\n",
      "    \"text\": \"\\u03f5t | zt+1, \\u02c6h0\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            351.862,\n",
      "            586.0421443999993\n",
      "          ],\n",
      "          [\n",
      "            351.862,\n",
      "            599.5479171999992\n",
      "          ],\n",
      "          [\n",
      "            400.0825791,\n",
      "            599.5479171999992\n",
      "          ],\n",
      "          [\n",
      "            400.0825791,\n",
      "            586.0421443999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 6,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"c41e1a65839755a60d4b928a8a29f913\",\n",
      "    \"text\": \"(cid:17)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            404.66299999999995,\n",
      "            559.7389599999992\n",
      "          ],\n",
      "          [\n",
      "            404.66299999999995,\n",
      "            569.7015599999993\n",
      "          ],\n",
      "          [\n",
      "            410.61266471999994,\n",
      "            569.7015599999993\n",
      "          ],\n",
      "          [\n",
      "            410.61266471999994,\n",
      "            559.7389599999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 6,\n",
      "      \"parent_id\": \"5c09aa0e9850db129929a7b5f62a0f7c\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"2f954424e3c0c1fada844aee72b60b2e\",\n",
      "    \"text\": \"(cid:17)(cid:17)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            400.58,\n",
      "            581.6569599999992\n",
      "          ],\n",
      "          [\n",
      "            400.58,\n",
      "            591.6195599999993\n",
      "          ],\n",
      "          [\n",
      "            412.47932943999996,\n",
      "            591.6195599999993\n",
      "          ],\n",
      "          [\n",
      "            412.47932943999996,\n",
      "            581.6569599999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 6,\n",
      "      \"parent_id\": \"5c09aa0e9850db129929a7b5f62a0f7c\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"3ed85bc73fdf7d338bb31fecf7141af4\",\n",
      "    \"text\": \"+\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            412.27399999999994,\n",
      "            566.7531443999992\n",
      "          ],\n",
      "          [\n",
      "            412.27399999999994,\n",
      "            576.7157443999993\n",
      "          ],\n",
      "          [\n",
      "            420.02291027999996,\n",
      "            576.7157443999993\n",
      "          ],\n",
      "          [\n",
      "            420.02291027999996,\n",
      "            566.7531443999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 6,\n",
      "      \"parent_id\": \"5c09aa0e9850db129929a7b5f62a0f7c\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"11b0d90d2a7d362bc8b6909e17c72143\",\n",
      "    \"text\": \"4 EXPERIMENTS\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.29900000000004,\n",
      "            619.2701231999993\n",
      "          ],\n",
      "          [\n",
      "            108.29900000000004,\n",
      "            631.2253231999993\n",
      "          ],\n",
      "          [\n",
      "            200.08349530000004,\n",
      "            631.2253231999993\n",
      "          ],\n",
      "          [\n",
      "            200.08349530000004,\n",
      "            619.2701231999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 6,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"6be44ec9d071e6aeacaa102c9acc65d6\",\n",
      "    \"text\": \"To assess the efficacy of our model, we conducted a series of evaluations across multiple bench- marks. These experiments aim to address several key questions: (1) Can our model generate plausi- ble images and reasonable texts? (2) How does our model compare with state-of-the-art models in both single-turn and multi-turn interleaved vision-and-language generation tasks? (3) What impact does the design of each module have on overall performance? Below we will discuss the experimen- tal setup and present a comprehensive analysis of our model\\u2019s performance. We use three datasets: CC3M (Sharma et al., 2018), VIST (Huang et al., 2016), and MMDialog (Feng et al., 2022). More details about datasets and data format can be found in Appendix B.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            645.3393215999993\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            732.0139215999993\n",
      "          ],\n",
      "          [\n",
      "            504.0042698,\n",
      "            732.0139215999993\n",
      "          ],\n",
      "          [\n",
      "            504.0042698,\n",
      "            645.3393215999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Sharmaetal .,\",\n",
      "          \"url\": \"cite.sharma2018conceptual\",\n",
      "          \"start_index\": 589\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2018\",\n",
      "          \"url\": \"cite.sharma2018conceptual\",\n",
      "          \"start_index\": 604\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Huangetal .,\",\n",
      "          \"url\": \"cite.huang2016visual\",\n",
      "          \"start_index\": 617\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2016\",\n",
      "          \"url\": \"cite.huang2016visual\",\n",
      "          \"start_index\": 631\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Fengetal .,\",\n",
      "          \"url\": \"cite.feng2022mmdialog\",\n",
      "          \"start_index\": 652\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022\",\n",
      "          \"url\": \"cite.feng2022mmdialog\",\n",
      "          \"start_index\": 665\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"sperformance . Weusethreedatasets CC3M ( Sharmaetal ., 2018 ), VIST ( Huangetal ., 2016 ), andMMDialog ( Fengetal ., 2022 ). detailsaboutdatasetsanddataformatcanbefoundinAppendixB\",\n",
      "          \"url\": \"appendix.B\",\n",
      "          \"start_index\": 545\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 6,\n",
      "      \"parent_id\": \"11b0d90d2a7d362bc8b6909e17c72143\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Footer\",\n",
      "    \"element_id\": \"1b2a05a9cbb889521972ff94b258ff50\",\n",
      "    \"text\": \"6\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            303.509,\n",
      "            751.9393215999993\n",
      "          ],\n",
      "          [\n",
      "            303.509,\n",
      "            761.9019215999992\n",
      "          ],\n",
      "          [\n",
      "            308.4903,\n",
      "            761.9019215999992\n",
      "          ],\n",
      "          [\n",
      "            308.4903,\n",
      "            751.9393215999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 6,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"a22771e05280e9f5c7d221b1949b7e3f\",\n",
      "    \"text\": \"(4)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            492.384,\n",
      "            264.22032159999924\n",
      "          ],\n",
      "          [\n",
      "            492.384,\n",
      "            274.1829215999993\n",
      "          ],\n",
      "          [\n",
      "            504.0003916,\n",
      "            274.1829215999993\n",
      "          ],\n",
      "          [\n",
      "            504.0003916,\n",
      "            264.22032159999924\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 6,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"72fcd1109c8446bc75e9f5300b6f03a4\",\n",
      "    \"text\": \"(5)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            492.384,\n",
      "            577.9313215999993\n",
      "          ],\n",
      "          [\n",
      "            492.384,\n",
      "            587.8939215999992\n",
      "          ],\n",
      "          [\n",
      "            504.0003916,\n",
      "            587.8939215999992\n",
      "          ],\n",
      "          [\n",
      "            504.0003916,\n",
      "            577.9313215999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 6,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"c545d6a47d75f09b671aa2521537e396\",\n",
      "    \"text\": \"Table 1: Image generation on VIST. Given the historical context, models need to generate im- ages for each step. FID scores evaluate the vi- sual diversities between generated and ground truth images within each story sequence.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.72232159999999\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            135.52092159999984\n",
      "          ],\n",
      "          [\n",
      "            298.0764454000001,\n",
      "            135.52092159999984\n",
      "          ],\n",
      "          [\n",
      "            298.0764454000001,\n",
      "            81.72232159999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 7,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"32318823d23bf49d62ba031c6100a890\",\n",
      "    \"text\": \"Model\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            113.27492742,\n",
      "            149.7326166503359\n",
      "          ],\n",
      "          [\n",
      "            113.27492742,\n",
      "            157.64447834633597\n",
      "          ],\n",
      "          [\n",
      "            133.932798308256,\n",
      "            157.64447834633597\n",
      "          ],\n",
      "          [\n",
      "            133.932798308256,\n",
      "            149.7326166503359\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 7,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"3444b25eb066b267173fcfac778d795b\",\n",
      "    \"text\": \"CLIP-I (\\u2191)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            224.468231695584,\n",
      "            149.558555693024\n",
      "          ],\n",
      "          [\n",
      "            224.468231695584,\n",
      "            157.64447834633597\n",
      "          ],\n",
      "          [\n",
      "            258.196729644768,\n",
      "            157.64447834633597\n",
      "          ],\n",
      "          [\n",
      "            258.196729644768,\n",
      "            149.558555693024\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 7,\n",
      "      \"parent_id\": \"32318823d23bf49d62ba031c6100a890\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"723dfbb9ab8c6fc304ec919476950f3e\",\n",
      "    \"text\": \"FID (\\u2193)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            268.74324128553604,\n",
      "            149.558555693024\n",
      "          ],\n",
      "          [\n",
      "            268.74324128553604,\n",
      "            157.64447834633597\n",
      "          ],\n",
      "          [\n",
      "            292.80494783476803,\n",
      "            157.64447834633597\n",
      "          ],\n",
      "          [\n",
      "            292.80494783476803,\n",
      "            149.558555693024\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 7,\n",
      "      \"parent_id\": \"32318823d23bf49d62ba031c6100a890\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"918746bfd3779e9e23e224e0045cfd7b\",\n",
      "    \"text\": \"Table 2: Narration Generation on VIST. We added LoRA fine-tuning for GILL, MiniGPT- 4, and MiniGPT-5 with the same LoRA config- uration. The results show that adding genera- tive vokens does not hurt the performance on the multimodal comprehension tasks.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            313.922,\n",
      "            95.12332159999994\n",
      "          ],\n",
      "          [\n",
      "            313.922,\n",
      "            159.87992159999976\n",
      "          ],\n",
      "          [\n",
      "            503.99844540000015,\n",
      "            159.87992159999976\n",
      "          ],\n",
      "          [\n",
      "            503.99844540000015,\n",
      "            95.12332159999994\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 7,\n",
      "      \"parent_id\": \"32318823d23bf49d62ba031c6100a890\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"5004e15d35e1b020bd95456683c6b2c7\",\n",
      "    \"text\": \"SD 2.1 (Rombach et al., 2022b) Fine-tuned SD 2.1 Two-stage Baseline GILL (Koh et al., 2023) MiniGPT-5 (Prefix Tuning) MiniGPT-5 (LoRA)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            113.27492742,\n",
      "            162.93758300033596\n",
      "          ],\n",
      "          [\n",
      "            113.27492742,\n",
      "            214.80393776633593\n",
      "          ],\n",
      "          [\n",
      "            213.921720054816,\n",
      "            214.80393776633593\n",
      "          ],\n",
      "          [\n",
      "            213.921720054816,\n",
      "            162.93758300033596\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Rombachetal .,\",\n",
      "          \"url\": \"cite.rombach2021highresolution\",\n",
      "          \"start_index\": 8\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022b\",\n",
      "          \"url\": \"cite.rombach2021highresolution\",\n",
      "          \"start_index\": 24\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Kohetal .,\",\n",
      "          \"url\": \"cite.koh2023generating\",\n",
      "          \"start_index\": 74\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.koh2023generating\",\n",
      "          \"start_index\": 86\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 7,\n",
      "      \"parent_id\": \"32318823d23bf49d62ba031c6100a890\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"95297423bf33ef64e31e9037c8c2ca5b\",\n",
      "    \"text\": \"0.59 0.61 0.57 0.60 0.65 0.66\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            234.41030901,\n",
      "            162.93758300033596\n",
      "          ],\n",
      "          [\n",
      "            234.41030901,\n",
      "            214.74855473446394\n",
      "          ],\n",
      "          [\n",
      "            248.25919981545607,\n",
      "            214.74855473446394\n",
      "          ],\n",
      "          [\n",
      "            248.25919981545607,\n",
      "            162.93758300033596\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 7,\n",
      "      \"parent_id\": \"32318823d23bf49d62ba031c6100a890\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"5f83acdc3a5dba744466fb1f5ec0b194\",\n",
      "    \"text\": \"393.49 390.25 403.06 381.88 381.55 366.62\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            269.89500871656,\n",
      "            162.93758300033596\n",
      "          ],\n",
      "          [\n",
      "            269.89500871656,\n",
      "            214.74855473446394\n",
      "          ],\n",
      "          [\n",
      "            291.6557612180161,\n",
      "            214.74855473446394\n",
      "          ],\n",
      "          [\n",
      "            291.6557612180161,\n",
      "            162.93758300033596\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 7,\n",
      "      \"parent_id\": \"32318823d23bf49d62ba031c6100a890\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"d29e7569184e25fb89c72be0377bdc5c\",\n",
      "    \"text\": \"Model\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            317.97771432,\n",
      "            173.37312557785606\n",
      "          ],\n",
      "          [\n",
      "            317.97771432,\n",
      "            179.4562899938561\n",
      "          ],\n",
      "          [\n",
      "            333.86085661017603,\n",
      "            179.4562899938561\n",
      "          ],\n",
      "          [\n",
      "            333.86085661017603,\n",
      "            173.37312557785606\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 7,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"8da442c83ecdc52830652db2c6816703\",\n",
      "    \"text\": \"GILL (Koh et al., 2023) MiniGPT-4 (Zhu et al., 2023) MiniGPT-5\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            317.97703588,\n",
      "            183.525301737856\n",
      "          ],\n",
      "          [\n",
      "            317.97703588,\n",
      "            203.12706159385596\n",
      "          ],\n",
      "          [\n",
      "            389.734721771136,\n",
      "            203.12706159385596\n",
      "          ],\n",
      "          [\n",
      "            389.734721771136,\n",
      "            183.525301737856\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Zhuetal .,\",\n",
      "          \"url\": \"cite.zhu2023minigpt\",\n",
      "          \"start_index\": 35\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.zhu2023minigpt\",\n",
      "          \"start_index\": 47\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 7,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"5f5a6a0f309e90a6965769445f3d893a\",\n",
      "    \"text\": \"S-BERT (\\u2191) Rouge-L (\\u2191) Meteor (\\u2191)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            397.843579937664,\n",
      "            173.2392959607041\n",
      "          ],\n",
      "          [\n",
      "            397.843579937664,\n",
      "            179.4562899938561\n",
      "          ],\n",
      "          [\n",
      "            499.94537083052796,\n",
      "            179.4562899938561\n",
      "          ],\n",
      "          [\n",
      "            499.94537083052796,\n",
      "            173.2392959607041\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 7,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"02bf3bf1d655aca80c0e95553fde7230\",\n",
      "    \"text\": \"0.3864 0.6273 0.6315\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            404.12466864,\n",
      "            183.525301737856\n",
      "          ],\n",
      "          [\n",
      "            404.12466864,\n",
      "            203.08447944294392\n",
      "          ],\n",
      "          [\n",
      "            420.8561909233921,\n",
      "            203.08447944294392\n",
      "          ],\n",
      "          [\n",
      "            420.8561909233921,\n",
      "            183.525301737856\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 7,\n",
      "      \"parent_id\": \"5f5a6a0f309e90a6965769445f3d893a\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"2176f067a6c2418eb7fb5a3ac69aef57\",\n",
      "    \"text\": \"0.1784 0.3401 0.3373\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            442.0420018,\n",
      "            183.525301737856\n",
      "          ],\n",
      "          [\n",
      "            442.0420018,\n",
      "            203.12706159385596\n",
      "          ],\n",
      "          [\n",
      "            458.7725547283201,\n",
      "            203.12706159385596\n",
      "          ],\n",
      "          [\n",
      "            458.7725547283201,\n",
      "            183.525301737856\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 7,\n",
      "      \"parent_id\": \"5f5a6a0f309e90a6965769445f3d893a\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"2923c0d9dbe1b4f7f3809cca12d4ac2b\",\n",
      "    \"text\": \"0.1951 0.3296 0.3263\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            478.4455084496641,\n",
      "            183.525301737856\n",
      "          ],\n",
      "          [\n",
      "            478.4455084496641,\n",
      "            203.12706159385596\n",
      "          ],\n",
      "          [\n",
      "            495.17844297376,\n",
      "            203.12706159385596\n",
      "          ],\n",
      "          [\n",
      "            495.17844297376,\n",
      "            183.525301737856\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 7,\n",
      "      \"parent_id\": \"5f5a6a0f309e90a6965769445f3d893a\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"6f1acdddd2114ae14675329bf26c60fc\",\n",
      "    \"text\": \"4.1 EXPERIMENTAL SETUP\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.249,\n",
      "            239.21632160000001\n",
      "          ],\n",
      "          [\n",
      "            108.249,\n",
      "            249.17892160000008\n",
      "          ],\n",
      "          [\n",
      "            229.5727185,\n",
      "            249.17892160000008\n",
      "          ],\n",
      "          [\n",
      "            229.5727185,\n",
      "            239.21632160000001\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 7,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"481721762bbe7446904de6d668cdfd0f\",\n",
      "    \"text\": \"Baselines For a comprehensive evaluation of our performance in multimodal generation, we con- the Fine-tuned Unimodal ducted comparative analyses with several prominent baseline models: Generation Models, Two-stage Baseline, GILL, and Divter.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            264.1525834\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            296.1029216\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            296.1029216\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            264.1525834\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 7,\n",
      "      \"parent_id\": \"6f1acdddd2114ae14675329bf26c60fc\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"3d1c98b1c6170789f79e92b6a37f12d8\",\n",
      "    \"text\": \"Fine-tuned Unimodal Generation Models: To facilitate fair comparisons in both image and text generation, we fine-tuned two separate models, Stable Diffusion 2.1 and MiniGPT- 4 (Zhu et al., 2023), utilizing the VIST dataset. Within the Stable Diffusion 2.1 (Rombach et al., 2022b) model, the U-Net parameters were fine-tuned. For MiniGPT-4\\u2019s LLM part, LoRA parameters were fine-tuned.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            135.397,\n",
      "            306.85858340000004\n",
      "          ],\n",
      "          [\n",
      "            135.397,\n",
      "            360.7269216\n",
      "          ],\n",
      "          [\n",
      "            504.00402739999987,\n",
      "            360.7269216\n",
      "          ],\n",
      "          [\n",
      "            504.00402739999987,\n",
      "            306.85858340000004\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Zhuetal .,\",\n",
      "          \"url\": \"cite.zhu2023minigpt\",\n",
      "          \"start_index\": 178\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.zhu2023minigpt\",\n",
      "          \"start_index\": 190\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"( etal ., 2022b ) model , theU - Netparameterswerefine - tuned . ForMiniGPT - 4 \\u2019 sLLMpart\",\n",
      "          \"url\": \"cite.rombach2021highresolution\",\n",
      "          \"start_index\": 257\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"etal .,\",\n",
      "          \"url\": \"cite.rombach2021highresolution\",\n",
      "          \"start_index\": 266\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022b\",\n",
      "          \"url\": \"cite.rombach2021highresolution\",\n",
      "          \"start_index\": 274\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 7,\n",
      "      \"parent_id\": \"6f1acdddd2114ae14675329bf26c60fc\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"1cfab46f68e3d29a5bf3eadcadc59754\",\n",
      "    \"text\": \"Two-stage Baseline: A common approach in multimodal generation involves first employ- ing Large Language Models (LLMs) to create image captions, which are then fed into text-to-image models for image generation (Wu et al., 2023b). We create such a two-stage baseline for comparison with our end-to-end method by fine-tuning MiniGPT-4 for caption generation and Stable Diffusion 2.1 for text-to-image generation. Given the absence of image descriptions in the VIST dataset, we incorporate a SOTA image captioning model, InstructBLIP-13B (Dai et al., 2023), to generate synthetic captions for supervision.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            135.39700000000002,\n",
      "            365.1865834000001\n",
      "          ],\n",
      "          [\n",
      "            135.39700000000002,\n",
      "            440.9719216000001\n",
      "          ],\n",
      "          [\n",
      "            504.00402740000004,\n",
      "            440.9719216000001\n",
      "          ],\n",
      "          [\n",
      "            504.00402740000004,\n",
      "            365.1865834000001\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Wuetal .,\",\n",
      "          \"url\": \"cite.wu2023visual\",\n",
      "          \"start_index\": 213\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023b\",\n",
      "          \"url\": \"cite.wu2023visual\",\n",
      "          \"start_index\": 224\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Daietal .,\",\n",
      "          \"url\": \"cite.instructblip\",\n",
      "          \"start_index\": 537\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.instructblip\",\n",
      "          \"start_index\": 549\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 7,\n",
      "      \"parent_id\": \"6f1acdddd2114ae14675329bf26c60fc\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"001b97f395376eea7234f510f32e4ab9\",\n",
      "    \"text\": \"GILL1 (Koh et al., 2023): GILL is a recent innovation that allows the LLM to generate vokens using a pre-trained text-to-image generation model for single-image generation, where GILL minimizes the Mean Squared Error (MSE) loss between the text-to-image text encoding feature and voken features, similar to LCAP in our approach. For fine-tuning on multimodal datasets, since GILL requires image captions for training, we use Descriptions of Images-in-Isolation (DII) (Huang et al., 2016) in the VIST fine-tuning and generate captions for MMDialog fine-tuning. Contrarily, MiniGPT-5 does not related on all caption data during multimodal generation fine-tuning.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            135.39700000000005,\n",
      "            444.2295408000001\n",
      "          ],\n",
      "          [\n",
      "            135.39700000000005,\n",
      "            532.1769216000001\n",
      "          ],\n",
      "          [\n",
      "            504.0040274,\n",
      "            532.1769216000001\n",
      "          ],\n",
      "          [\n",
      "            504.0040274,\n",
      "            444.2295408000001\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"(\",\n",
      "          \"url\": \"Hfootnote.1\",\n",
      "          \"start_index\": 8\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Kohetal .,\",\n",
      "          \"url\": \"cite.koh2023generating\",\n",
      "          \"start_index\": 9\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.koh2023generating\",\n",
      "          \"start_index\": 21\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Huangetal .,\",\n",
      "          \"url\": \"cite.huang2016visual\",\n",
      "          \"start_index\": 469\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2016\",\n",
      "          \"url\": \"cite.huang2016visual\",\n",
      "          \"start_index\": 483\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 7,\n",
      "      \"parent_id\": \"6f1acdddd2114ae14675329bf26c60fc\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"ff01c3948b3895ba1bf4850fa539219d\",\n",
      "    \"text\": \"Divter (Sun et al., 2021): Divter is a state-of-the-art conversational agent developed for multimodal dialogue contexts. It introduces a customized transformer structure for gener- ating multimodal responses. Divter\\u2019s methodology includes pretraining on a vast corpus of text-only dialogues and text-image pairs, followed by fine-tuning on a selected set of multimodal response data. The MMDialog dataset regards Divter\\u2019s method as the baseline.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            135.397,\n",
      "            536.6365834000002\n",
      "          ],\n",
      "          [\n",
      "            135.397,\n",
      "            590.5049216000002\n",
      "          ],\n",
      "          [\n",
      "            504.0040274,\n",
      "            590.5049216000002\n",
      "          ],\n",
      "          [\n",
      "            504.0040274,\n",
      "            536.6365834000002\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Sunetal .,\",\n",
      "          \"url\": \"cite.sun2021multimodal\",\n",
      "          \"start_index\": 10\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.sun2021multimodal\",\n",
      "          \"start_index\": 22\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 7,\n",
      "      \"parent_id\": \"6f1acdddd2114ae14675329bf26c60fc\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"437fff7b09998ebcf3e1c1e9841675b0\",\n",
      "    \"text\": \"Metrics To comprehensively assess the model performance across image, text, and multimodal dimensions, we employ a diverse set of metrics. For evaluating the quality and diversity of generated images, we utilize the Inception Score (IS) (Salimans et al., 2016), and Fr\\u00b4echet Inception Distance (FID) (Heusel et al., 2017). Textual performance is gauged through metrics such as BLEU (Papineni et al., 2002), Rouge-L (Lin, 2004), METEOR (Banerjee & Lavie, 2005), and Sentence-BERT (S- BERT) (Reimers & Gurevych, 2019) scores.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999999,\n",
      "            601.2605834000002\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999999,\n",
      "            666.0879216000002\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999995,\n",
      "            666.0879216000002\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999995,\n",
      "            601.2605834000002\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Salimansetal .,\",\n",
      "          \"url\": \"cite.salimans2016improved\",\n",
      "          \"start_index\": 238\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2016\",\n",
      "          \"url\": \"cite.salimans2016improved\",\n",
      "          \"start_index\": 255\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Heuseletal .,\",\n",
      "          \"url\": \"cite.heusel2017gans\",\n",
      "          \"start_index\": 301\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2017\",\n",
      "          \"url\": \"cite.heusel2017gans\",\n",
      "          \"start_index\": 316\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"( etal ., 2002 ), Rouge - L ( Lin , 2004 ), METEOR ( Banerjee & Lavie , 2005 ), andSentence - BERT ( S\",\n",
      "          \"url\": \"cite.papineni2002bleu\",\n",
      "          \"start_index\": 382\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"etal .,\",\n",
      "          \"url\": \"cite.papineni2002bleu\",\n",
      "          \"start_index\": 392\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2002\",\n",
      "          \"url\": \"cite.papineni2002bleu\",\n",
      "          \"start_index\": 400\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Lin\",\n",
      "          \"url\": \"cite.lin2004rouge\",\n",
      "          \"start_index\": 416\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2004\",\n",
      "          \"url\": \"cite.lin2004rouge\",\n",
      "          \"start_index\": 421\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Banerjee & Lavie\",\n",
      "          \"url\": \"cite.banerjee2005meteor\",\n",
      "          \"start_index\": 436\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2005\",\n",
      "          \"url\": \"cite.banerjee2005meteor\",\n",
      "          \"start_index\": 454\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Reimers & Gurevych\",\n",
      "          \"url\": \"cite.reimers2019sentence\",\n",
      "          \"start_index\": 490\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2019\",\n",
      "          \"url\": \"cite.reimers2019sentence\",\n",
      "          \"start_index\": 510\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 7,\n",
      "      \"parent_id\": \"6f1acdddd2114ae14675329bf26c60fc\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"c98b57cb92060a6860b55ae080976e76\",\n",
      "    \"text\": \"From the multimodal perspective, we leverage CLIP-based metrics (Rombach et al., 2022b) to assess the similarities between generated content and ground truth. CLIP-I evaluates the similarity between\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000006,\n",
      "            673.0613216000002\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000006,\n",
      "            693.9829216000002\n",
      "          ],\n",
      "          [\n",
      "            504.0033874,\n",
      "            693.9829216000002\n",
      "          ],\n",
      "          [\n",
      "            504.0033874,\n",
      "            673.0613216000002\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Rombachetal .,\",\n",
      "          \"url\": \"cite.rombach2021highresolution\",\n",
      "          \"start_index\": 65\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022b\",\n",
      "          \"url\": \"cite.rombach2021highresolution\",\n",
      "          \"start_index\": 81\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 7,\n",
      "      \"parent_id\": \"6f1acdddd2114ae14675329bf26c60fc\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"bda1386dab6d254b3b4152d558f43d60\",\n",
      "    \"text\": \"1Given the variations in the valid data within the CC3M dataset, we made adjustments to ensure fair com- parisons. Specifically, we retrained it on our specific CC3M data, following the guidelines in their official implementation (https://github.com/kohjingyu/gill).\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000001,\n",
      "            701.4405616\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000001,\n",
      "            731.7987424\n",
      "          ],\n",
      "          [\n",
      "            504.0010559999999,\n",
      "            731.7987424\n",
      "          ],\n",
      "          [\n",
      "            504.0010559999999,\n",
      "            701.4405616\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 7,\n",
      "      \"parent_id\": \"6f1acdddd2114ae14675329bf26c60fc\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Footer\",\n",
      "    \"element_id\": \"b27174cfbef8ed13de34b0b4fa42e394\",\n",
      "    \"text\": \"7\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            303.509,\n",
      "            751.9393216\n",
      "          ],\n",
      "          [\n",
      "            303.509,\n",
      "            761.9019216\n",
      "          ],\n",
      "          [\n",
      "            308.4903,\n",
      "            761.9019216\n",
      "          ],\n",
      "          [\n",
      "            308.4903,\n",
      "            751.9393216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 7,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"419c3e6b5ac26f7815621ba6c21d0f59\",\n",
      "    \"text\": \"Table 3: Multimodal Story Generation. VIST Human Evaluation on 5,000 samples comparing MiniGPT-5 with both Two-stage Baseline and GILL, across Language Continuity, Image Quality, and Multimodal Coherence aspects. The results highlight the superiority of MiniGPT-5 in more than half cases.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.72232159999999\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            124.56192159999989\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            124.56192159999989\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            81.72232159999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 8,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"93d34060b8eaf2005e99298027a220fc\",\n",
      "    \"text\": \"Two-Stage Baseline\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            263.41484408,\n",
      "            138.70822484595203\n",
      "          ],\n",
      "          [\n",
      "            263.41484408,\n",
      "            147.52233631795207\n",
      "          ],\n",
      "          [\n",
      "            333.85722296422404,\n",
      "            147.52233631795207\n",
      "          ],\n",
      "          [\n",
      "            333.85722296422404,\n",
      "            138.70822484595203\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 8,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"5f1c4a54c7b80bb919fed8fc4605314c\",\n",
      "    \"text\": \"GILL (Koh et al., 2023)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            378.685793910816,\n",
      "            138.70822484595203\n",
      "          ],\n",
      "          [\n",
      "            378.685793910816,\n",
      "            147.52233631795207\n",
      "          ],\n",
      "          [\n",
      "            463.07209714374403,\n",
      "            147.52233631795207\n",
      "          ],\n",
      "          [\n",
      "            463.07209714374403,\n",
      "            138.70822484595203\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 8,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"3d0465478ccf8cd7eac852cfc1bb2913\",\n",
      "    \"text\": \"Model\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            135.28880895999998,\n",
      "            152.65318148595202\n",
      "          ],\n",
      "          [\n",
      "            135.28880895999998,\n",
      "            161.46729295795205\n",
      "          ],\n",
      "          [\n",
      "            158.30245401339198,\n",
      "            161.46729295795205\n",
      "          ],\n",
      "          [\n",
      "            158.30245401339198,\n",
      "            152.65318148595202\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 8,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"b0d5f34775480fdd2b5609167792eb12\",\n",
      "    \"text\": \"MiniGPT-5 Baseline\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            242.803340695456,\n",
      "            152.65318148595202\n",
      "          ],\n",
      "          [\n",
      "            242.803340695456,\n",
      "            161.46729295795205\n",
      "          ],\n",
      "          [\n",
      "            324.0606343558241,\n",
      "            161.46729295795205\n",
      "          ],\n",
      "          [\n",
      "            324.0606343558241,\n",
      "            152.65318148595202\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 8,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"e0f451f1f0bd348ccf49322bd3dc586d\",\n",
      "    \"text\": \"Tie MiniGPT-5 Baseline\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            338.83308518289607,\n",
      "            152.65318148595202\n",
      "          ],\n",
      "          [\n",
      "            338.83308518289607,\n",
      "            161.46729295795205\n",
      "          ],\n",
      "          [\n",
      "            446.3035463609919,\n",
      "            161.46729295795205\n",
      "          ],\n",
      "          [\n",
      "            446.3035463609919,\n",
      "            152.65318148595202\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 8,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"af4b0dadda101f601bc5ce7de1e38f37\",\n",
      "    \"text\": \"Tie\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            461.0759971880639,\n",
      "            152.65318148595202\n",
      "          ],\n",
      "          [\n",
      "            461.0759971880639,\n",
      "            161.46729295795205\n",
      "          ],\n",
      "          [\n",
      "            472.5167138787199,\n",
      "            161.46729295795205\n",
      "          ],\n",
      "          [\n",
      "            472.5167138787199,\n",
      "            152.65318148595202\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 8,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"a240a4c5eee2ea57cf817198a7dfea90\",\n",
      "    \"text\": \"Language Continuity (%) Image Quality (%) Multimodal Coherence (%)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            135.28880895999998,\n",
      "            166.774197405952\n",
      "          ],\n",
      "          [\n",
      "            135.28880895999998,\n",
      "            194.97960183795203\n",
      "          ],\n",
      "          [\n",
      "            232.226406929056,\n",
      "            194.97960183795203\n",
      "          ],\n",
      "          [\n",
      "            232.226406929056,\n",
      "            166.774197405952\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 8,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"0aa67b580cb2f7f03c2a799686edeb46\",\n",
      "    \"text\": \"55.22 52.43 56.90\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            253.04946456,\n",
      "            166.71249862564798\n",
      "          ],\n",
      "          [\n",
      "            253.04946456,\n",
      "            194.917903057648\n",
      "          ],\n",
      "          [\n",
      "            272.881215372,\n",
      "            194.917903057648\n",
      "          ],\n",
      "          [\n",
      "            272.881215372,\n",
      "            166.71249862564798\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 8,\n",
      "      \"parent_id\": \"a240a4c5eee2ea57cf817198a7dfea90\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"87fe125fa7617894065b2e1d32889afb\",\n",
      "    \"text\": \"34.89 37.79 28.88\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            298.96643256,\n",
      "            166.774197405952\n",
      "          ],\n",
      "          [\n",
      "            298.96643256,\n",
      "            194.97960183795203\n",
      "          ],\n",
      "          [\n",
      "            318.798183372,\n",
      "            194.97960183795203\n",
      "          ],\n",
      "          [\n",
      "            318.798183372,\n",
      "            166.774197405952\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 8,\n",
      "      \"parent_id\": \"a240a4c5eee2ea57cf817198a7dfea90\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"dc31eed0154dcfd55013b711824dd03c\",\n",
      "    \"text\": \"9.89 9.78 14.22\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            334.637141687184,\n",
      "            166.774197405952\n",
      "          ],\n",
      "          [\n",
      "            334.637141687184,\n",
      "            194.97960183795203\n",
      "          ],\n",
      "          [\n",
      "            354.468892499184,\n",
      "            194.97960183795203\n",
      "          ],\n",
      "          [\n",
      "            354.468892499184,\n",
      "            166.774197405952\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 8,\n",
      "      \"parent_id\": \"a240a4c5eee2ea57cf817198a7dfea90\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"547ec4e5e85520535ba84c231792882b\",\n",
      "    \"text\": \"54.18 54.25 55.32\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            375.29211168,\n",
      "            166.71249862564798\n",
      "          ],\n",
      "          [\n",
      "            375.29211168,\n",
      "            194.917903057648\n",
      "          ],\n",
      "          [\n",
      "            395.123862492,\n",
      "            194.917903057648\n",
      "          ],\n",
      "          [\n",
      "            395.123862492,\n",
      "            166.71249862564798\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 8,\n",
      "      \"parent_id\": \"a240a4c5eee2ea57cf817198a7dfea90\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"7b233e9e1a87f5abcfec6440222753d7\",\n",
      "    \"text\": \"35.31 35.41 30.34\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            421.20819496,\n",
      "            166.774197405952\n",
      "          ],\n",
      "          [\n",
      "            421.20819496,\n",
      "            194.97960183795203\n",
      "          ],\n",
      "          [\n",
      "            441.039945772,\n",
      "            194.97960183795203\n",
      "          ],\n",
      "          [\n",
      "            441.039945772,\n",
      "            166.774197405952\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 8,\n",
      "      \"parent_id\": \"a240a4c5eee2ea57cf817198a7dfea90\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"060c41fe0e84cca59086ca23f8c02b85\",\n",
      "    \"text\": \"10.51 10.34 14.33\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            456.878904087184,\n",
      "            166.774197405952\n",
      "          ],\n",
      "          [\n",
      "            456.878904087184,\n",
      "            194.97960183795203\n",
      "          ],\n",
      "          [\n",
      "            476.710654899184,\n",
      "            194.97960183795203\n",
      "          ],\n",
      "          [\n",
      "            476.710654899184,\n",
      "            166.774197405952\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 8,\n",
      "      \"parent_id\": \"a240a4c5eee2ea57cf817198a7dfea90\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"7b1d2d38a77a1dfcb6a520307aa13291\",\n",
      "    \"text\": \"generated and ground-truth image features. To address potential misalignments in the multimodal generation, such as when the ground truth is text-only, but the output is multimodal, we utilize MM-Relevance (Feng et al., 2022). This metric calculates the F1 score based on CLIP similarities, providing a nuanced evaluation of multimodal coherence.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            221.2313216\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            264.0709215999999\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999984,\n",
      "            264.0709215999999\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999984,\n",
      "            221.2313216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Fengetal .,\",\n",
      "          \"url\": \"cite.feng2022mmdialog\",\n",
      "          \"start_index\": 207\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022\",\n",
      "          \"url\": \"cite.feng2022mmdialog\",\n",
      "          \"start_index\": 220\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 8,\n",
      "      \"parent_id\": \"a240a4c5eee2ea57cf817198a7dfea90\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"29b3619d61a47d64f579e8a5c325422f\",\n",
      "    \"text\": \"Recognizing that the generated multimodal output might be meaningful yet differ from the ground truth, we also incorporate human evaluation to assess the model\\u2019s performance. We examine the model\\u2019s effectiveness from three perspectives: (1) Language Continuity: assessing if the produced text aligns seamlessly with the provided context; (2) Image Quality: evaluating the clarity and rel- evance of the generated image; and (3) Multimodal Coherence: determining if the combined text- image output is consistent with the initial context.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            271.04532159999985\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            335.8019215999999\n",
      "          ],\n",
      "          [\n",
      "            504.0033874,\n",
      "            335.8019215999999\n",
      "          ],\n",
      "          [\n",
      "            504.0033874,\n",
      "            271.04532159999985\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 8,\n",
      "      \"parent_id\": \"a240a4c5eee2ea57cf817198a7dfea90\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"982be95acb299e4b37c4f038bb9d719a\",\n",
      "    \"text\": \"4.2 MAIN RESULTS\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.249,\n",
      "            351.91132159999995\n",
      "          ],\n",
      "          [\n",
      "            108.249,\n",
      "            361.8739215999999\n",
      "          ],\n",
      "          [\n",
      "            197.7368983,\n",
      "            361.8739215999999\n",
      "          ],\n",
      "          [\n",
      "            197.7368983,\n",
      "            351.91132159999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 8,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"b97e429d4d63b28aeee80632302cc90f\",\n",
      "    \"text\": \"In this subsection, we present the performance of different models on the VIST (Huang et al., 2016) and MMDialg (Feng et al., 2022) datasets. Our evaluations span all vision, language, and multi- modality domains to showcase the versatility and robustness of the proposed models.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000001,\n",
      "            372.8603215999999\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000001,\n",
      "            404.7409215999999\n",
      "          ],\n",
      "          [\n",
      "            504.0033874,\n",
      "            404.7409215999999\n",
      "          ],\n",
      "          [\n",
      "            504.0033874,\n",
      "            372.8603215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Huangetal .,\",\n",
      "          \"url\": \"cite.huang2016visual\",\n",
      "          \"start_index\": 80\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2016\",\n",
      "          \"url\": \"cite.huang2016visual\",\n",
      "          \"start_index\": 94\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Fengetal .,\",\n",
      "          \"url\": \"cite.feng2022mmdialog\",\n",
      "          \"start_index\": 113\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022\",\n",
      "          \"url\": \"cite.feng2022mmdialog\",\n",
      "          \"start_index\": 126\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 8,\n",
      "      \"parent_id\": \"982be95acb299e4b37c4f038bb9d719a\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"d06180c083e8f06a32b7948d55e0b08f\",\n",
      "    \"text\": \"Unimodal Generation with Multimodal Input To evaluate the model performance on image gen- eration and text generation, we systematically provide models with prior history context and subse- quently assess the generated images and narrations at each following step. Tables 1 and 2 outline the results of these experiments on the VIST validation set, showing the performance in both image and language metrics, respectively. The findings demonstrate that MiniGPT-5 can generate coher- ent, high-quality images utilizing long-horizontal multimodal input prompts across all data, without compromising the original model\\u2019s ability for multimodal comprehension, indicating the efficacy of our model in diverse settings.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            416.12858339999997\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            502.8729216\n",
      "          ],\n",
      "          [\n",
      "            504.00383260000007,\n",
      "            502.8729216\n",
      "          ],\n",
      "          [\n",
      "            504.00383260000007,\n",
      "            416.12858339999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"5cangeneratecoher\",\n",
      "          \"url\": \"table.caption.3\",\n",
      "          \"start_index\": 460\n",
      "        },\n",
      "        {\n",
      "          \"text\": \",\",\n",
      "          \"url\": \"table.caption.3\",\n",
      "          \"start_index\": 573\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 8,\n",
      "      \"parent_id\": \"982be95acb299e4b37c4f038bb9d719a\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"29d8707b3387e8e8e379de318fbe1af0\",\n",
      "    \"text\": \"Multimodal Generation with Multimodal Input To assess the quality of multimodal generation, we test both our model and the baselines on the VIST validation set by human evaluation. Given a preceding multimodal sequence, models are tasked with producing the subsequent scenario for each task. We select a random sample of 5,000 sequences, with each requiring evaluation by two workers. These evaluators are tasked with determining the superior multimodal output based on three criteria: Language Continuity, Image Quality, and Multimodal Coherence. This assessment is facilitated using Amazon Mechanical Turk (Crowston, 2012), with a representative example (Fig. 4) provided in the Appendix. As depicted in Table 3, our model, MiniGPT-5, is found to generate more fitting text narrations in around 55% of instances, deliver superior image quality in around 53% of cases, and produce more coherent multimodal outputs in around 56% of the scenarios. This data distinctly showcases its enhanced multimodal generation capabilities compared to the two-stage baseline, which must generate intermediate image captions first.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            514.2605834000001\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            644.8409216\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999984,\n",
      "            644.8409216\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999984,\n",
      "            514.2605834000001\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Crowston\",\n",
      "          \"url\": \"cite.crowston2012amazon\",\n",
      "          \"start_index\": 609\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2012\",\n",
      "          \"url\": \"cite.crowston2012amazon\",\n",
      "          \"start_index\": 619\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"4\",\n",
      "          \"url\": \"figure.caption.11\",\n",
      "          \"start_index\": 662\n",
      "        },\n",
      "        {\n",
      "          \"text\": \",\",\n",
      "          \"url\": \"table.caption.4\",\n",
      "          \"start_index\": 713\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 8,\n",
      "      \"parent_id\": \"982be95acb299e4b37c4f038bb9d719a\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"91ea4516da020986a03263ff5bf6e1ca\",\n",
      "    \"text\": \"Multimodal Dialog Generation on MMDialog We conduct an evaluation of our method on the MMDialog dataset to determine the effectiveness of generating precise and appropriate multimodal information in multi-turn conversational scenarios. The model is required to generate either uni- modal or multimodal responses based on the previous turns during the conversations. Our results, as presented in Table 4, demonstrate that MiniGPT-5 outperforms the baseline model Divter in terms of generating more accurate textual responses. While the image qualities of the generated responses are similar, MiniGPT-5 excels in MM-Relevance compared to the baselines. This indicates that our\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            656.2275834000001\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            732.0139216000001\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999984,\n",
      "            732.0139216000001\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999984,\n",
      "            656.2275834000001\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \",\",\n",
      "          \"url\": \"table.caption.5\",\n",
      "          \"start_index\": 402\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 8,\n",
      "      \"parent_id\": \"982be95acb299e4b37c4f038bb9d719a\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Footer\",\n",
      "    \"element_id\": \"38a3dd0cd82a8b947eb7079e8d207637\",\n",
      "    \"text\": \"8\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            303.509,\n",
      "            751.9393216000001\n",
      "          ],\n",
      "          [\n",
      "            303.509,\n",
      "            761.9019216\n",
      "          ],\n",
      "          [\n",
      "            308.4903,\n",
      "            761.9019216\n",
      "          ],\n",
      "          [\n",
      "            308.4903,\n",
      "            751.9393216000001\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 8,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"6cdef2c3812490f7e4cdef04939728c7\",\n",
      "    \"text\": \"Table 4: Multimodal generation results on MMDialog test set. In order to compare with their base- line, we use the same metrics reported in MMDialog (Feng et al., 2022).\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.72232159999999\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            102.6439216\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            102.6439216\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            81.72232159999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 9,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"e0ed9d616c5e1fbbe691375603f98bd8\",\n",
      "    \"text\": \"Model\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            113.978,\n",
      "            117.1883216\n",
      "          ],\n",
      "          [\n",
      "            113.978,\n",
      "            127.15092160000006\n",
      "          ],\n",
      "          [\n",
      "            139.9903486,\n",
      "            127.15092160000006\n",
      "          ],\n",
      "          [\n",
      "            139.9903486,\n",
      "            117.1883216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 9,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"a5d3fcee22285ace6098728db29fc1a3\",\n",
      "    \"text\": \"IS (\\u2191) BLEU-1 (\\u2191) BLEU-2 (\\u2191) Rouge-L (\\u2191) MM-Relevance (\\u2191)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            222.5304896,\n",
      "            116.9691444\n",
      "          ],\n",
      "          [\n",
      "            222.5304896,\n",
      "            127.15092160000006\n",
      "          ],\n",
      "          [\n",
      "            515.8085457999999,\n",
      "            127.15092160000006\n",
      "          ],\n",
      "          [\n",
      "            515.8085457999999,\n",
      "            116.9691444\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 9,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"1be3fbfa5e00050ca1dcff79367f12cc\",\n",
      "    \"text\": \"Divter (Sun et al., 2021) GILL (Koh et al., 2023) MiniGPT-5\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            113.97799999999995,\n",
      "            133.14832159999992\n",
      "          ],\n",
      "          [\n",
      "            113.97799999999995,\n",
      "            165.02892159999988\n",
      "          ],\n",
      "          [\n",
      "            210.57536960000004,\n",
      "            165.02892159999988\n",
      "          ],\n",
      "          [\n",
      "            210.57536960000004,\n",
      "            133.14832159999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Sunetal .,\",\n",
      "          \"url\": \"cite.sun2021multimodal\",\n",
      "          \"start_index\": 8\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2021\",\n",
      "          \"url\": \"cite.sun2021multimodal\",\n",
      "          \"start_index\": 20\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Kohetal .,\",\n",
      "          \"url\": \"cite.koh2023generating\",\n",
      "          \"start_index\": 32\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.koh2023generating\",\n",
      "          \"start_index\": 44\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"8ef9821a4492c284cafe7d67c4e0f31d\",\n",
      "    \"text\": \"20.53 23.78 20.23\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            222.79947979999994,\n",
      "            133.14832159999992\n",
      "          ],\n",
      "          [\n",
      "            222.79947979999994,\n",
      "            165.02892159999988\n",
      "          ],\n",
      "          [\n",
      "            245.21984999999998,\n",
      "            165.02892159999988\n",
      "          ],\n",
      "          [\n",
      "            245.21984999999998,\n",
      "            133.14832159999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 9,\n",
      "      \"parent_id\": \"1be3fbfa5e00050ca1dcff79367f12cc\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"487b8a2c8b9df7e5a729fb199f5e9599\",\n",
      "    \"text\": \"0.0944 0.2912 0.3369\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            267.95899999999995,\n",
      "            133.14832159999992\n",
      "          ],\n",
      "          [\n",
      "            267.95899999999995,\n",
      "            164.9591833999998\n",
      "          ],\n",
      "          [\n",
      "            295.35709560000004,\n",
      "            164.9591833999998\n",
      "          ],\n",
      "          [\n",
      "            295.35709560000004,\n",
      "            133.14832159999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 9,\n",
      "      \"parent_id\": \"1be3fbfa5e00050ca1dcff79367f12cc\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"1575781b29783763ca1a49ca3b91b7df\",\n",
      "    \"text\": \"0.0745 0.1945 0.2323\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            328.33235599999995,\n",
      "            133.14832159999992\n",
      "          ],\n",
      "          [\n",
      "            328.33235599999995,\n",
      "            164.9591833999998\n",
      "          ],\n",
      "          [\n",
      "            355.73045160000004,\n",
      "            164.9591833999998\n",
      "          ],\n",
      "          [\n",
      "            355.73045160000004,\n",
      "            133.14832159999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 9,\n",
      "      \"parent_id\": \"1be3fbfa5e00050ca1dcff79367f12cc\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"3940482a7fdb6595825ed468fc42e28a\",\n",
      "    \"text\": \"0.1119 0.1207 0.1176\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            389.25460060000006,\n",
      "            133.14832159999992\n",
      "          ],\n",
      "          [\n",
      "            389.25460060000006,\n",
      "            165.02892159999988\n",
      "          ],\n",
      "          [\n",
      "            416.6561499999999,\n",
      "            165.02892159999988\n",
      "          ],\n",
      "          [\n",
      "            416.6561499999999,\n",
      "            133.14832159999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 9,\n",
      "      \"parent_id\": \"1be3fbfa5e00050ca1dcff79367f12cc\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"9634f4cb6d47840b8dd4efbf30ea25a2\",\n",
      "    \"text\": \"0.62 0.64 0.67\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            469.02399999999994,\n",
      "            133.14832159999992\n",
      "          ],\n",
      "          [\n",
      "            469.02399999999994,\n",
      "            164.9591833999998\n",
      "          ],\n",
      "          [\n",
      "            486.4596887999999,\n",
      "            164.9591833999998\n",
      "          ],\n",
      "          [\n",
      "            486.4596887999999,\n",
      "            133.14832159999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 9,\n",
      "      \"parent_id\": \"1be3fbfa5e00050ca1dcff79367f12cc\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"6bbb4733b53fea2bc26d761626c1c180\",\n",
      "    \"text\": \"Table 5: Evaluation of different method designs for image generation qualities on the CC3M vali- dation set. The results show that all of our designs can help the model better align with the stable diffusion model in the pertaining stage.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            183.26832159999992\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            215.14892159999988\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999997,\n",
      "            215.14892159999988\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999997,\n",
      "            183.26832159999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 9,\n",
      "      \"parent_id\": \"1be3fbfa5e00050ca1dcff79367f12cc\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"0273bd3fa40f91cd65ca995382aad338\",\n",
      "    \"text\": \"Model\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            155.21432244,\n",
      "            229.85210080972786\n",
      "          ],\n",
      "          [\n",
      "            155.21432244,\n",
      "            240.27626806772787\n",
      "          ],\n",
      "          [\n",
      "            182.43182315063797,\n",
      "            240.27626806772787\n",
      "          ],\n",
      "          [\n",
      "            182.43182315063797,\n",
      "            229.85210080972786\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 9,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"608dcee68205136add653d56439cb187\",\n",
      "    \"text\": \"CLIP-I (\\u2191) CLIP-T (\\u2191)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            272.308993249114,\n",
      "            229.6227691300519\n",
      "          ],\n",
      "          [\n",
      "            272.308993249114,\n",
      "            240.27626806772787\n",
      "          ],\n",
      "          [\n",
      "            376.30232986691396,\n",
      "            240.27626806772787\n",
      "          ],\n",
      "          [\n",
      "            376.30232986691396,\n",
      "            229.6227691300519\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 9,\n",
      "      \"parent_id\": \"0273bd3fa40f91cd65ca995382aad338\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"b2f6219ce9ce339023e205ea8565fd1b\",\n",
      "    \"text\": \"IS (\\u2191)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            388.81133057651397,\n",
      "            229.6227691300519\n",
      "          ],\n",
      "          [\n",
      "            388.81133057651397,\n",
      "            240.27626806772787\n",
      "          ],\n",
      "          [\n",
      "            412.83912713691393,\n",
      "            240.27626806772787\n",
      "          ],\n",
      "          [\n",
      "            412.83912713691393,\n",
      "            229.6227691300519\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 9,\n",
      "      \"parent_id\": \"0273bd3fa40f91cd65ca995382aad338\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"367525ca9537c8b10450e2e77f21ee6f\",\n",
      "    \"text\": \"FID (\\u2193)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            425.34812784651393,\n",
      "            229.6227691300519\n",
      "          ],\n",
      "          [\n",
      "            425.34812784651393,\n",
      "            240.27626806772787\n",
      "          ],\n",
      "          [\n",
      "            456.90217609691393,\n",
      "            240.27626806772787\n",
      "          ],\n",
      "          [\n",
      "            456.90217609691393,\n",
      "            229.6227691300519\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 9,\n",
      "      \"parent_id\": \"0273bd3fa40f91cd65ca995382aad338\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"8464d1a7482f839fe6038840f8c66b22\",\n",
      "    \"text\": \"MiniGPT-5 MiniGPT-5 (w/o CFG) MiniGPT-5 (w/o LCAP ) MiniGPT-5 (w/o LLDM )\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            155.21432244,\n",
      "            246.55257393972795\n",
      "          ],\n",
      "          [\n",
      "            155.21432244,\n",
      "            292.10412735387587\n",
      "          ],\n",
      "          [\n",
      "            259.801855006914,\n",
      "            292.10412735387587\n",
      "          ],\n",
      "          [\n",
      "            259.801855006914,\n",
      "            246.55257393972795\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 9,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"562e5a66e00b8cec06a5e85fcf90fc0f\",\n",
      "    \"text\": \"0.61 0.60 0.54 0.58\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            285.33245558577397,\n",
      "            246.47960476892194\n",
      "          ],\n",
      "          [\n",
      "            285.33245558577397,\n",
      "            291.37693260772784\n",
      "          ],\n",
      "          [\n",
      "            303.583357490514,\n",
      "            291.37693260772784\n",
      "          ],\n",
      "          [\n",
      "            303.583357490514,\n",
      "            246.47960476892194\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 9,\n",
      "      \"parent_id\": \"8464d1a7482f839fe6038840f8c66b22\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"574d0d0f7b4a132b249200bd0e059d80\",\n",
      "    \"text\": \"0.22 0.22 0.16 0.20\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            343.58088725946,\n",
      "            246.47960476892194\n",
      "          ],\n",
      "          [\n",
      "            343.58088725946,\n",
      "            291.37693260772784\n",
      "          ],\n",
      "          [\n",
      "            361.83360412821804,\n",
      "            291.37693260772784\n",
      "          ],\n",
      "          [\n",
      "            361.83360412821804,\n",
      "            246.47960476892194\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 9,\n",
      "      \"parent_id\": \"8464d1a7482f839fe6038840f8c66b22\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"7db561e8dc3910727ef93db250c97b90\",\n",
      "    \"text\": \"28.09 23.41 21.27 24.79\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            389.092801507888,\n",
      "            246.47960476892194\n",
      "          ],\n",
      "          [\n",
      "            389.092801507888,\n",
      "            291.37693260772784\n",
      "          ],\n",
      "          [\n",
      "            412.555739538246,\n",
      "            291.37693260772784\n",
      "          ],\n",
      "          [\n",
      "            412.555739538246,\n",
      "            246.47960476892194\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 9,\n",
      "      \"parent_id\": \"8464d1a7482f839fe6038840f8c66b22\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"611dc5225e9b5fd9ff0a76c59a5ab64f\",\n",
      "    \"text\": \"31.47 33.73 40.24 34.65\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            429.392632127316,\n",
      "            246.47960476892194\n",
      "          ],\n",
      "          [\n",
      "            429.392632127316,\n",
      "            291.37693260772784\n",
      "          ],\n",
      "          [\n",
      "            452.8555701576739,\n",
      "            291.37693260772784\n",
      "          ],\n",
      "          [\n",
      "            452.8555701576739,\n",
      "            246.47960476892194\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 9,\n",
      "      \"parent_id\": \"8464d1a7482f839fe6038840f8c66b22\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"881e864f96833f7d25c329066f27db3a\",\n",
      "    \"text\": \"model can better learn how to position image generation and produce highly coherent multimodal responses appropriately.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            319.05032159999996\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            339.9719216\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999967,\n",
      "            339.9719216\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999967,\n",
      "            319.05032159999996\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 9,\n",
      "      \"parent_id\": \"8464d1a7482f839fe6038840f8c66b22\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"2b15b4b24f013318f336930d562f7972\",\n",
      "    \"text\": \"4.3 ABLATION STUDIES\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.249,\n",
      "            357.01632159999997\n",
      "          ],\n",
      "          [\n",
      "            108.249,\n",
      "            366.9789216\n",
      "          ],\n",
      "          [\n",
      "            216.6954963,\n",
      "            366.9789216\n",
      "          ],\n",
      "          [\n",
      "            216.6954963,\n",
      "            357.01632159999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 9,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"37c9275c79722045444bf4a9311ade60\",\n",
      "    \"text\": \"To further evaluate the effectiveness of our design, we conducted several ablation studies, and more ablation studies can be found in Appendix C.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000001,\n",
      "            378.34032160000004\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000001,\n",
      "            399.2619216\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            399.2619216\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            378.34032160000004\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \", weconductedseveralablationstudies , ablationstudiescanbefoundinAppendixC\",\n",
      "          \"url\": \"appendix.C\",\n",
      "          \"start_index\": 51\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"parent_id\": \"2b15b4b24f013318f336930d562f7972\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"aae579d2e7499319c72de498860abb3d\",\n",
      "    \"text\": \"Text-to-Image Generation Qualities on CC3M\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000001,\n",
      "            410.6485834\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000001,\n",
      "            420.6111834\n",
      "          ],\n",
      "          [\n",
      "            303.54591280000005,\n",
      "            420.6111834\n",
      "          ],\n",
      "          [\n",
      "            303.54591280000005,\n",
      "            410.6485834\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 9,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"49925441690f0166262750ef72a7b958\",\n",
      "    \"text\": \"Evaluation of Classifier-Free Guidance (CFG) To assess the effectiveness of the CFG strategy, we trained our model without CFG dropoff. During inference, the model utilized the original CFG denoising process, which utilized the empty caption feature from Stable Diffusion\\u2019s text encoder as negative prompt features. The results in Table 5 demonstrate that all metrics are worse without CFG, indicating that the CFG training strategy improves the image generation quality.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000001,\n",
      "            432.0685834\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000001,\n",
      "            485.9369216\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            485.9369216\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            432.0685834\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Duringinference\",\n",
      "          \"url\": \"table.caption.7\",\n",
      "          \"start_index\": 135\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"parent_id\": \"aae579d2e7499319c72de498860abb3d\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"fffe7c4541c7be61727889db1ef64402\",\n",
      "    \"text\": \"Evaluation of Different Loss Guidance As described in Sec. 3.3, we introduced an auxiliary loss, denoted as LCAP for CC3M training. To assess the impact of this loss and determine if the single caption loss alone can generate high-quality images like GILL, we trained our model without the caption loss LCAP (alignment between the mapped generative voken features and the caption fea- tures from stable diffusion text encoder) and the conditional latent diffusion loss LLDM (alignment between the mapped generative voken features and conditional features for latent diffusion process of ground truth images) separately. The results, as shown in Table 5, indicate that the caption loss significantly aids in generating better images, and the voken alignment loss further enhances coher- ence and image quality performance.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000003,\n",
      "            497.3235834\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000003,\n",
      "            595.0269216\n",
      "          ],\n",
      "          [\n",
      "            504.0038490000001,\n",
      "            595.0269216\n",
      "          ],\n",
      "          [\n",
      "            504.0038490000001,\n",
      "            497.3235834\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"3 . 3\",\n",
      "          \"url\": \"subsection.3.3\",\n",
      "          \"start_index\": 59\n",
      "        },\n",
      "        {\n",
      "          \"text\": \",\",\n",
      "          \"url\": \"table.caption.7\",\n",
      "          \"start_index\": 652\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"parent_id\": \"aae579d2e7499319c72de498860abb3d\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"f6365493634e782497bd701d0925de9a\",\n",
      "    \"text\": \"Influence of Input Types for Image Generation To assess the impact of various types of input data for image generation, models are tasked with generating the final-step images based on specific prompts and comparing them with ground truth images by CLIP-I metric. All models are fine-tuned on data with full multimodal context and tested on various input types. As indicated in Table 6, the MiniGPT-5 model exhibits exceptional proficiency in producing semantically precise images compared to other models. Furthermore, we observed increased CLIP similarities when more in- formation was provided in the input, signifying the models\\u2019 enhanced ability to process diverse, long-horizon multimodal inputs.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000006,\n",
      "            606.4145834000001\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000006,\n",
      "            693.1589216\n",
      "          ],\n",
      "          [\n",
      "            504.0033874,\n",
      "            693.1589216\n",
      "          ],\n",
      "          [\n",
      "            504.0033874,\n",
      "            606.4145834000001\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"- ondatawithfullmultimodalcontextandtestedonvariousinputtypes . AsindicatedinTable6\",\n",
      "          \"url\": \"table.caption.8\",\n",
      "          \"start_index\": 279\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"parent_id\": \"aae579d2e7499319c72de498860abb3d\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"248c5d8f0ab74102b8f3d5a08eef1f38\",\n",
      "    \"text\": \"Instead of multimodal input, we also test single text-to-image generation qualities on the CC3M validation set, as displayed in Table 7. The results indicate that although our model can have better generation on multi-turn multimodal scenarios, Stable Diffusion 2 achieves the best outcomes across\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000006,\n",
      "            700.1333216\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000006,\n",
      "            732.0139216\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999995,\n",
      "            732.0139216\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999995,\n",
      "            700.1333216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \".\",\n",
      "          \"url\": \"table.caption.9\",\n",
      "          \"start_index\": 135\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 9,\n",
      "      \"parent_id\": \"aae579d2e7499319c72de498860abb3d\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Footer\",\n",
      "    \"element_id\": \"ffeddaa786303fe82a652a40d124fa53\",\n",
      "    \"text\": \"9\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            303.509,\n",
      "            751.9393216000001\n",
      "          ],\n",
      "          [\n",
      "            303.509,\n",
      "            761.9019216\n",
      "          ],\n",
      "          [\n",
      "            308.4903,\n",
      "            761.9019216\n",
      "          ],\n",
      "          [\n",
      "            308.4903,\n",
      "            751.9393216000001\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 9,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"cd64546c1703dbcebece59157e81ae04\",\n",
      "    \"text\": \"SD 2\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            81.85792631100003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            81.85792631100003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 10,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"c8aa9c73ed215a62d5ce2bcd1944e771\",\n",
      "    \"text\": \"first, we wentto the park.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            81.85792631100003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            81.85792631100003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 10,\n",
      "      \"parent_id\": \"cd64546c1703dbcebece59157e81ae04\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"f246bea58ef04e6017552ede1beb9d4f\",\n",
      "    \"text\": \"GILL\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            81.85792631100003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            81.85792631100003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 10,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"42afa194c5e0bd225462dee79bfc87b3\",\n",
      "    \"text\": \"My favorite was this realcovered wagon from200 years ago.GT\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            81.85792631100003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            81.85792631100003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 10,\n",
      "      \"parent_id\": \"f246bea58ef04e6017552ede1beb9d4f\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"415d19621a53435112664bc991bb6c9c\",\n",
      "    \"text\": \"VSIT -- Multimodal Generation\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            81.85792631100003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            81.85792631100003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 10,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"8a07f9076f69068706153b35faa57bd4\",\n",
      "    \"text\": \"MMDialog -- Multimodal Dialog Generation\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            81.85792631100003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            81.85792631100003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 10,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"65dfa3f63594a2a6c08885ac7d76394b\",\n",
      "    \"text\": \"MiniGPT-5GT\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            81.85792631100003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            81.85792631100003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 10,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"25c6ef02480a140060d5c1eadae76dc4\",\n",
      "    \"text\": \"They also have a giftshop.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            81.85792631100003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            81.85792631100003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 10,\n",
      "      \"parent_id\": \"65dfa3f63594a2a6c08885ac7d76394b\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"a02360b93fd3521d7accec1cc4491aee\",\n",
      "    \"text\": \"They had an area forcryptozoology.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            81.85792631100003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            81.85792631100003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 10,\n",
      "      \"parent_id\": \"65dfa3f63594a2a6c08885ac7d76394b\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"f18131c1169b9d90444949e49c264018\",\n",
      "    \"text\": \"MiniGPT-5Two-StageIt's a great place tospend some time in.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            81.85792631100003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            81.85792631100003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 10,\n",
      "      \"parent_id\": \"65dfa3f63594a2a6c08885ac7d76394b\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"6cd12a931c850f8aedad7176f1e4b68a\",\n",
      "    \"text\": \"I went to thenatural historymuseum today.their evolution displaywas interesting.They had manyinteresting things ondisplay.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            81.85792631100003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            81.85792631100003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 10,\n",
      "      \"parent_id\": \"65dfa3f63594a2a6c08885ac7d76394b\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"351a2b7a2e5572d04ffe750c3f96a20a\",\n",
      "    \"text\": \"Two-stage\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            81.85792631100003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            81.85792631100003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 10,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"1508ac44d5bb3b6f93e225c7cb1ebbaf\",\n",
      "    \"text\": \"VSIT -- Image Generation\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            81.85792631100003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            81.85792631100003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 10,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"5ddb20a82ec35ce42b600071b60761c3\",\n",
      "    \"text\": \"GILLYes, from a loan.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            81.85792631100003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            81.85792631100003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 10,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"05606c3353b001023242a52320b8ae2d\",\n",
      "    \"text\": \"MiniGPT-5GT\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            81.85792631100003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            81.85792631100003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 10,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"02635275e38428d6ac4d00af97ef29ce\",\n",
      "    \"text\": \"How gracefullcoming? From aloan?\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            81.85792631100003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            81.85792631100003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 10,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"69c3bb34d88eb333ab035b7329f6d37a\",\n",
      "    \"text\": \"I bought a bookabout the history ofthe museumGILL\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            81.85792631100003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            81.85792631100003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 10,\n",
      "      \"parent_id\": \"02635275e38428d6ac4d00af97ef29ce\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"4b47ab123b778248080f1e65ac8d5daa\",\n",
      "    \"text\": \"then, we wentswimmingi looked cooolin my glassesat the poollater, we wentto visit mommywe playeddress up.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            81.85792631100003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            81.85792631100003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 10,\n",
      "      \"parent_id\": \"02635275e38428d6ac4d00af97ef29ce\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"951a06f22b7903daa57e7ca737ce2cdb\",\n",
      "    \"text\": \"A Maya example,couple comingsoon to 8th-century king andwife, lady fromTikal, dancing.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            81.85792631100003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            81.85792631100003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 10,\n",
      "      \"parent_id\": \"02635275e38428d6ac4d00af97ef29ce\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"4682dd198da2639d5a9370face81ab52\",\n",
      "    \"text\": \"ID of perfectthough art:complementarity,complicity,simplicity, security.No, it's not a loan. It was foundin the tomb of an 8th centuryMaya king and his wife at Tika!Loan, privatecollection. Addingcolor to gallery!Lovely depiction oftextiles, gestures.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            81.85792631100003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            589.6030000000001\n",
      "          ],\n",
      "          [\n",
      "            484.1989631555,\n",
      "            81.85792631100003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 10,\n",
      "      \"parent_id\": \"02635275e38428d6ac4d00af97ef29ce\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"5f4cabbc9abdc807a04f297960ebd93a\",\n",
      "    \"text\": \"Figure 3: Qualitative examples from MiniGPT-5 and baselines on the VIST and MMDialog datasets. The orange blocks indicate the input prompts, while the green blocks include model outputs. The comparisons show that MiniGPT-5 can produce coherent and high-quality multimodal output. We would like to emphasize that MiniGPT-5 does not use any caption data during fine-tuning on VIST and MMDialog, which obeys to our description-free settings. More qualitative examples can be found in the Appendix D.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            599.4263215999999\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            664.1829216\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999984,\n",
      "            664.1829216\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999984,\n",
      "            599.4263215999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 10,\n",
      "      \"parent_id\": \"02635275e38428d6ac4d00af97ef29ce\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"f58c709deae9419cf663f4c6b5bf432c\",\n",
      "    \"text\": \"all metrics for pure text-to-image generation. Since our model attempts to align with the pretrained text encoder of Stable Diffusion 2 in this stage, there is a slight gap in performance due to the limitation of data amount. Compared with the observations on the VIST dataset, we can conclude that MiniGPT-5 is better at extracting features from long-horizontal multimodal information instead\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            689.1743216\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            732.0139216\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            732.0139216\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            689.1743216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 10,\n",
      "      \"parent_id\": \"02635275e38428d6ac4d00af97ef29ce\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Footer\",\n",
      "    \"element_id\": \"a86b0daf76f01383da8d69ed71118e40\",\n",
      "    \"text\": \"10\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            301.019,\n",
      "            751.9393216000001\n",
      "          ],\n",
      "          [\n",
      "            301.019,\n",
      "            761.9019216\n",
      "          ],\n",
      "          [\n",
      "            310.98159999999996,\n",
      "            761.9019216\n",
      "          ],\n",
      "          [\n",
      "            310.98159999999996,\n",
      "            751.9393216000001\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 10,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"2073c33e59cfb5a4afabdce4748143b1\",\n",
      "    \"text\": \"Table 6: Influence of prompts for image generation on CLIP-I metrics on VIST. We establish four distinct conditions for the final-step image generation: \\u2018No Context\\u2019 (solely the last step\\u2019s narration), \\u2018Text Context\\u2019 (inclusive of historical textual narrations), \\u2018Image Context\\u2019 (inclusive of historical images), and \\u2018Image-Text Context\\u2019 (inclusive of both historical images and narrations). From the results, MiniGPT-5 can generate more coherent images.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            81.72232159999999\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            135.52092159999984\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999995,\n",
      "            135.52092159999984\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999995,\n",
      "            81.72232159999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"fc7094e7c1bffd7599555d88a08bbc7e\",\n",
      "    \"text\": \"Model\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            115.89649468,\n",
      "            149.83206288521603\n",
      "          ],\n",
      "          [\n",
      "            115.89649468,\n",
      "            159.12228701121603\n",
      "          ],\n",
      "          [\n",
      "            140.153269872986,\n",
      "            159.12228701121603\n",
      "          ],\n",
      "          [\n",
      "            140.153269872986,\n",
      "            149.83206288521603\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"a99e40849b256bbb887f4db13aa018d3\",\n",
      "    \"text\": \"No Context Text Context\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            245.22570473804598,\n",
      "            149.83206288521603\n",
      "          ],\n",
      "          [\n",
      "            245.22570473804598,\n",
      "            159.12228701121603\n",
      "          ],\n",
      "          [\n",
      "            347.17662429677,\n",
      "            159.12228701121603\n",
      "          ],\n",
      "          [\n",
      "            347.17662429677,\n",
      "            149.83206288521603\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"580ca1aa0cdaef1f5c93f723bc2e29cb\",\n",
      "    \"text\": \"Image Context\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            358.32489324797,\n",
      "            149.83206288521603\n",
      "          ],\n",
      "          [\n",
      "            358.32489324797,\n",
      "            159.12228701121603\n",
      "          ],\n",
      "          [\n",
      "            413.14650581549597,\n",
      "            159.12228701121603\n",
      "          ],\n",
      "          [\n",
      "            413.14650581549597,\n",
      "            149.83206288521603\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"4a5f431e117c717c9c0d671dcecad14f\",\n",
      "    \"text\": \"Image-Text Context\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            424.294774766696,\n",
      "            149.83206288521603\n",
      "          ],\n",
      "          [\n",
      "            424.294774766696,\n",
      "            159.12228701121603\n",
      "          ],\n",
      "          [\n",
      "            498.4493437404279,\n",
      "            159.12228701121603\n",
      "          ],\n",
      "          [\n",
      "            498.4493437404279,\n",
      "            149.83206288521603\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"b253a44f17d1fb7dc43810e5341638e6\",\n",
      "    \"text\": \"SD 2.1 (Rombach et al., 2022b) Fine-tuned SD 2.1 Two-stage Baseline GILL (Koh et al., 2023) MiniGPT-5 (Prefix Tuning) MiniGPT-5 (LoRA)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            115.89649468,\n",
      "            164.71585499521598\n",
      "          ],\n",
      "          [\n",
      "            115.89649468,\n",
      "            225.10203206121582\n",
      "          ],\n",
      "          [\n",
      "            234.07743578684605,\n",
      "            225.10203206121582\n",
      "          ],\n",
      "          [\n",
      "            234.07743578684605,\n",
      "            164.71585499521598\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Rombachetal .,\",\n",
      "          \"url\": \"cite.rombach2021highresolution\",\n",
      "          \"start_index\": 8\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022b\",\n",
      "          \"url\": \"cite.rombach2021highresolution\",\n",
      "          \"start_index\": 24\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Kohetal .,\",\n",
      "          \"url\": \"cite.koh2023generating\",\n",
      "          \"start_index\": 74\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.koh2023generating\",\n",
      "          \"start_index\": 86\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"4a5f431e117c717c9c0d671dcecad14f\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"c2aea5030d4113d10967f5c5320c5ec9\",\n",
      "    \"text\": \"0.57 0.59 0.54 0.56 0.60 0.61\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            258.57518723,\n",
      "            164.71585499521598\n",
      "          ],\n",
      "          [\n",
      "            258.57518723,\n",
      "            225.03700049233385\n",
      "          ],\n",
      "          [\n",
      "            274.83364902760803,\n",
      "            225.03700049233385\n",
      "          ],\n",
      "          [\n",
      "            274.83364902760803,\n",
      "            164.71585499521598\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"4a5f431e117c717c9c0d671dcecad14f\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"48465e3dace6fd26d898ba3e707390cb\",\n",
      "    \"text\": \"0.59 0.61 0.56 0.59 0.63 0.64\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            315.124781484962,\n",
      "            164.71585499521598\n",
      "          ],\n",
      "          [\n",
      "            315.124781484962,\n",
      "            225.03700049233385\n",
      "          ],\n",
      "          [\n",
      "            331.38324328257005,\n",
      "            225.03700049233385\n",
      "          ],\n",
      "          [\n",
      "            331.38324328257005,\n",
      "            164.71585499521598\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"4a5f431e117c717c9c0d671dcecad14f\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"1b5205d869eaa90abe441d755c2ce270\",\n",
      "    \"text\": \"- 0.57 0.60 0.68 0.69\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            377.60210830942003,\n",
      "            164.71585499521598\n",
      "          ],\n",
      "          [\n",
      "            377.60210830942003,\n",
      "            225.03700049233385\n",
      "          ],\n",
      "          [\n",
      "            393.868721176938,\n",
      "            225.03700049233385\n",
      "          ],\n",
      "          [\n",
      "            393.868721176938,\n",
      "            164.71585499521598\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"4a5f431e117c717c9c0d671dcecad14f\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"e3b7c38847f57607ae905a93a80e743a\",\n",
      "    \"text\": \"- 0.58 0.60 0.70 0.70\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            453.242543566204,\n",
      "            164.71585499521598\n",
      "          ],\n",
      "          [\n",
      "            453.242543566204,\n",
      "            225.03700049233385\n",
      "          ],\n",
      "          [\n",
      "            469.50100536381194,\n",
      "            225.03700049233385\n",
      "          ],\n",
      "          [\n",
      "            469.50100536381194,\n",
      "            164.71585499521598\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"4a5f431e117c717c9c0d671dcecad14f\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"9b00e43257b1e4622f2e2f6270cea054\",\n",
      "    \"text\": \"Table 7: Generation Qualities on CC3M and VIST. We find that MiniGPT-5 is better at extracting features from long-horizontal multimodal information than single text input.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            242.46532159999992\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            263.38692159999994\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999996,\n",
      "            263.38692159999994\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999996,\n",
      "            242.46532159999992\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"4a5f431e117c717c9c0d671dcecad14f\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"ca6a62ed7f05c5a24db263738a651b39\",\n",
      "    \"text\": \"CC3M\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            338.637,\n",
      "            277.93132160000005\n",
      "          ],\n",
      "          [\n",
      "            338.637,\n",
      "            287.8939216\n",
      "          ],\n",
      "          [\n",
      "            365.7651598,\n",
      "            287.8939216\n",
      "          ],\n",
      "          [\n",
      "            365.7651598,\n",
      "            277.93132160000005\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"71004779583f438a89ac44dbda86405e\",\n",
      "    \"text\": \"VIST\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            437.5257676,\n",
      "            277.93132160000005\n",
      "          ],\n",
      "          [\n",
      "            437.5257676,\n",
      "            287.8939216\n",
      "          ],\n",
      "          [\n",
      "            459.6626648,\n",
      "            287.8939216\n",
      "          ],\n",
      "          [\n",
      "            459.6626648,\n",
      "            277.93132160000005\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"dc1c3aafbff8fb6d8f1ce3e8090baa11\",\n",
      "    \"text\": \"Model\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            118.689,\n",
      "            293.6923216\n",
      "          ],\n",
      "          [\n",
      "            118.689,\n",
      "            303.65492159999997\n",
      "          ],\n",
      "          [\n",
      "            144.7013486,\n",
      "            303.65492159999997\n",
      "          ],\n",
      "          [\n",
      "            144.7013486,\n",
      "            293.6923216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"06763478b580a3c74b22e8889184c038\",\n",
      "    \"text\": \"CLIP-I (\\u2191)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            309.9808826,\n",
      "            293.47314439999997\n",
      "          ],\n",
      "          [\n",
      "            309.9808826,\n",
      "            303.65492159999997\n",
      "          ],\n",
      "          [\n",
      "            352.3105458,\n",
      "            303.65492159999997\n",
      "          ],\n",
      "          [\n",
      "            352.3105458,\n",
      "            293.47314439999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"dc1c3aafbff8fb6d8f1ce3e8090baa11\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"4ee51c9801bc362d98b3aa9eeff7cf97\",\n",
      "    \"text\": \"FID (\\u2193) CLIP-I (\\u2191)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            364.2656658,\n",
      "            293.47314439999997\n",
      "          ],\n",
      "          [\n",
      "            364.2656658,\n",
      "            303.65492159999997\n",
      "          ],\n",
      "          [\n",
      "            448.7085458,\n",
      "            303.65492159999997\n",
      "          ],\n",
      "          [\n",
      "            448.7085458,\n",
      "            293.47314439999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"dc1c3aafbff8fb6d8f1ce3e8090baa11\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"a28fc4a28deb729f30d9ea9877345a0b\",\n",
      "    \"text\": \"FID (\\u2193)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            460.66366580000005,\n",
      "            293.47314439999997\n",
      "          ],\n",
      "          [\n",
      "            460.66366580000005,\n",
      "            303.65492159999997\n",
      "          ],\n",
      "          [\n",
      "            490.82054580000005,\n",
      "            303.65492159999997\n",
      "          ],\n",
      "          [\n",
      "            490.82054580000005,\n",
      "            293.47314439999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"dc1c3aafbff8fb6d8f1ce3e8090baa11\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"b0131082363a60be3192051f9775adb2\",\n",
      "    \"text\": \"Stable Diffusion 2.1 (Rombach et al., 2022b) GILL (Koh et al., 2023) MiniGPT-5\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            118.689,\n",
      "            309.6533216\n",
      "          ],\n",
      "          [\n",
      "            118.689,\n",
      "            341.9329216\n",
      "          ],\n",
      "          [\n",
      "            298.02576260000006,\n",
      "            341.9329216\n",
      "          ],\n",
      "          [\n",
      "            298.02576260000006,\n",
      "            309.6533216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Rombachetal .,\",\n",
      "          \"url\": \"cite.rombach2021highresolution\",\n",
      "          \"start_index\": 22\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022b\",\n",
      "          \"url\": \"cite.rombach2021highresolution\",\n",
      "          \"start_index\": 38\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Kohetal .,\",\n",
      "          \"url\": \"cite.koh2023generating\",\n",
      "          \"start_index\": 51\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2023\",\n",
      "          \"url\": \"cite.koh2023generating\",\n",
      "          \"start_index\": 63\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"dc1c3aafbff8fb6d8f1ce3e8090baa11\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"47da42109c21422af1c29682036e63a9\",\n",
      "    \"text\": \"0.64 0.57 0.61\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            322.42417,\n",
      "            309.5835834\n",
      "          ],\n",
      "          [\n",
      "            322.42417,\n",
      "            341.9329216\n",
      "          ],\n",
      "          [\n",
      "            339.86255,\n",
      "            341.9329216\n",
      "          ],\n",
      "          [\n",
      "            339.86255,\n",
      "            309.5835834\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"dc1c3aafbff8fb6d8f1ce3e8090baa11\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"689d687440bb10debd4675de6e03dd35\",\n",
      "    \"text\": \"26.39 36.85 31.47\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            368.1325788,\n",
      "            309.5835834\n",
      "          ],\n",
      "          [\n",
      "            368.1325788,\n",
      "            341.9329216\n",
      "          ],\n",
      "          [\n",
      "            390.55225879999995,\n",
      "            341.9329216\n",
      "          ],\n",
      "          [\n",
      "            390.55225879999995,\n",
      "            309.5835834\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"dc1c3aafbff8fb6d8f1ce3e8090baa11\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"f5a4a96c4a03be5cfc16e71f23d80731\",\n",
      "    \"text\": \"0.59 0.60 0.66\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            418.8222876,\n",
      "            309.6533216\n",
      "          ],\n",
      "          [\n",
      "            418.8222876,\n",
      "            341.8631834\n",
      "          ],\n",
      "          [\n",
      "            436.26055,\n",
      "            341.8631834\n",
      "          ],\n",
      "          [\n",
      "            436.26055,\n",
      "            309.6533216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"dc1c3aafbff8fb6d8f1ce3e8090baa11\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"d34fe1fb4b8a736b5cee5f62a2a580ab\",\n",
      "    \"text\": \"393.49 381.88 366.62\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            462.04004639999994,\n",
      "            309.6533216\n",
      "          ],\n",
      "          [\n",
      "            462.04004639999994,\n",
      "            341.8631834\n",
      "          ],\n",
      "          [\n",
      "            489.4409088,\n",
      "            341.8631834\n",
      "          ],\n",
      "          [\n",
      "            489.4409088,\n",
      "            309.6533216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"dc1c3aafbff8fb6d8f1ce3e8090baa11\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"a5c7032f095d6898515618246280bbfd\",\n",
      "    \"text\": \"of single text input. This indicates potential future directions on efficiently aligning LLMs with generative models. On the other hand, our model outperforms another state-of-the-art multimodal generation model, GILL, on all metrics, further validating the effectiveness of our design.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            368.8073216\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            400.6869216\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999997,\n",
      "            400.6869216\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999997,\n",
      "            368.8073216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"dc1c3aafbff8fb6d8f1ce3e8090baa11\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"9b4c1fb55ae280b25a2632127ea7774d\",\n",
      "    \"text\": \"5 CONCLUSION\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.299,\n",
      "            419.3461232000001\n",
      "          ],\n",
      "          [\n",
      "            108.299,\n",
      "            431.30132320000007\n",
      "          ],\n",
      "          [\n",
      "            195.3774711,\n",
      "            431.30132320000007\n",
      "          ],\n",
      "          [\n",
      "            195.3774711,\n",
      "            419.3461232000001\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"2f06246d0482d91edcda9ccb5411139f\",\n",
      "    \"text\": \"In this paper, we introduce MiniGPT-5, designed to augment the capabilities of LLMs for multi- modal generation by aligning the LLM with a pretrained text-to-image generation model. Our ap- proach demonstrates substantial improvements, as evidenced by comprehensive experiments. There are still some limitations of MiniGPT-5. For example, we still find the object texture hard to main- tain in the new generation, and the generated image quality still has space to improve. Through this work, we aspire to set a new benchmark for multimodal generative models, opening doors to applications previously deemed challenging due to the disjointed nature of existing image and text synthesis paradigms.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000001,\n",
      "            445.34532160000003\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000001,\n",
      "            532.0199216000001\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999995,\n",
      "            532.0199216000001\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999995,\n",
      "            445.34532160000003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"9b4c1fb55ae280b25a2632127ea7774d\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"8e2525b0a210f59e5d2ff70067d189da\",\n",
      "    \"text\": \"REFERENCES\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.29900000000002,\n",
      "            550.6791232\n",
      "          ],\n",
      "          [\n",
      "            108.29900000000002,\n",
      "            562.6343232000002\n",
      "          ],\n",
      "          [\n",
      "            175.25983050000005,\n",
      "            562.6343232000002\n",
      "          ],\n",
      "          [\n",
      "            175.25983050000005,\n",
      "            550.6791232\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"67492099117299e632b99fb3a9f0e757\",\n",
      "    \"text\": \"Emanuele Aiello, Lili Yu, Yixin Nie, Armen Aghajanyan, and Barlas Oguz. Jointly training large\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000003,\n",
      "            570.7003216\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000003,\n",
      "            580.6629216000001\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999997,\n",
      "            580.6629216000001\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999997,\n",
      "            570.7003216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"8e2525b0a210f59e5d2ff70067d189da\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"123c58d82d3bf5cec5f2f09d16a25f72\",\n",
      "    \"text\": \"autoregressive multimodal models. arXiv preprint arXiv:2309.15564, 2023.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            117.96300000000002,\n",
      "            581.4301818000001\n",
      "          ],\n",
      "          [\n",
      "            117.96300000000002,\n",
      "            591.6219216000002\n",
      "          ],\n",
      "          [\n",
      "            420.32615,\n",
      "            591.6219216000002\n",
      "          ],\n",
      "          [\n",
      "            420.32615,\n",
      "            581.4301818000001\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"8e2525b0a210f59e5d2ff70067d189da\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"f9daf907c1a7d6dee25a787f6a2efdcb\",\n",
      "    \"text\": \"Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds, et al. Flamingo: a visual language model for few-shot learning. Advances in Neural Information Processing Systems, 35:23716\\u2013 23736, 2022.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            602.8863216000001\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            645.7249216000001\n",
      "          ],\n",
      "          [\n",
      "            504.00378739999974,\n",
      "            645.7249216000001\n",
      "          ],\n",
      "          [\n",
      "            504.00378739999974,\n",
      "            602.8863216000001\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"8e2525b0a210f59e5d2ff70067d189da\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"e89fb22911f6b11d969cf00db99ed1b5\",\n",
      "    \"text\": \"Satanjeev Banerjee and Alon Lavie. Meteor: An automatic metric for mt evaluation with improved correlation with human judgments. In Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization, pp. 65\\u201372, 2005.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            656.9893216000002\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            688.8699216000001\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            688.8699216000001\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            656.9893216000002\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"8e2525b0a210f59e5d2ff70067d189da\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"6d53ac4de7ff43ee7170c9d610e98c1d\",\n",
      "    \"text\": \"Huiwen Chang, Han Zhang, Jarred Barber, AJ Maschinot, Jose Lezama, Lu Jiang, Ming-Hsuan Yang, Kevin Murphy, William T Freeman, Michael Rubinstein, et al. Muse: Text-to-image gen- eration via masked generative transformers. arXiv preprint arXiv:2301.00704, 2023.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999989,\n",
      "            700.1333216000002\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999989,\n",
      "            732.0139216000001\n",
      "          ],\n",
      "          [\n",
      "            504.0037873999997,\n",
      "            732.0139216000001\n",
      "          ],\n",
      "          [\n",
      "            504.0037873999997,\n",
      "            700.1333216000002\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"parent_id\": \"8e2525b0a210f59e5d2ff70067d189da\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Footer\",\n",
      "    \"element_id\": \"72a6c9741baf5316bd3b56c4cff4bde9\",\n",
      "    \"text\": \"11\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            301.0189999999999,\n",
      "            751.9393216000001\n",
      "          ],\n",
      "          [\n",
      "            301.0189999999999,\n",
      "            761.9019216000002\n",
      "          ],\n",
      "          [\n",
      "            310.98159999999984,\n",
      "            761.9019216000002\n",
      "          ],\n",
      "          [\n",
      "            310.98159999999984,\n",
      "            751.9393216000001\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 11,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"f4297e1cf707a5cf689d48e51fd8b283\",\n",
      "    \"text\": \"Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality, March 2023.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            84.01332159999993\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            115.89392159999989\n",
      "          ],\n",
      "          [\n",
      "            504.0037873999998,\n",
      "            115.89392159999989\n",
      "          ],\n",
      "          [\n",
      "            504.0037873999998,\n",
      "            84.01332159999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 12,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"3d274e07982773b3e6de54a46c0700f6\",\n",
      "    \"text\": \"Kevin Crowston. Amazon mechanical turk: A research tool for organizations and information sys- In Shaping the Future of ICT Research. Methods and Approaches: IFIP WG tems scholars. 8.2, Working Conference, Tampa, FL, USA, December 13-14, 2012. Proceedings, pp. 210\\u2013221. Springer, 2012.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            124.5763215999998\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            167.41492159999973\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            167.41492159999973\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            124.5763215999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 12,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"119df14259b348ceab34bb680b71a5ec\",\n",
      "    \"text\": \"Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Junqi Zhao, Weisheng Wang, Boyang Li, Pascale Fung, and Steven Hoi. Instructblip: Towards general-purpose vision-language models with instruction tuning, 2023.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            176.09732159999965\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            207.9779215999996\n",
      "          ],\n",
      "          [\n",
      "            504.00378739999974,\n",
      "            207.9779215999996\n",
      "          ],\n",
      "          [\n",
      "            504.00378739999974,\n",
      "            176.09732159999965\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 12,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"717b8deaa7e055569e2678e39cc0a68b\",\n",
      "    \"text\": \"Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. Qlora: Efficient finetuning\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            216.65932159999954\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            226.6219215999996\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            226.6219215999996\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            216.65932159999954\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 12,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"e06e3113e17e228316ce19fd34b3fa66\",\n",
      "    \"text\": \"of quantized llms. arXiv preprint arXiv:2305.14314, 2023.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            117.96299999999997,\n",
      "            227.3891817999995\n",
      "          ],\n",
      "          [\n",
      "            117.96299999999997,\n",
      "            237.58092159999956\n",
      "          ],\n",
      "          [\n",
      "            352.80015,\n",
      "            237.58092159999956\n",
      "          ],\n",
      "          [\n",
      "            352.80015,\n",
      "            227.3891817999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 12,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"86c9113b8262beb056f019e529c0525b\",\n",
      "    \"text\": \"Prafulla Dhariwal and Alexander Nichol. Diffusion models beat gans on image synthesis. Advances\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            246.0331817999995\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            256.22492159999956\n",
      "          ],\n",
      "          [\n",
      "            503.99968319999994,\n",
      "            256.22492159999956\n",
      "          ],\n",
      "          [\n",
      "            503.99968319999994,\n",
      "            246.0331817999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 12,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"11a8831333615d9468116d9d28a67597\",\n",
      "    \"text\": \"in neural information processing systems, 34:8780\\u20138794, 2021.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            117.96299999999997,\n",
      "            256.99218179999946\n",
      "          ],\n",
      "          [\n",
      "            117.96299999999997,\n",
      "            267.1839215999995\n",
      "          ],\n",
      "          [\n",
      "            371.6893528,\n",
      "            267.1839215999995\n",
      "          ],\n",
      "          [\n",
      "            371.6893528,\n",
      "            256.99218179999946\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 12,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"a9729555f30c853ab8c61ba28cd794ea\",\n",
      "    \"text\": \"Jiazhan Feng, Qingfeng Sun, Can Xu, Pu Zhao, Yaming Yang, Chongyang Tao, Dongyan Zhao, and Qingwei Lin. Mmdialog: A large-scale multi-turn dialogue dataset towards multi-modal open-domain conversation. arXiv preprint arXiv:2211.05719, 2022.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999994,\n",
      "            275.8663215999994\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999994,\n",
      "            307.74692159999944\n",
      "          ],\n",
      "          [\n",
      "            504.0037873999998,\n",
      "            307.74692159999944\n",
      "          ],\n",
      "          [\n",
      "            504.0037873999998,\n",
      "            275.8663215999994\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 12,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"5cb4aa9a71cdf61364e2e43b698414ed\",\n",
      "    \"text\": \"Yuying Ge, Yixiao Ge, Ziyun Zeng, Xintao Wang, and Ying Shan. Planting a seed of vision in large\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999994,\n",
      "            316.42832159999944\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999994,\n",
      "            326.39092159999944\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999997,\n",
      "            326.39092159999944\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999997,\n",
      "            316.42832159999944\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 12,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"334957f5bd421958cfcf528655f9374c\",\n",
      "    \"text\": \"language model. arXiv preprint arXiv:2307.08041, 2023.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            117.96299999999994,\n",
      "            327.15818179999945\n",
      "          ],\n",
      "          [\n",
      "            117.96299999999994,\n",
      "            337.34992159999945\n",
      "          ],\n",
      "          [\n",
      "            346.98214999999993,\n",
      "            337.34992159999945\n",
      "          ],\n",
      "          [\n",
      "            346.98214999999993,\n",
      "            327.15818179999945\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 12,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"dd6f1acd1ae7e2f0a6950f7c798d8c56\",\n",
      "    \"text\": \"Jing Gu, Yilin Wang, Nanxuan Zhao, Tsu-Jui Fu, Wei Xiong, Qing Liu, Zhifei Zhang, He Zhang, Jianming Zhang, HyunJoon Jung, and Xin Eric Wang. Photoswap: Personalized subject swapping in images, 2023.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999991,\n",
      "            346.0313215999995\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999991,\n",
      "            377.91192159999946\n",
      "          ],\n",
      "          [\n",
      "            504.00378739999957,\n",
      "            377.91192159999946\n",
      "          ],\n",
      "          [\n",
      "            504.00378739999957,\n",
      "            346.0313215999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 12,\n",
      "      \"parent_id\": \"334957f5bd421958cfcf528655f9374c\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"4af282d3e0c2aec314917b6490abaff1\",\n",
      "    \"text\": \"Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilibrium. Advances in neural information processing systems, 30, 2017.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999991,\n",
      "            386.5943215999995\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999991,\n",
      "            418.47392159999947\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            418.47392159999947\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            386.5943215999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 12,\n",
      "      \"parent_id\": \"334957f5bd421958cfcf528655f9374c\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"7b6df0979b34653ce1c57a779ae1befb\",\n",
      "    \"text\": \"Jonathan Ho and Tim Salimans.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999989,\n",
      "            427.1563215999995\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999989,\n",
      "            437.11892159999945\n",
      "          ],\n",
      "          [\n",
      "            255.90475959999992,\n",
      "            437.11892159999945\n",
      "          ],\n",
      "          [\n",
      "            255.90475959999992,\n",
      "            427.1563215999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 12,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"45be51106f1a94c8c9692d998b88b871\",\n",
      "    \"text\": \"Classifier-free diffusion guidance.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            276.03917419999993,\n",
      "            427.1563215999995\n",
      "          ],\n",
      "          [\n",
      "            276.03917419999993,\n",
      "            437.11892159999945\n",
      "          ],\n",
      "          [\n",
      "            421.7820495999999,\n",
      "            437.11892159999945\n",
      "          ],\n",
      "          [\n",
      "            421.7820495999999,\n",
      "            427.1563215999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 12,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"9bf911f884623ee1cbec5ec880d2dac9\",\n",
      "    \"text\": \"arXiv preprint\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            441.9139999999999,\n",
      "            426.92718179999946\n",
      "          ],\n",
      "          [\n",
      "            441.9139999999999,\n",
      "            436.88978179999947\n",
      "          ],\n",
      "          [\n",
      "            504.0009231999998,\n",
      "            436.88978179999947\n",
      "          ],\n",
      "          [\n",
      "            504.0009231999998,\n",
      "            426.92718179999946\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 12,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"74189a57055f8e3c7c4d7978216a051a\",\n",
      "    \"text\": \"arXiv:2207.12598, 2022.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            117.96299999999985,\n",
      "            437.88618179999946\n",
      "          ],\n",
      "          [\n",
      "            117.96299999999985,\n",
      "            448.07792159999946\n",
      "          ],\n",
      "          [\n",
      "            218.13614999999984,\n",
      "            448.07792159999946\n",
      "          ],\n",
      "          [\n",
      "            218.13614999999984,\n",
      "            437.88618179999946\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 12,\n",
      "      \"parent_id\": \"9bf911f884623ee1cbec5ec880d2dac9\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"eeff0bec0aebb8a1fcde6f7d83743ad9\",\n",
      "    \"text\": \"Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De Laroussilhe, An- drea Gesmundo, Mona Attariyan, and Sylvain Gelly. Parameter-efficient transfer learning for nlp. In International Conference on Machine Learning, pp. 2790\\u20132799. PMLR, 2019.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999986,\n",
      "            456.75932159999945\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999986,\n",
      "            488.63992159999947\n",
      "          ],\n",
      "          [\n",
      "            504.0037873999996,\n",
      "            488.63992159999947\n",
      "          ],\n",
      "          [\n",
      "            504.0037873999996,\n",
      "            456.75932159999945\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 12,\n",
      "      \"parent_id\": \"9bf911f884623ee1cbec5ec880d2dac9\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"c26d7667f269a561a2d30448d96502b6\",\n",
      "    \"text\": \"Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, arXiv preprint\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.9999999999998,\n",
      "            497.32232159999944\n",
      "          ],\n",
      "          [\n",
      "            107.9999999999998,\n",
      "            518.0137817999995\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999967,\n",
      "            518.0137817999995\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999967,\n",
      "            497.32232159999944\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 12,\n",
      "      \"parent_id\": \"9bf911f884623ee1cbec5ec880d2dac9\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"0057dfc493e2528ba3482f7c5cd052c1\",\n",
      "    \"text\": \"and Weizhu Chen. Lora: Low-rank adaptation of large language models. arXiv:2106.09685, 2021.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            117.9629999999998,\n",
      "            508.2803215999995\n",
      "          ],\n",
      "          [\n",
      "            117.9629999999998,\n",
      "            529.2019215999994\n",
      "          ],\n",
      "          [\n",
      "            434.29547519999977,\n",
      "            529.2019215999994\n",
      "          ],\n",
      "          [\n",
      "            434.29547519999977,\n",
      "            508.2803215999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 12,\n",
      "      \"parent_id\": \"9bf911f884623ee1cbec5ec880d2dac9\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"0c35e7f95b7159542ed8cedc87861676\",\n",
      "    \"text\": \"Ting-Hao K. Huang, Francis Ferraro, Nasrin Mostafazadeh, Ishan Misra, Jacob Devlin, Aishwarya Agrawal, Ross Girshick, Xiaodong He, Pushmeet Kohli, Dhruv Batra, et al. Visual storytelling. In 15th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL 2016), 2016.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999979,\n",
      "            537.8843215999996\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999979,\n",
      "            580.7239215999996\n",
      "          ],\n",
      "          [\n",
      "            504.0037873999995,\n",
      "            580.7239215999996\n",
      "          ],\n",
      "          [\n",
      "            504.0037873999995,\n",
      "            537.8843215999996\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 12,\n",
      "      \"parent_id\": \"9bf911f884623ee1cbec5ec880d2dac9\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"75f73a19752f28677716d065b60c428e\",\n",
      "    \"text\": \"Diederik P Kingma and Max Welling. Auto-encoding variational bayes.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999979,\n",
      "            589.4053215999995\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999979,\n",
      "            599.3679215999996\n",
      "          ],\n",
      "          [\n",
      "            429.4233637999997,\n",
      "            599.3679215999996\n",
      "          ],\n",
      "          [\n",
      "            429.4233637999997,\n",
      "            589.4053215999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 12,\n",
      "      \"parent_id\": \"9bf911f884623ee1cbec5ec880d2dac9\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"2628fa108945de8140c077b978729594\",\n",
      "    \"text\": \"arXiv preprint\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            443.73399999999975,\n",
      "            589.1761817999995\n",
      "          ],\n",
      "          [\n",
      "            443.73399999999975,\n",
      "            599.1387817999995\n",
      "          ],\n",
      "          [\n",
      "            503.99776739999976,\n",
      "            599.1387817999995\n",
      "          ],\n",
      "          [\n",
      "            503.99776739999976,\n",
      "            589.1761817999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 12,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"87f718b16e5026e77a2a64bae923239d\",\n",
      "    \"text\": \"arXiv:1312.6114, 2013.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            117.96299999999974,\n",
      "            600.1351817999996\n",
      "          ],\n",
      "          [\n",
      "            117.96299999999974,\n",
      "            610.3269215999995\n",
      "          ],\n",
      "          [\n",
      "            213.15514999999974,\n",
      "            610.3269215999995\n",
      "          ],\n",
      "          [\n",
      "            213.15514999999974,\n",
      "            600.1351817999996\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 12,\n",
      "      \"parent_id\": \"2628fa108945de8140c077b978729594\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"a9ce10a749108a8a01a7993d865b96e0\",\n",
      "    \"text\": \"Jing Yu Koh, Daniel Fried, and Ruslan Salakhutdinov. Generating images with multimodal language\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999976,\n",
      "            619.0083215999996\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999976,\n",
      "            628.9709215999995\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999994,\n",
      "            628.9709215999995\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999994,\n",
      "            619.0083215999996\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 12,\n",
      "      \"parent_id\": \"2628fa108945de8140c077b978729594\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"d1c0c9f053d534c6529530f8745d73ee\",\n",
      "    \"text\": \"models. arXiv preprint arXiv:2305.17216, 2023.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            117.96299999999975,\n",
      "            629.7381817999996\n",
      "          ],\n",
      "          [\n",
      "            117.96299999999975,\n",
      "            639.9299215999995\n",
      "          ],\n",
      "          [\n",
      "            312.4021499999998,\n",
      "            639.9299215999995\n",
      "          ],\n",
      "          [\n",
      "            312.4021499999998,\n",
      "            629.7381817999996\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 12,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"883731403e64482928136a06bcdfcd5c\",\n",
      "    \"text\": \"Bo Li, Yuanhan Zhang, Liangyu Chen, Jinghao Wang, Jingkang Yang, and Ziwei Liu. Otter: A multi-modal model with in-context instruction tuning. arXiv preprint arXiv:2305.03726, 2023a.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999977,\n",
      "            648.6123215999995\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999977,\n",
      "            669.5339215999995\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999955,\n",
      "            669.5339215999995\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999955,\n",
      "            648.6123215999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 12,\n",
      "      \"parent_id\": \"d1c0c9f053d534c6529530f8745d73ee\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"6a2de4ff43115ab4289d89e58426df65\",\n",
      "    \"text\": \"Dongxu Li, Junnan Li, Hung Le, Guangsen Wang, Silvio Savarese, and Steven C.H. Hoi. LAVIS: A one-stop library for language-vision intelligence. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations), pp. 31\\u2013 41, Toronto, Canada, July 2023b. Association for Computational Linguistics. URL https: //aclanthology.org/2023.acl-demo.3.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999983,\n",
      "            678.2153215999996\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999983,\n",
      "            732.0139215999995\n",
      "          ],\n",
      "          [\n",
      "            504.0033955999998,\n",
      "            732.0139215999995\n",
      "          ],\n",
      "          [\n",
      "            504.0033955999998,\n",
      "            678.2153215999996\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"), pp . 31 41 , Toronto , Canada , July2023b . AssociationforComputationalLinguistics . URLhttps\",\n",
      "          \"url\": \"https://aclanthology.org/2023.acl-demo.3\",\n",
      "          \"start_index\": 267\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"// aclanthology . org / 2023 . acl - demo . 3\",\n",
      "          \"url\": \"https://aclanthology.org/2023.acl-demo.3\",\n",
      "          \"start_index\": 365\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 12,\n",
      "      \"parent_id\": \"d1c0c9f053d534c6529530f8745d73ee\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Footer\",\n",
      "    \"element_id\": \"86ceda2ff32eeea5ababe23bdfe68861\",\n",
      "    \"text\": \"12\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            301.0189999999998,\n",
      "            751.9393215999996\n",
      "          ],\n",
      "          [\n",
      "            301.0189999999998,\n",
      "            761.9019215999996\n",
      "          ],\n",
      "          [\n",
      "            310.98159999999973,\n",
      "            761.9019215999996\n",
      "          ],\n",
      "          [\n",
      "            310.98159999999973,\n",
      "            751.9393215999996\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 12,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"1d18a95636f344ce715dcd3fba227b8e\",\n",
      "    \"text\": \"Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi. Blip-2: Bootstrapping language- arXiv preprint\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            84.01332159999993\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            104.70578179999995\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999967,\n",
      "            104.70578179999995\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999967,\n",
      "            84.01332159999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 13,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"d47b92a87096ce4664b1a60cb0d475d5\",\n",
      "    \"text\": \"image pre-training with frozen image encoders and large language models. arXiv:2301.12597, 2023c.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            117.963,\n",
      "            94.97232159999987\n",
      "          ],\n",
      "          [\n",
      "            117.963,\n",
      "            115.89392159999989\n",
      "          ],\n",
      "          [\n",
      "            434.75375479999997,\n",
      "            115.89392159999989\n",
      "          ],\n",
      "          [\n",
      "            434.75375479999997,\n",
      "            94.97232159999987\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 13,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"cce006eb897e7ffba894dae54eec104f\",\n",
      "    \"text\": \"Xiang Lisa Li and Percy Liang. Prefix-tuning: Optimizing continuous prompts for generation. arXiv\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000003,\n",
      "            125.03218179999988\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000003,\n",
      "            135.22392159999993\n",
      "          ],\n",
      "          [\n",
      "            503.9998972000001,\n",
      "            135.22392159999993\n",
      "          ],\n",
      "          [\n",
      "            503.9998972000001,\n",
      "            125.03218179999988\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 13,\n",
      "      \"parent_id\": \"d47b92a87096ce4664b1a60cb0d475d5\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"94971ee1213d0e9b9f00bf4b89bf5dc7\",\n",
      "    \"text\": \"preprint arXiv:2101.00190, 2021.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            117.96300000000008,\n",
      "            135.99018179999985\n",
      "          ],\n",
      "          [\n",
      "            117.96300000000008,\n",
      "            146.1819215999999\n",
      "          ],\n",
      "          [\n",
      "            252.91515000000007,\n",
      "            146.1819215999999\n",
      "          ],\n",
      "          [\n",
      "            252.91515000000007,\n",
      "            135.99018179999985\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 13,\n",
      "      \"parent_id\": \"d47b92a87096ce4664b1a60cb0d475d5\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"4f185d26c8e8830739ba09f4ebea0c87\",\n",
      "    \"text\": \"Chin-Yew Lin. Rouge: A package for automatic evaluation of summaries. In Text summarization\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000009,\n",
      "            155.3201817999999\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000009,\n",
      "            165.51192159999994\n",
      "          ],\n",
      "          [\n",
      "            503.99922300000003,\n",
      "            165.51192159999994\n",
      "          ],\n",
      "          [\n",
      "            503.99922300000003,\n",
      "            155.3201817999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 13,\n",
      "      \"parent_id\": \"d47b92a87096ce4664b1a60cb0d475d5\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"098ac88b7c950ca0f13d960d05e8c4b8\",\n",
      "    \"text\": \"branches out, pp. 74\\u201381, 2004.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            117.96300000000008,\n",
      "            166.27918179999983\n",
      "          ],\n",
      "          [\n",
      "            117.96300000000008,\n",
      "            176.47092159999988\n",
      "          ],\n",
      "          [\n",
      "            241.63785000000004,\n",
      "            176.47092159999988\n",
      "          ],\n",
      "          [\n",
      "            241.63785000000004,\n",
      "            166.27918179999983\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 13,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"ee29ff759e89977e38d74dd3d6132145\",\n",
      "    \"text\": \"Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, and Mark Chen. Glide: Towards photorealistic image generation and editing with text-guided diffusion models. arXiv preprint arXiv:2112.10741, 2021.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000009,\n",
      "            185.83732159999977\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000009,\n",
      "            217.71792159999973\n",
      "          ],\n",
      "          [\n",
      "            504.00378739999974,\n",
      "            217.71792159999973\n",
      "          ],\n",
      "          [\n",
      "            504.00378739999974,\n",
      "            185.83732159999977\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 13,\n",
      "      \"parent_id\": \"098ac88b7c950ca0f13d960d05e8c4b8\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"74f17bb04b9dba61bf47c78467a9169c\",\n",
      "    \"text\": \"OpenAI. Gpt-4 technical report, 2023.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000006,\n",
      "            227.0843215999996\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000006,\n",
      "            237.04692159999968\n",
      "          ],\n",
      "          [\n",
      "            261.54359120000015,\n",
      "            237.04692159999968\n",
      "          ],\n",
      "          [\n",
      "            261.54359120000015,\n",
      "            227.0843215999996\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 13,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"28aa71465ed833c8290b06c93e74e4e8\",\n",
      "    \"text\": \"Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems, 35: 27730\\u201327744, 2022.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000006,\n",
      "            246.41432159999965\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000006,\n",
      "            289.2529215999996\n",
      "          ],\n",
      "          [\n",
      "            504.0037873999997,\n",
      "            289.2529215999996\n",
      "          ],\n",
      "          [\n",
      "            504.0037873999997,\n",
      "            246.41432159999965\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 13,\n",
      "      \"parent_id\": \"74f17bb04b9dba61bf47c78467a9169c\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"18e17115eef1b492996096ac18332644\",\n",
      "    \"text\": \"Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting on association for computational linguistics, pp. 311\\u2013318. Association for Computational Linguistics, 2002.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000003,\n",
      "            298.62032159999956\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000003,\n",
      "            330.5009215999996\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999984,\n",
      "            330.5009215999996\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999984,\n",
      "            298.62032159999956\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 13,\n",
      "      \"parent_id\": \"74f17bb04b9dba61bf47c78467a9169c\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"ae9f10e8cad2ec2d80c7d6b5c70753e3\",\n",
      "    \"text\": \"Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever. Zero-shot text-to-image generation. In International Conference on Machine Learning, pp. 8821\\u20138831. PMLR, 2021.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            339.8673215999996\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            371.7479215999996\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            371.7479215999996\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            339.8673215999996\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 13,\n",
      "      \"parent_id\": \"74f17bb04b9dba61bf47c78467a9169c\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"50cf5269ba1389ca623420be65abdbe9\",\n",
      "    \"text\": \"Scott Reed, Zeynep Akata, Xinchen Yan, Lajanugen Logeswaran, Bernt Schiele, and Honglak Lee. Generative adversarial text to image synthesis. In International conference on machine learning, pp. 1060\\u20131069. PMLR, 2016.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            381.1143215999996\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            412.9949215999996\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            412.9949215999996\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            381.1143215999996\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 13,\n",
      "      \"parent_id\": \"74f17bb04b9dba61bf47c78467a9169c\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"1bb872637e56dc0b3201fe9eed8a78b3\",\n",
      "    \"text\": \"Nils Reimers and Iryna Gurevych. Sentence-bert: Sentence embeddings using siamese bert-\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000003,\n",
      "            422.36132159999966\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000003,\n",
      "            432.3239215999996\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            432.3239215999996\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            422.36132159999966\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 13,\n",
      "      \"parent_id\": \"74f17bb04b9dba61bf47c78467a9169c\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"68563f24f0ed4834cd71589e7ba50fa9\",\n",
      "    \"text\": \"networks. arXiv preprint arXiv:1908.10084, 2019.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            117.96300000000002,\n",
      "            433.0911817999996\n",
      "          ],\n",
      "          [\n",
      "            117.96300000000002,\n",
      "            443.2829215999996\n",
      "          ],\n",
      "          [\n",
      "            320.04315,\n",
      "            443.2829215999996\n",
      "          ],\n",
      "          [\n",
      "            320.04315,\n",
      "            433.0911817999996\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 13,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"3c397a9101d56cb9409fffea668718ba\",\n",
      "    \"text\": \"Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\\u00a8orn Ommer. High- resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF confer- ence on computer vision and pattern recognition, pp. 10684\\u201310695, 2022a.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000003,\n",
      "            452.6003215999996\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000003,\n",
      "            484.5309215999996\n",
      "          ],\n",
      "          [\n",
      "            504.0032974000001,\n",
      "            484.5309215999996\n",
      "          ],\n",
      "          [\n",
      "            504.0032974000001,\n",
      "            452.6003215999996\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 13,\n",
      "      \"parent_id\": \"68563f24f0ed4834cd71589e7ba50fa9\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"5fac339a0e9a4634d1ca99d706056e4b\",\n",
      "    \"text\": \"Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\\u00a8orn Ommer. High-\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000003,\n",
      "            493.84732159999965\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000003,\n",
      "            503.8599215999996\n",
      "          ],\n",
      "          [\n",
      "            503.99822120000005,\n",
      "            503.8599215999996\n",
      "          ],\n",
      "          [\n",
      "            503.99822120000005,\n",
      "            493.84732159999965\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 13,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"25b96624bbbbf6f3fd47b5cc33fabd0c\",\n",
      "    \"text\": \"resolution image synthesis with latent diffusion models. In CVPR, 2022b.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            117.96300000000002,\n",
      "            504.6271817999996\n",
      "          ],\n",
      "          [\n",
      "            117.96300000000002,\n",
      "            514.8189215999996\n",
      "          ],\n",
      "          [\n",
      "            412.14645,\n",
      "            514.8189215999996\n",
      "          ],\n",
      "          [\n",
      "            412.14645,\n",
      "            504.6271817999996\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 13,\n",
      "      \"parent_id\": \"5fac339a0e9a4634d1ca99d706056e4b\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"87b176741c8a2a122b013878dbfec923\",\n",
      "    \"text\": \"Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily L Denton, Kamyar Ghasemipour, Raphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans, et al. Photorealistic text-to-image diffusion models with deep language understanding. Advances in Neural Informa- tion Processing Systems, 35:36479\\u201336494, 2022.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            524.1853215999996\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            567.0249215999996\n",
      "          ],\n",
      "          [\n",
      "            504.00378739999974,\n",
      "            567.0249215999996\n",
      "          ],\n",
      "          [\n",
      "            504.00378739999974,\n",
      "            524.1853215999996\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 13,\n",
      "      \"parent_id\": \"5fac339a0e9a4634d1ca99d706056e4b\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"a583bbc271890105884b2ac3ef35717a\",\n",
      "    \"text\": \"Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved techniques for training gans. Advances in neural information processing systems, 29, 2016.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000001,\n",
      "            576.3913215999996\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000001,\n",
      "            608.2719215999997\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            608.2719215999997\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            576.3913215999996\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 13,\n",
      "      \"parent_id\": \"5fac339a0e9a4634d1ca99d706056e4b\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"a99b74da19a7ccb4363ee34658f7b572\",\n",
      "    \"text\": \"Piyush Sharma, Nan Ding, Sebastian Goodman, and Radu Soricut. Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 2556\\u20132565, 2018.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000003,\n",
      "            617.6393215999997\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000003,\n",
      "            660.4779215999997\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            660.4779215999997\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            617.6393215999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 13,\n",
      "      \"parent_id\": \"5fac339a0e9a4634d1ca99d706056e4b\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"330fb9f56c099cfc403e98b09ce31c2e\",\n",
      "    \"text\": \"Qingfeng Sun, Yujing Wang, Can Xu, Kai Zheng, Yaming Yang, Huang Hu, Fei Xu, Jessica Zhang, Xiubo Geng, and Daxin Jiang. Multimodal dialogue response generation. arXiv preprint arXiv:2110.08515, 2021.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000003,\n",
      "            669.8453215999997\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000003,\n",
      "            701.7249215999997\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999984,\n",
      "            701.7249215999997\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999984,\n",
      "            669.8453215999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 13,\n",
      "      \"parent_id\": \"5fac339a0e9a4634d1ca99d706056e4b\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"feb01f355c42908ec43c6673c1558023\",\n",
      "    \"text\": \"Quan Sun, Yuxin Fang, Ledell Wu, Xinlong Wang, and Yue Cao. Eva-clip: Improved training\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000003,\n",
      "            711.0923215999997\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000003,\n",
      "            721.0549215999996\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            721.0549215999996\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            711.0923215999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 13,\n",
      "      \"parent_id\": \"5fac339a0e9a4634d1ca99d706056e4b\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"086b4b21adf752f82540a6d313e908db\",\n",
      "    \"text\": \"techniques for clip at scale. arXiv preprint arXiv:2303.15389, 2023a.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            117.96300000000002,\n",
      "            721.8221817999996\n",
      "          ],\n",
      "          [\n",
      "            117.96300000000002,\n",
      "            732.0139215999997\n",
      "          ],\n",
      "          [\n",
      "            394.28354440000004,\n",
      "            732.0139215999997\n",
      "          ],\n",
      "          [\n",
      "            394.28354440000004,\n",
      "            721.8221817999996\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 13,\n",
      "      \"parent_id\": \"5fac339a0e9a4634d1ca99d706056e4b\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Footer\",\n",
      "    \"element_id\": \"689453668e0d4671a333480e780699c2\",\n",
      "    \"text\": \"13\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            301.019,\n",
      "            751.9393215999996\n",
      "          ],\n",
      "          [\n",
      "            301.019,\n",
      "            761.9019215999997\n",
      "          ],\n",
      "          [\n",
      "            310.98159999999996,\n",
      "            761.9019215999997\n",
      "          ],\n",
      "          [\n",
      "            310.98159999999996,\n",
      "            751.9393215999996\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 13,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"396f5db0e68bf78a96304d8ecd4a839f\",\n",
      "    \"text\": \"Quan Sun, Qiying Yu, Yufeng Cui, Fan Zhang, Xiaosong Zhang, Yueze Wang, Hongcheng Gao, Jingjing Liu, Tiejun Huang, and Xinlong Wang. Generative pretraining in multimodality. 2023b.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            84.01332159999993\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            104.93492159999994\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999984,\n",
      "            104.93492159999994\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999984,\n",
      "            84.01332159999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 14,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"81834d9591dc1f257a48dcdf32b95542\",\n",
      "    \"text\": \"Hao Tan and Mohit Bansal. Vokenization: Improving language understanding with contextualized,\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            113.90132159999985\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            123.86392159999991\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999996,\n",
      "            123.86392159999991\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999996,\n",
      "            113.90132159999985\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 14,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"754bf7c05db903f14e13583065d51de9\",\n",
      "    \"text\": \"visual-grounded supervision. arXiv preprint arXiv:2010.06775, 2020.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            117.963,\n",
      "            124.63118179999981\n",
      "          ],\n",
      "          [\n",
      "            117.963,\n",
      "            134.82292159999986\n",
      "          ],\n",
      "          [\n",
      "            396.79515000000004,\n",
      "            134.82292159999986\n",
      "          ],\n",
      "          [\n",
      "            396.79515000000004,\n",
      "            124.63118179999981\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 14,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"3b3cee3ea322f0d9e9852fa5a795447c\",\n",
      "    \"text\": \"Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\\u00b4ee Lacroix, Baptiste Rozi`ere, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971, 2023.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            143.7393215999998\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            175.66992159999973\n",
      "          ],\n",
      "          [\n",
      "            504.0001666,\n",
      "            175.66992159999973\n",
      "          ],\n",
      "          [\n",
      "            504.0001666,\n",
      "            143.7393215999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 14,\n",
      "      \"parent_id\": \"754bf7c05db903f14e13583065d51de9\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"7af5c0d0f2e02a32d76d909ce19e9cdb\",\n",
      "    \"text\": \"Maria Tsimpoukelli, Jacob L Menick, Serkan Cabi, SM Eslami, Oriol Vinyals, and Felix Hill. Mul- timodal few-shot learning with frozen language models. Advances in Neural Information Pro- cessing Systems, 34:200\\u2013212, 2021.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            184.63632159999963\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            216.5169215999996\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999967,\n",
      "            216.5169215999996\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999967,\n",
      "            184.63632159999963\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 14,\n",
      "      \"parent_id\": \"754bf7c05db903f14e13583065d51de9\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"3eb25db1e0903f9eca999dcd0bd6f160\",\n",
      "    \"text\": \"Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \\u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural informa- tion processing systems, 30, 2017a.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999999,\n",
      "            225.4833215999995\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999999,\n",
      "            257.36392159999946\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            257.36392159999946\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            225.4833215999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 14,\n",
      "      \"parent_id\": \"754bf7c05db903f14e13583065d51de9\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"23f73dfad29b7b70cbcd5f4534dc685c\",\n",
      "    \"text\": \"Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \\u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural informa- tion processing systems, pp. 5998\\u20136008, 2017b.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            266.33032159999937\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            298.2109215999994\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            298.2109215999994\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            266.33032159999937\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 14,\n",
      "      \"parent_id\": \"754bf7c05db903f14e13583065d51de9\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"43d66bf9d1ed5c4172e2ff519dba498c\",\n",
      "    \"text\": \"Chenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, and Nan Duan. Vi- arXiv preprint\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            307.17732159999935\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            327.8687817999994\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            327.8687817999994\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            307.17732159999935\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 14,\n",
      "      \"parent_id\": \"754bf7c05db903f14e13583065d51de9\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"85b3187eca137542338ae2ef05619ff3\",\n",
      "    \"text\": \"sual chatgpt: Talking, drawing and editing with visual foundation models. arXiv:2303.04671, 2023a.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            117.96299999999997,\n",
      "            318.13532159999943\n",
      "          ],\n",
      "          [\n",
      "            117.96299999999997,\n",
      "            339.0569215999994\n",
      "          ],\n",
      "          [\n",
      "            434.43495159999986,\n",
      "            339.0569215999994\n",
      "          ],\n",
      "          [\n",
      "            434.43495159999986,\n",
      "            318.13532159999943\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 14,\n",
      "      \"parent_id\": \"754bf7c05db903f14e13583065d51de9\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"6982a805be850d907e2058f53345e4ea\",\n",
      "    \"text\": \"Chenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, and Nan Duan. Vi- arXiv preprint\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            348.02332159999935\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            368.7157817999994\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            368.7157817999994\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            348.02332159999935\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 14,\n",
      "      \"parent_id\": \"754bf7c05db903f14e13583065d51de9\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"820c5dfc533f60a5c46a632ce894e56c\",\n",
      "    \"text\": \"sual chatgpt: Talking, drawing and editing with visual foundation models. arXiv:2303.04671, 2023b.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            117.96299999999997,\n",
      "            358.9823215999994\n",
      "          ],\n",
      "          [\n",
      "            117.96299999999997,\n",
      "            379.90392159999936\n",
      "          ],\n",
      "          [\n",
      "            434.43495159999986,\n",
      "            379.90392159999936\n",
      "          ],\n",
      "          [\n",
      "            434.43495159999986,\n",
      "            358.9823215999994\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 14,\n",
      "      \"parent_id\": \"754bf7c05db903f14e13583065d51de9\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"9cbe76076bc3e52ea3c6a6b8d6786128\",\n",
      "    \"text\": \"Shengqiong Wu, Hao Fei, Leigang Qu, Wei Ji, and Tat-Seng Chua. Next-gpt: Any-to-any multi-\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            388.87032159999933\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            398.83292159999934\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            398.83292159999934\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            388.87032159999933\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 14,\n",
      "      \"parent_id\": \"754bf7c05db903f14e13583065d51de9\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"d3420d3bab75438e7e2edf57e4c945db\",\n",
      "    \"text\": \"modal llm, 2023c.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            117.96299999999997,\n",
      "            399.8293215999994\n",
      "          ],\n",
      "          [\n",
      "            117.96299999999997,\n",
      "            409.79192159999934\n",
      "          ],\n",
      "          [\n",
      "            190.47080279999997,\n",
      "            409.79192159999934\n",
      "          ],\n",
      "          [\n",
      "            190.47080279999997,\n",
      "            399.8293215999994\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 14,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"cb7820e80ec0db7d535345617fae668a\",\n",
      "    \"text\": \"Jiahui Yu, Yuanzhong Xu, Jing Yu Koh, Thang Luong, Gunjan Baid, Zirui Wang, Vijay Vasudevan, Alexander Ku, Yinfei Yang, Burcu Karagol Ayan, et al. Scaling autoregressive models for content- rich text-to-image generation. arXiv preprint arXiv:2206.10789, 2(3):5, 2022.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            418.75832159999936\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            450.6389215999993\n",
      "          ],\n",
      "          [\n",
      "            504.0037873999998,\n",
      "            450.6389215999993\n",
      "          ],\n",
      "          [\n",
      "            504.0037873999998,\n",
      "            418.75832159999936\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 14,\n",
      "      \"parent_id\": \"d3420d3bab75438e7e2edf57e4c945db\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"c05cbea62cc434252a9df66278d25ec8\",\n",
      "    \"text\": \"Lili Yu, Bowen Shi, Ramakanth Pasunuru, Benjamin Muller, Olga Golovneva, Tianlu Wang, Arun Babu, Binh Tang, Brian Karrer, Shelly Sheynin, et al. Scaling autoregressive multi-modal models: Pretraining and instruction tuning. arXiv preprint arXiv:2309.02591, 2023.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999994,\n",
      "            459.60532159999934\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999994,\n",
      "            491.4859215999993\n",
      "          ],\n",
      "          [\n",
      "            504.0037873999998,\n",
      "            491.4859215999993\n",
      "          ],\n",
      "          [\n",
      "            504.0037873999998,\n",
      "            459.60532159999934\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 14,\n",
      "      \"parent_id\": \"d3420d3bab75438e7e2edf57e4c945db\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"ce9d8269e3a7bac19ccfbce61f0ed0b2\",\n",
      "    \"text\": \"Renrui Zhang, Rongyao Fang, Peng Gao, Wei Zhang, Kunchang Li, Jifeng Dai, Yu Qiao, and Hong- sheng Li. Tip-adapter: Training-free clip-adapter for better vision-language modeling. arXiv preprint arXiv:2111.03930, 2021.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999994,\n",
      "            500.4523215999993\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999994,\n",
      "            532.3329215999993\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999997,\n",
      "            532.3329215999993\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999997,\n",
      "            500.4523215999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 14,\n",
      "      \"parent_id\": \"d3420d3bab75438e7e2edf57e4c945db\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"def67da2ce0c8461d2bf5a3e86d31e3a\",\n",
      "    \"text\": \"Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny. Minigpt-4: En- hancing vision-language understanding with advanced large language models. arXiv preprint arXiv:2304.10592, 2023.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            541.2993215999993\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            573.1789215999993\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999967,\n",
      "            573.1789215999993\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999967,\n",
      "            541.2993215999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 14,\n",
      "      \"parent_id\": \"d3420d3bab75438e7e2edf57e4c945db\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Footer\",\n",
      "    \"element_id\": \"e09e9152f82da6cb29ff941b636eb06b\",\n",
      "    \"text\": \"14\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            301.019,\n",
      "            751.9393215999993\n",
      "          ],\n",
      "          [\n",
      "            301.019,\n",
      "            761.9019215999994\n",
      "          ],\n",
      "          [\n",
      "            310.98159999999996,\n",
      "            761.9019215999994\n",
      "          ],\n",
      "          [\n",
      "            310.98159999999996,\n",
      "            751.9393215999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 14,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"695586bf7ba8d0d99ed34e89f22a29e1\",\n",
      "    \"text\": \"A IMPLEMENTATION DETAILS\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.299,\n",
      "            82.45112319999998\n",
      "          ],\n",
      "          [\n",
      "            108.299,\n",
      "            94.40632319999997\n",
      "          ],\n",
      "          [\n",
      "            269.35760600000003,\n",
      "            94.40632319999997\n",
      "          ],\n",
      "          [\n",
      "            269.35760600000003,\n",
      "            82.45112319999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 15,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"2faabbbafdcdd1b696f23941df1059c7\",\n",
      "    \"text\": \"In the pretraining stage, we introduce additional voken embeddings at both the input and out- put layers of the Vicuna-7B model, while keeping the embeddings of other tokens fixed. These new embeddings \\u2013 denoted as \\u03b8voken input and \\u03b8voken output \\u2013 along with the feature mapper module (\\u03b8MLP, \\u03b8enc dec, q) are jointly trained on the CC3M dataset, which consists of single text-image pairs. Training is conducted using the AdamW optimizer over two epochs, with a batch size of 48, amount- ing to over 110,000 steps, and a learning rate of 2 \\u00d7 10\\u22124.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999999,\n",
      "            107.58332159999998\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999999,\n",
      "            172.3399215999999\n",
      "          ],\n",
      "          [\n",
      "            504.0043191999999,\n",
      "            172.3399215999999\n",
      "          ],\n",
      "          [\n",
      "            504.0043191999999,\n",
      "            107.58332159999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 15,\n",
      "      \"parent_id\": \"695586bf7ba8d0d99ed34e89f22a29e1\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"ff4cef5d26d3db02ba4eaac6b664e62b\",\n",
      "    \"text\": \"In the subsequent fine-tuning stage, we incorporate LoRA modules \\u2013 denoted as \\u03b8LoRA \\u2013 into Vicuna for the generation of both tokens and vokens. We keep the MLP model \\u03b8MLP and decoder query q fixed. The model is then fine-tuned on interleaved vision-and-language datasets, like VIST and MMDialog. The trainable parameters for this stage are \\u03b8 = {\\u03b8voken input, \\u03b8voken output, \\u03b8LoRA, \\u03b8enc dec}. Training is carried out using the AdamW optimizer over four epochs, with a batch size of 32 and a learning rate of 2 \\u00d7 10\\u22125. Trainable parameters are nearly 6.6 million, and all training can be completed on a server equipped with 4 A6000 GPUs.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999994,\n",
      "            179.09514439999987\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999994,\n",
      "            255.02992159999985\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            255.02992159999985\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            179.09514439999987\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 15,\n",
      "      \"parent_id\": \"695586bf7ba8d0d99ed34e89f22a29e1\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"81178dd55bcef92eb2f50d0648682972\",\n",
      "    \"text\": \"B EXPERIMENTAL SETTINGS\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.29899999999999,\n",
      "            272.3041231999998\n",
      "          ],\n",
      "          [\n",
      "            108.29899999999999,\n",
      "            284.2593231999998\n",
      "          ],\n",
      "          [\n",
      "            263.42475759999996,\n",
      "            284.2593231999998\n",
      "          ],\n",
      "          [\n",
      "            263.42475759999996,\n",
      "            272.3041231999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 15,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"8322d512c6ac6c0196b224aaf177e073\",\n",
      "    \"text\": \"B.1 DATASETS\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.24899999999997,\n",
      "            297.4363215999998\n",
      "          ],\n",
      "          [\n",
      "            108.24899999999997,\n",
      "            307.39892159999977\n",
      "          ],\n",
      "          [\n",
      "            177.45980549999993,\n",
      "            307.39892159999977\n",
      "          ],\n",
      "          [\n",
      "            177.45980549999993,\n",
      "            297.4363215999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 15,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"0cdac77078573ed5746b9d20d55330bc\",\n",
      "    \"text\": \"CC3M (Sharma et al., 2018): Conceptual Captions (CC3M) dataset represents a remarkable col- lection of high-quality image captions, amassing approximately 3.3 million pairs of text and images from the internet. The CC3M dataset\\u2019s diverse content, quality assurance, and support for multi- modal learning make it a valuable asset for researchers and AI enthusiasts. Each dataset sample consists of an image accompanied by a corresponding text description, reflecting the richness of human language and visual perception. However, after accounting for license restrictions and elim- inating invalid image links, the dataset comprises approximately 2.2 million data pairs suitable for training purposes and 10 thousand data pairs designated for validation.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999994,\n",
      "            322.3725833999998\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999994,\n",
      "            409.11692159999984\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999984,\n",
      "            409.11692159999984\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999984,\n",
      "            322.3725833999998\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Sharmaetal .,\",\n",
      "          \"url\": \"cite.sharma2018conceptual\",\n",
      "          \"start_index\": 6\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2018\",\n",
      "          \"url\": \"cite.sharma2018conceptual\",\n",
      "          \"start_index\": 21\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 15,\n",
      "      \"parent_id\": \"8322d512c6ac6c0196b224aaf177e073\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"80b7e31c0ddee693dd38bb5e5d3705f0\",\n",
      "    \"text\": \"VIST (Huang et al., 2016): Visual Storytelling (VIST) dataset is an innovative compilation of visual narratives. The VIST dataset\\u2019s engaging content, narrative structure, and emphasis on se- quential understanding position it as an essential resource for researchers focusing on sequential image understanding. Each sequence within this dataset consists of five images accompanied by corresponding textual narratives, showcasing the intricate interplay between visual imagery and sto- rytelling. Designed to foster creativity and challenge conventional image-captioning models, the dataset provides a platform for training and validating algorithms capable of generating coherent and contextually relevant stories. After eliminating the invalid image links, we got over 65 thou- sand unique photos organized into more than 34 thousand storytelling sequences for training and 4 thousand sequences with 8 thousand images for validation.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999994,\n",
      "            420.5045833999999\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999994,\n",
      "            529.1669215999999\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999984,\n",
      "            529.1669215999999\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999984,\n",
      "            420.5045833999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Huangetal .,\",\n",
      "          \"url\": \"cite.huang2016visual\",\n",
      "          \"start_index\": 6\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2016\",\n",
      "          \"url\": \"cite.huang2016visual\",\n",
      "          \"start_index\": 20\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 15,\n",
      "      \"parent_id\": \"8322d512c6ac6c0196b224aaf177e073\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"b9495f7b4209ac584ae915c269b7f1ce\",\n",
      "    \"text\": \"MMDialog (Feng et al., 2022): Multi-Modal Dialogue (MMDialog) dataset stands as the largest collection of multimodal conversation dialogues. The MMDialog dataset\\u2019s extensive scale, real human-human chat content, and emphasis on multimodal open-domain conversations position it as an unparalleled asset for researchers and practitioners in artificial intelligence. Each dialogue within this dataset typically includes 2.59 images, integrated anywhere within the conversation, showcasing the complex interplay between text and visual elements. Designed to mirror real-world conversational dynamics, the dataset is a robust platform for developing, training, and validating algorithms capable of understanding and generating coherent dialogues that seamlessly blend textual and visual information.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999994,\n",
      "            540.5545834\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999994,\n",
      "            638.2579215999999\n",
      "          ],\n",
      "          [\n",
      "            504.0045216,\n",
      "            638.2579215999999\n",
      "          ],\n",
      "          [\n",
      "            504.0045216,\n",
      "            540.5545834\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Fengetal .,\",\n",
      "          \"url\": \"cite.feng2022mmdialog\",\n",
      "          \"start_index\": 10\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"2022\",\n",
      "          \"url\": \"cite.feng2022mmdialog\",\n",
      "          \"start_index\": 23\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 15,\n",
      "      \"parent_id\": \"8322d512c6ac6c0196b224aaf177e073\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"d3a37f0eb0044c6021efba904e2cd27a\",\n",
      "    \"text\": \"B.2 DATA FORMAT\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.24899999999994,\n",
      "            653.2093216\n",
      "          ],\n",
      "          [\n",
      "            108.24899999999994,\n",
      "            663.1719216\n",
      "          ],\n",
      "          [\n",
      "            195.77596469999995,\n",
      "            663.1719216\n",
      "          ],\n",
      "          [\n",
      "            195.77596469999995,\n",
      "            653.2093216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 15,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"2bf75b76e62ffef7dc6607694ab2c4e9\",\n",
      "    \"text\": \"Pretraining Stage In the pretraining stage, we aim to synchronize the generative voken with the text-to-image model\\u2019s conditional feature, focusing on single-turn text-image pairs. To achieve this, we utilize data from the CC3M dataset, constructing training samples by appending vokens as image placeholders after the captions, such as \\u201ca big black dog [IMG1] . . . [IMGn].\\u201d The Language Model (LLM) is then tasked with only generating these placeholders for text creation, and the correspond-\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999993,\n",
      "            678.1455834\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999993,\n",
      "            732.0139216\n",
      "          ],\n",
      "          [\n",
      "            504.0038945999998,\n",
      "            732.0139216\n",
      "          ],\n",
      "          [\n",
      "            504.0038945999998,\n",
      "            678.1455834\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 15,\n",
      "      \"parent_id\": \"d3a37f0eb0044c6021efba904e2cd27a\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Footer\",\n",
      "    \"element_id\": \"f0476706b48cda16bf5a818344f07603\",\n",
      "    \"text\": \"15\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            301.01899999999995,\n",
      "            751.9393216\n",
      "          ],\n",
      "          [\n",
      "            301.01899999999995,\n",
      "            761.9019216\n",
      "          ],\n",
      "          [\n",
      "            310.9815999999999,\n",
      "            761.9019216\n",
      "          ],\n",
      "          [\n",
      "            310.9815999999999,\n",
      "            751.9393216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 15,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"07014c780bf71884c6bc2dbb9a326346\",\n",
      "    \"text\": \"ing output hidden features are further employed to compute the conditional generation loss with the ground truth image.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            84.01332159999993\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            104.93492159999994\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999995,\n",
      "            104.93492159999994\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999995,\n",
      "            84.01332159999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 16,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"c2001695c05231f37aa2efd4fba492c6\",\n",
      "    \"text\": \"Fine-tuning Stage In this stage, we utilize the VIST and MMDialog datasets, which contain multi-turn multimodal data. During training, we integrate placeholders for input images, such as \\u2019<Img><ImageHere></Img>\\u2019, into the input text prompts when applicable. These prompts also encompass various instructions corresponding to different task types, with outputs manifesting as pure-text, pure-voken, or text-voken combinations. Below, we present example templates in the VIST dataset to illustrate the different task types:\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            116.32258339999987\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            181.14892159999965\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999997,\n",
      "            181.14892159999965\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999997,\n",
      "            116.32258339999987\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 16,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"37bd56d4317ef5cd68c3f19bbda80aab\",\n",
      "    \"text\": \"Text Generation: Input: \\u201c<History Context> What happens in the next scene image: <Img><ImageHere></Img>\\u201d; Output: \\u201c<Text Description>\\u201d\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            135.39699999999996,\n",
      "            191.3041443999996\n",
      "          ],\n",
      "          [\n",
      "            135.39699999999996,\n",
      "            212.4449215999996\n",
      "          ],\n",
      "          [\n",
      "            504.0007344,\n",
      "            212.4449215999996\n",
      "          ],\n",
      "          [\n",
      "            504.0007344,\n",
      "            191.3041443999996\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 16,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"525298797e0e89c0cc39018896419660\",\n",
      "    \"text\": \"Image Generation: Input: \\u201c<History Context> Generate an image with the scene de- scription: [Text Description]\\u201d; Output: \\u201c[IMG1]...[IMGn]\\u201d\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            135.397,\n",
      "            216.9141443999995\n",
      "          ],\n",
      "          [\n",
      "            135.397,\n",
      "            238.0549215999995\n",
      "          ],\n",
      "          [\n",
      "            503.99783960000013,\n",
      "            238.0549215999995\n",
      "          ],\n",
      "          [\n",
      "            503.99783960000013,\n",
      "            216.9141443999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 16,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"ListItem\",\n",
      "    \"element_id\": \"326868c3cde94638bbf16e6d16af6649\",\n",
      "    \"text\": \"Text-Image Generation: Input: \\u201c<History Context> What should happen then?\\u201d; Output: \\u201c<Text Description> [IMG1]...[IMGn]\\u201d\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            135.39700000000005,\n",
      "            242.5241443999994\n",
      "          ],\n",
      "          [\n",
      "            135.39700000000005,\n",
      "            263.6649215999994\n",
      "          ],\n",
      "          [\n",
      "            504.00245780000006,\n",
      "            263.6649215999994\n",
      "          ],\n",
      "          [\n",
      "            504.00245780000006,\n",
      "            242.5241443999994\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 16,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"8b640f2c4e1dda711aef9b014f236c19\",\n",
      "    \"text\": \"By structuring the input and output in this manner, we create a flexible framework that accommo- dates various multimodal tasks, enhancing the model\\u2019s ability to interpret and generate textual and visual content. The history context in the VIST dataset includes all previous story steps with texts and images. In the MMDialog dataset, due to the limitation of computational resources, we only use up to one previous turn as the history context, and all data are formatted into the dialog.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000006,\n",
      "            274.03832159999934\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000006,\n",
      "            327.83692159999936\n",
      "          ],\n",
      "          [\n",
      "            504.0033874,\n",
      "            327.83692159999936\n",
      "          ],\n",
      "          [\n",
      "            504.0033874,\n",
      "            274.03832159999934\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 16,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"d25e1ee5431b78fd620e9262fe691674\",\n",
      "    \"text\": \"C MORE EXPERIMENTS\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.29900000000006,\n",
      "            344.94012319999933\n",
      "          ],\n",
      "          [\n",
      "            108.29900000000006,\n",
      "            356.8953231999994\n",
      "          ],\n",
      "          [\n",
      "            237.19149530000007,\n",
      "            356.8953231999994\n",
      "          ],\n",
      "          [\n",
      "            237.19149530000007,\n",
      "            344.94012319999933\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 16,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"51da03a097fa7e8261d9e0b09df4cae2\",\n",
      "    \"text\": \"C.1 EVALUATION OF GUIDANCE SCALE\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.24900000000005,\n",
      "            369.9003215999994\n",
      "          ],\n",
      "          [\n",
      "            108.24900000000005,\n",
      "            379.86292159999937\n",
      "          ],\n",
      "          [\n",
      "            283.1093996000001,\n",
      "            379.86292159999937\n",
      "          ],\n",
      "          [\n",
      "            283.1093996000001,\n",
      "            369.9003215999994\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 16,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"dc98c28f049e1ebb6f7966720f9f7b56\",\n",
      "    \"text\": \"Since our model incorporates CFG, evaluating how different guidance scales affect image generation is crucial. Therefore, we plotted several line charts in Fig 5 to depict the changes in metrics with varying guidance scales. The figures reveal that the stable diffusion model and our model generate better images as the guidance scale increases. However, when the scale exceeds 10, the image semantic coherence stabilizes while the image quality declines. This suggests that the guidance scale should be set within a reasonable range for optimal image generation.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000006,\n",
      "            390.42332159999944\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000006,\n",
      "            455.1809215999994\n",
      "          ],\n",
      "          [\n",
      "            504.00338740000007,\n",
      "            455.1809215999994\n",
      "          ],\n",
      "          [\n",
      "            504.00338740000007,\n",
      "            390.42332159999944\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"whenthescaleexceeds10\",\n",
      "          \"url\": \"figure.caption.12\",\n",
      "          \"start_index\": 354\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 16,\n",
      "      \"parent_id\": \"51da03a097fa7e8261d9e0b09df4cae2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"980991ce0c84d2c28b6a80872be75d15\",\n",
      "    \"text\": \"C.2 EVALUATION OF VOKEN NUMBER\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.24900000000005,\n",
      "            469.9603215999995\n",
      "          ],\n",
      "          [\n",
      "            108.24900000000005,\n",
      "            479.9229215999994\n",
      "          ],\n",
      "          [\n",
      "            277.5462903,\n",
      "            479.9229215999994\n",
      "          ],\n",
      "          [\n",
      "            277.5462903,\n",
      "            469.9603215999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 16,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"2b2a51c3258be989813b88dbde6c65d0\",\n",
      "    \"text\": \"The voken features in our model are directly utilized as conditions in the text-to-image model, leading to the expectation that an increase in the number of vokens would enhance the model\\u2019s representative capabilities. To validate this hypothesis, we experimented by training the model with varying numbers of vokens, ranging from 1 to 8. As illustrated in Fig 6, the model\\u2019s performance consistently improves with adding more vokens. This improvement is particularly noticeable when the number of vokens is increased from 1 to 4, highlighting the significant role that vokens play in enhancing the model\\u2019s effectiveness.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000006,\n",
      "            490.4833215999995\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000006,\n",
      "            566.1999215999995\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            566.1999215999995\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            490.4833215999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \",\",\n",
      "          \"url\": \"figure.caption.14\",\n",
      "          \"start_index\": 362\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 16,\n",
      "      \"parent_id\": \"980991ce0c84d2c28b6a80872be75d15\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"3cb572ffc0730ceb42f77f1bc4fa40e6\",\n",
      "    \"text\": \"C.3 ABLATION OF MODEL DESIGNS\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.24900000000005,\n",
      "            580.9803215999995\n",
      "          ],\n",
      "          [\n",
      "            108.24900000000005,\n",
      "            590.9429215999995\n",
      "          ],\n",
      "          [\n",
      "            268.2911408000001,\n",
      "            590.9429215999995\n",
      "          ],\n",
      "          [\n",
      "            268.2911408000001,\n",
      "            580.9803215999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 16,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"b2ee7ad6417a8d9a31ee8f6e7fc1f1c7\",\n",
      "    \"text\": \"This section explores alternatives to the transformer encoder/decoder architecture discussed in the main paper. Specifically, we experimented with two additional settings: Fixed Queries, and Decoder-Only model where learnable queries are fed into the transformer decoder. For the fixed queries design, we initialize queries the same as learnable queries experiments in the main paper and keep them fixed during training. In the decoder-only approach, we utilize solely the transformer decoder and apply padding to the decoder\\u2019s output, ensuring that the token length reaches 77. This length adjustment allows the output to be compatible with the Stable Diffusion encoder. The results of these experiments are detailed in Table 8. From the results of MiniGPT-5 with fixed queries, we find there exists a slight trade-off between image-text coherence and image qualities, where fixed queries can lead to higher image metrics (IS and FID) but lower CLIP similarities. Meanwhile, MiniGPT-5 consistently outperforms the Decoder-Only results in all four evaluation metrics, vali- dating the robustness and efficacy of MiniGPT-5\\u2019s transformer encoder/decoder architecture design.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000006,\n",
      "            601.5033215999995\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000006,\n",
      "            732.0139215999995\n",
      "          ],\n",
      "          [\n",
      "            504.0033874,\n",
      "            732.0139215999995\n",
      "          ],\n",
      "          [\n",
      "            504.0033874,\n",
      "            601.5033215999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \".\",\n",
      "          \"url\": \"table.caption.13\",\n",
      "          \"start_index\": 725\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 16,\n",
      "      \"parent_id\": \"3cb572ffc0730ceb42f77f1bc4fa40e6\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Footer\",\n",
      "    \"element_id\": \"f9ae7fbe6a8ac9d4093eb68a5ad9908a\",\n",
      "    \"text\": \"16\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            301.01900000000006,\n",
      "            751.9393215999995\n",
      "          ],\n",
      "          [\n",
      "            301.01900000000006,\n",
      "            761.9019215999995\n",
      "          ],\n",
      "          [\n",
      "            310.9816,\n",
      "            761.9019215999995\n",
      "          ],\n",
      "          [\n",
      "            310.9816,\n",
      "            751.9393215999995\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 16,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"1c1906798f9385528fb33984d7a04470\",\n",
      "    \"text\": \"Figure 4: Screenshot for human evaluation interface on the Amazon Mechanical Turk crowdsource evaluation platform. Output 1 is generated by MiniGPT-5, while output 2 is generated by the two- stage baseline.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            467.4383216\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            499.3189216\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999995,\n",
      "            499.3189216\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999995,\n",
      "            467.4383216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 17,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"2842abe117d584cd4705b0217d50b176\",\n",
      "    \"text\": \"Model\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            118.66951064,\n",
      "            517.5115554695681\n",
      "          ],\n",
      "          [\n",
      "            118.66951064,\n",
      "            530.064232217568\n",
      "          ],\n",
      "          [\n",
      "            151.444549629028,\n",
      "            530.064232217568\n",
      "          ],\n",
      "          [\n",
      "            151.444549629028,\n",
      "            517.5115554695681\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 17,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"9a189d48eebd4fb8b78805f8310c1c68\",\n",
      "    \"text\": \"CLIP-I (\\u2191) CLIP-T (\\u2191)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            274.209728224468,\n",
      "            517.235396581112\n",
      "          ],\n",
      "          [\n",
      "            274.209728224468,\n",
      "            530.064232217568\n",
      "          ],\n",
      "          [\n",
      "            399.4353216770841,\n",
      "            530.064232217568\n",
      "          ],\n",
      "          [\n",
      "            399.4353216770841,\n",
      "            517.235396581112\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 17,\n",
      "      \"parent_id\": \"2842abe117d584cd4705b0217d50b176\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"55bc2d1b583d00d4e43d6ff0f651089e\",\n",
      "    \"text\": \"IS (\\u2191)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            414.4985337746841,\n",
      "            517.235396581112\n",
      "          ],\n",
      "          [\n",
      "            414.4985337746841,\n",
      "            530.064232217568\n",
      "          ],\n",
      "          [\n",
      "            443.4313033170842,\n",
      "            530.064232217568\n",
      "          ],\n",
      "          [\n",
      "            443.4313033170842,\n",
      "            517.235396581112\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 17,\n",
      "      \"parent_id\": \"2842abe117d584cd4705b0217d50b176\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"9dc5b7f3d6eecad8bf5b9cadcb89015d\",\n",
      "    \"text\": \"FID (\\u2193)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            458.4945154146842,\n",
      "            517.235396581112\n",
      "          ],\n",
      "          [\n",
      "            458.4945154146842,\n",
      "            530.064232217568\n",
      "          ],\n",
      "          [\n",
      "            496.49158107708416,\n",
      "            530.064232217568\n",
      "          ],\n",
      "          [\n",
      "            496.49158107708416,\n",
      "            517.235396581112\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 17,\n",
      "      \"parent_id\": \"2842abe117d584cd4705b0217d50b176\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"9f60c1cc23605bb60e86c813d7994b38\",\n",
      "    \"text\": \"MiniGPT-5 MiniGPT-5 (Fixed Queries) MiniGPT-5 (Decoder-Only)\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            118.66951063999994,\n",
      "            537.622096249568\n",
      "          ],\n",
      "          [\n",
      "            118.66951063999994,\n",
      "            577.791014637568\n",
      "          ],\n",
      "          [\n",
      "            259.146516126868,\n",
      "            577.791014637568\n",
      "          ],\n",
      "          [\n",
      "            259.146516126868,\n",
      "            537.622096249568\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 17,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"9c63b75a38fb3a9bbb181b230c1d0095\",\n",
      "    \"text\": \"0.61 0.60 0.58\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            289.88802148272,\n",
      "            537.534227512332\n",
      "          ],\n",
      "          [\n",
      "            289.88802148272,\n",
      "            577.791014637568\n",
      "          ],\n",
      "          [\n",
      "            311.86167704900004,\n",
      "            577.791014637568\n",
      "          ],\n",
      "          [\n",
      "            311.86167704900004,\n",
      "            537.534227512332\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 17,\n",
      "      \"parent_id\": \"9f60c1cc23605bb60e86c813d7994b38\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"23f7bc52b69f1769eefd1906819d124c\",\n",
      "    \"text\": \"0.22 0.21 0.20\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            360.032379150544,\n",
      "            537.534227512332\n",
      "          ],\n",
      "          [\n",
      "            360.032379150544,\n",
      "            577.791014637568\n",
      "          ],\n",
      "          [\n",
      "            382.006034716824,\n",
      "            577.791014637568\n",
      "          ],\n",
      "          [\n",
      "            382.006034716824,\n",
      "            537.534227512332\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 17,\n",
      "      \"parent_id\": \"9f60c1cc23605bb60e86c813d7994b38\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"0293b6fba5d854db79cf2bb8057497e6\",\n",
      "    \"text\": \"28.09 28.55 24.74\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            414.83736583231206,\n",
      "            537.622096249568\n",
      "          ],\n",
      "          [\n",
      "            414.83736583231206,\n",
      "            577.791014637568\n",
      "          ],\n",
      "          [\n",
      "            443.086452083,\n",
      "            577.791014637568\n",
      "          ],\n",
      "          [\n",
      "            443.086452083,\n",
      "            537.622096249568\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 17,\n",
      "      \"parent_id\": \"9f60c1cc23605bb60e86c813d7994b38\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"e52a16641d71984285f26414aa6465bc\",\n",
      "    \"text\": \"31.47 30.56 34.88\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            463.36601414008004,\n",
      "            537.622096249568\n",
      "          ],\n",
      "          [\n",
      "            463.36601414008004,\n",
      "            577.791014637568\n",
      "          ],\n",
      "          [\n",
      "            491.61510039076796,\n",
      "            577.791014637568\n",
      "          ],\n",
      "          [\n",
      "            491.61510039076796,\n",
      "            537.622096249568\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 17,\n",
      "      \"parent_id\": \"9f60c1cc23605bb60e86c813d7994b38\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"826e9af91482c3a62f8fd998883b6f11\",\n",
      "    \"text\": \"Table 8: Evaluation of different model designs for image generation qualities on the CC3M valida- tion set.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            592.2103216\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            613.1319215999999\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999967,\n",
      "            613.1319215999999\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999967,\n",
      "            592.2103216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 17,\n",
      "      \"parent_id\": \"9f60c1cc23605bb60e86c813d7994b38\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"023c542841e91290f95732ada5270989\",\n",
      "    \"text\": \"D MORE QUALITATIVE EXAMPLES\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.299,\n",
      "            635.5431232\n",
      "          ],\n",
      "          [\n",
      "            108.299,\n",
      "            647.4983232\n",
      "          ],\n",
      "          [\n",
      "            293.71637169999997,\n",
      "            647.4983232\n",
      "          ],\n",
      "          [\n",
      "            293.71637169999997,\n",
      "            635.5431232\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 17,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"76249d8cbb952e7dfa4b29d133aa0ac2\",\n",
      "    \"text\": \"In this section, we provide additional qualitative examples to further demonstrate the capabilities of MiniGPT-5. Figures 7,8,9, and 10 showcase these examples across various datasets and settings.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            661.2793216\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            682.2009216\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            682.2009216\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            661.2793216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \",\",\n",
      "          \"url\": \"figure.caption.15\",\n",
      "          \"start_index\": 123\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"8\",\n",
      "          \"url\": \"figure.caption.16\",\n",
      "          \"start_index\": 124\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"9\",\n",
      "          \"url\": \"figure.caption.17\",\n",
      "          \"start_index\": 126\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"and10showcasetheseexamplesacrossvariousdatasetsandsettings\",\n",
      "          \"url\": \"figure.caption.18\",\n",
      "          \"start_index\": 129\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 17,\n",
      "      \"parent_id\": \"023c542841e91290f95732ada5270989\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"72841db1a6ebd75b95e88feea27af8c1\",\n",
      "    \"text\": \"Figure 7 presents a comparative analysis on the VIST validation set, illustrating how MiniGPT-5 outperforms baseline models in terms of image generation quality and alignment with multimodal inputs. The examples highlight the superiority of MiniGPT-5 in generating images that closely match the given text prompts.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            689.1743216\n",
      "          ],\n",
      "          [\n",
      "            107.99999999999997,\n",
      "            732.0139216\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999967,\n",
      "            732.0139216\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999967,\n",
      "            689.1743216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \".\",\n",
      "          \"url\": \"figure.caption.15\",\n",
      "          \"start_index\": 197\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 17,\n",
      "      \"parent_id\": \"023c542841e91290f95732ada5270989\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Footer\",\n",
      "    \"element_id\": \"2891c303767b455a6a2818e7b2ef06d4\",\n",
      "    \"text\": \"17\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            301.019,\n",
      "            751.9393216000001\n",
      "          ],\n",
      "          [\n",
      "            301.019,\n",
      "            761.9019216\n",
      "          ],\n",
      "          [\n",
      "            310.98159999999996,\n",
      "            761.9019216\n",
      "          ],\n",
      "          [\n",
      "            310.98159999999996,\n",
      "            751.9393216000001\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 17,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"a105dacc152209518b03bbc00754f689\",\n",
      "    \"text\": \"(a) FID vs CFG Scale\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            187.704,\n",
      "            190.78734240000006\n",
      "          ],\n",
      "          [\n",
      "            187.704,\n",
      "            199.75374239999996\n",
      "          ],\n",
      "          [\n",
      "            265.89997439999996,\n",
      "            199.75374239999996\n",
      "          ],\n",
      "          [\n",
      "            265.89997439999996,\n",
      "            190.78734240000006\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 18,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"b82d6bbf2e8407c471edd4ce40350d7a\",\n",
      "    \"text\": \"(b) IS vs CFG Scale\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            349.087,\n",
      "            190.78734240000006\n",
      "          ],\n",
      "          [\n",
      "            349.087,\n",
      "            199.75374239999996\n",
      "          ],\n",
      "          [\n",
      "            421.311352,\n",
      "            199.75374239999996\n",
      "          ],\n",
      "          [\n",
      "            421.311352,\n",
      "            190.78734240000006\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 18,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"259b7316bff39117b7dcda7cb2d8035d\",\n",
      "    \"text\": \"(c) CLIP-T vs CFG Scale\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            180.979,\n",
      "            310.7273424\n",
      "          ],\n",
      "          [\n",
      "            180.979,\n",
      "            319.6937424\n",
      "          ],\n",
      "          [\n",
      "            272.6245744,\n",
      "            319.6937424\n",
      "          ],\n",
      "          [\n",
      "            272.6245744,\n",
      "            310.7273424\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 18,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"fb6fc9cc5e9dd98a3098648113ba5f2a\",\n",
      "    \"text\": \"(d) CLIP-I vs CFG Scale\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            340.372,\n",
      "            310.7273424\n",
      "          ],\n",
      "          [\n",
      "            340.372,\n",
      "            319.6937424\n",
      "          ],\n",
      "          [\n",
      "            430.0270336,\n",
      "            319.6937424\n",
      "          ],\n",
      "          [\n",
      "            430.0270336,\n",
      "            310.7273424\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 18,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"18fc907084c8ff84943b0d595ea8b5b8\",\n",
      "    \"text\": \"Figure 5: Line charts for various metrics vs Classifier-free Guidance (CFG) scale on CC3M. The results suggest that our CFG strategy can exhibit comparable effectiveness to the CFG strategy employed in SD2, with the appropriate CFG scale significantly enhancing both image quality and coherence.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            330.56932159999997\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            373.4089216\n",
      "          ],\n",
      "          [\n",
      "            504.0033874000001,\n",
      "            373.4089216\n",
      "          ],\n",
      "          [\n",
      "            504.0033874000001,\n",
      "            330.56932159999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 18,\n",
      "      \"parent_id\": \"fb6fc9cc5e9dd98a3098648113ba5f2a\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"5130bdca35595f81d73c8797792cc336\",\n",
      "    \"text\": \"(a) FID vs nvoken\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            194.322,\n",
      "            506.8690816\n",
      "          ],\n",
      "          [\n",
      "            194.322,\n",
      "            516.3186544\n",
      "          ],\n",
      "          [\n",
      "            258.78436416000005,\n",
      "            516.3186544\n",
      "          ],\n",
      "          [\n",
      "            258.78436416000005,\n",
      "            506.8690816\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 18,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"9e6a9ba27b760bca4a8892ec467ec370\",\n",
      "    \"text\": \"(b) IS vs nvoken\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            355.705,\n",
      "            506.8690816\n",
      "          ],\n",
      "          [\n",
      "            355.705,\n",
      "            516.3186544\n",
      "          ],\n",
      "          [\n",
      "            414.19636416000003,\n",
      "            516.3186544\n",
      "          ],\n",
      "          [\n",
      "            414.19636416000003,\n",
      "            506.8690816\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 18,\n",
      "      \"parent_id\": \"5130bdca35595f81d73c8797792cc336\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"44e8517ed99ea592f254cc2a9b088c97\",\n",
      "    \"text\": \"(c) CLIP-T vs nvoken\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            187.597,\n",
      "            626.8090816\n",
      "          ],\n",
      "          [\n",
      "            187.597,\n",
      "            636.2586544\n",
      "          ],\n",
      "          [\n",
      "            265.50936416,\n",
      "            636.2586544\n",
      "          ],\n",
      "          [\n",
      "            265.50936416,\n",
      "            626.8090816\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 18,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"d75bfe644c37c0660ba5521f45a2b3f2\",\n",
      "    \"text\": \"(d) CLIP-I vs nvoken\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            346.99,\n",
      "            626.8090816\n",
      "          ],\n",
      "          [\n",
      "            346.99,\n",
      "            636.2586544\n",
      "          ],\n",
      "          [\n",
      "            422.91136416000006,\n",
      "            636.2586544\n",
      "          ],\n",
      "          [\n",
      "            422.91136416000006,\n",
      "            626.8090816\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 18,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"6b1e956b0858a211fe06036712b5db61\",\n",
      "    \"text\": \"Figure 6: Line charts for various metrics vs the number of vokens on CC3M. As the number of vokens increases, the image quality and CLIP scores improve. In this work, our default voken number is 8.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000006,\n",
      "            646.8483216\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000006,\n",
      "            678.7289216\n",
      "          ],\n",
      "          [\n",
      "            504.0033874,\n",
      "            678.7289216\n",
      "          ],\n",
      "          [\n",
      "            504.0033874,\n",
      "            646.8483216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 18,\n",
      "      \"parent_id\": \"d75bfe644c37c0660ba5521f45a2b3f2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"93668ed8e73d9463dca6d9292526fc20\",\n",
      "    \"text\": \"In Figure 8, we focus on the performance of MiniGPT-5 in free multimodal generation scenarios. The results clearly indicate an improvement over the Two-Stage baseline, emphasizing MiniGPT-5\\u2019s ability to perform consistent and creative multimodal generation.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.00000000000006,\n",
      "            700.1333216\n",
      "          ],\n",
      "          [\n",
      "            108.00000000000006,\n",
      "            732.0139216\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999984,\n",
      "            732.0139216\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999984,\n",
      "            700.1333216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \",\",\n",
      "          \"url\": \"figure.caption.16\",\n",
      "          \"start_index\": 11\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 18,\n",
      "      \"parent_id\": \"d75bfe644c37c0660ba5521f45a2b3f2\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Footer\",\n",
      "    \"element_id\": \"88fa5fcc37cd4ddba0c36f2add223000\",\n",
      "    \"text\": \"18\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            301.01900000000006,\n",
      "            751.9393216\n",
      "          ],\n",
      "          [\n",
      "            301.01900000000006,\n",
      "            761.9019216\n",
      "          ],\n",
      "          [\n",
      "            310.9816,\n",
      "            761.9019216\n",
      "          ],\n",
      "          [\n",
      "            310.9816,\n",
      "            751.9393216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 18,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"96fbbfcd63200cccc2a4a61e2cf2d3a0\",\n",
      "    \"text\": \"Figure 9 showcases the application of MiniGPT-5 in the context of the MMDialog test set. Here, the emphasis is on free multimodal dialog generation, with MiniGPT-5 displaying a decent performance in generating coherent and contextually relevant multimodal dialogues.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            84.01332159999993\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            115.89392159999989\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            115.89392159999989\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            84.01332159999993\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Figure9showcasestheapplicationofMiniGPT\",\n",
      "          \"url\": \"figure.caption.17\",\n",
      "          \"start_index\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 19,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"ec9cd6eb01c62f4841e3db53beb2454c\",\n",
      "    \"text\": \"Lastly, Figure 10 highlights MiniGPT-5\\u2019s performance in single text-to-image generation tasks on the CC3M validation set. The examples underline the model\\u2019s proficiency in generating visually accurate and contextually appropriate images from textual descriptions, surpassing the performance of baseline models.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            122.86832159999983\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            165.70692159999976\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            165.70692159999976\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999998,\n",
      "            122.86832159999983\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"links\": [\n",
      "        {\n",
      "          \"text\": \"Figure10highlightsMiniGPT - 5 \\u2019 sperformanceinsingletext - to - theCC3Mvalidationset\",\n",
      "          \"url\": \"figure.caption.18\",\n",
      "          \"start_index\": 8\n",
      "        }\n",
      "      ],\n",
      "      \"page_number\": 19,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"722270dc9cc3e7b62fada79bb864417c\",\n",
      "    \"text\": \"Each figure includes a clear depiction of input prompts (indicated in orange blocks) and the corre- sponding model outputs (in green blocks), providing a comprehensive view of MiniGPT-5\\u2019s capa- bilities across different multimodal generation tasks.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            172.6813215999997\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            204.56192159999966\n",
      "          ],\n",
      "          [\n",
      "            504.0033874,\n",
      "            204.56192159999966\n",
      "          ],\n",
      "          [\n",
      "            504.0033874,\n",
      "            172.6813215999997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 19,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Footer\",\n",
      "    \"element_id\": \"308c4df056afa73f7ae49fcf35934169\",\n",
      "    \"text\": \"19\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            301.019,\n",
      "            751.9393215999996\n",
      "          ],\n",
      "          [\n",
      "            301.019,\n",
      "            761.9019215999997\n",
      "          ],\n",
      "          [\n",
      "            310.98159999999996,\n",
      "            761.9019215999997\n",
      "          ],\n",
      "          [\n",
      "            310.98159999999996,\n",
      "            751.9393215999996\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 19,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"75bbf2adbed11284436f5b0cb9edca60\",\n",
      "    \"text\": \"we didn't expectsuch beautyoutdoors.the bridge wasall i thought itwould be.the view of thewater wereamazing.the bridge wasbreath taking.we all agreedthe food wasfantastic.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            142.10308080000004\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            626.781\n",
      "          ],\n",
      "          [\n",
      "            484.2025430109,\n",
      "            626.781\n",
      "          ],\n",
      "          [\n",
      "            484.2025430109,\n",
      "            142.10308080000004\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 20,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"dfb7f40e4c0ac2965c83019090399fc0\",\n",
      "    \"text\": \"GILLSD 2Two-stageMiniGPT-5GT\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            142.10308080000004\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            626.781\n",
      "          ],\n",
      "          [\n",
      "            484.2025430109,\n",
      "            626.781\n",
      "          ],\n",
      "          [\n",
      "            484.2025430109,\n",
      "            142.10308080000004\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 20,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"ab279b67aa8e43af1db15897b860ef33\",\n",
      "    \"text\": \"i took my wife outfor our anniversarydinner.our first coursewas a light butdelicious salad.following oursalad we hadsquash bisquefor our main coursewe had a beautifullyplated salmon.to end ourwonderfulnight we had aparfait fordessert.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            142.10308080000004\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            626.781\n",
      "          ],\n",
      "          [\n",
      "            484.2025430109,\n",
      "            626.781\n",
      "          ],\n",
      "          [\n",
      "            484.2025430109,\n",
      "            142.10308080000004\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 20,\n",
      "      \"parent_id\": \"dfb7f40e4c0ac2965c83019090399fc0\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"cd2174f14c49db66cb34d31945f4bf50\",\n",
      "    \"text\": \"GILLSD 2Two-stageMiniGPT-5GT\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            142.10308080000004\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            626.781\n",
      "          ],\n",
      "          [\n",
      "            484.2025430109,\n",
      "            626.781\n",
      "          ],\n",
      "          [\n",
      "            484.2025430109,\n",
      "            142.10308080000004\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 20,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"28aa347f7aa1e28ce4de4b2f353e9944\",\n",
      "    \"text\": \"GILLSD 2Two-stageMiniGPT-5GT\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            142.10308080000004\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            626.781\n",
      "          ],\n",
      "          [\n",
      "            484.2025430109,\n",
      "            626.781\n",
      "          ],\n",
      "          [\n",
      "            484.2025430109,\n",
      "            142.10308080000004\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 20,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"76b1c2246845a05fd16a5dabecaaf6be\",\n",
      "    \"text\": \"i had a photosession with myfavorite doll.she is sophilosophicalsometimes.the cat likesher too, theywere having agood time.the cat really likesher, he even gaveher a kiss !she finishedthe sessionposing withher guitar,she's such agoodmusician.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            142.10308080000004\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            626.781\n",
      "          ],\n",
      "          [\n",
      "            484.2025430109,\n",
      "            626.781\n",
      "          ],\n",
      "          [\n",
      "            484.2025430109,\n",
      "            142.10308080000004\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 20,\n",
      "      \"parent_id\": \"28aa347f7aa1e28ce4de4b2f353e9944\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"f35aa22eecc994523d17fabdba92b73d\",\n",
      "    \"text\": \"Figure 7: Comparative examples from MiniGPT-5 and baselines on the VIST validation set for image generation with multimodal input. Orange blocks denote input prompts, while green blocks show model outputs.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            636.6043216\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            668.4849216\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            668.4849216\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999999,\n",
      "            636.6043216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 20,\n",
      "      \"parent_id\": \"28aa347f7aa1e28ce4de4b2f353e9944\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Footer\",\n",
      "    \"element_id\": \"493d0b1a9261a58df1b6eea5daaddb15\",\n",
      "    \"text\": \"20\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            301.019,\n",
      "            751.9393216\n",
      "          ],\n",
      "          [\n",
      "            301.019,\n",
      "            761.9019216\n",
      "          ],\n",
      "          [\n",
      "            310.98159999999996,\n",
      "            761.9019216\n",
      "          ],\n",
      "          [\n",
      "            310.98159999999996,\n",
      "            751.9393216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 20,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"bb5e957aff432820f9e3fffc130c824e\",\n",
      "    \"text\": \"Everyone was ingreate spirits\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            90.27231440000003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            90.27231440000003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 21,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"3aa6b936c25149406306a980f2dfa329\",\n",
      "    \"text\": \"Jacob and his son.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            90.27231440000003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            90.27231440000003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 21,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"31aeff8ad4377ad9278e75a8af0df308\",\n",
      "    \"text\": \"The first book I readhad lots of coolpictures in it.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            90.27231440000003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            90.27231440000003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"3aa6b936c25149406306a980f2dfa329\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"e68a14c011bef5a5e91cf52592a9f235\",\n",
      "    \"text\": \"Me and tanner takinga selfie together afterthe meeting.GTMe bondrit duringintermission.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            90.27231440000003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            90.27231440000003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"3aa6b936c25149406306a980f2dfa329\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"4a95070b9da6c7796dedc6c7783767e9\",\n",
      "    \"text\": \"I really enjoyedreading the book.GILL\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            90.27231440000003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            90.27231440000003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"3aa6b936c25149406306a980f2dfa329\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"ff263d584f56d1c20cd6b2f0f8a8a372\",\n",
      "    \"text\": \"We had a greattime.GILL\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            90.27231440000003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            90.27231440000003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"3aa6b936c25149406306a980f2dfa329\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"3b34ec10f4813522ba6e5b0cb10dc398\",\n",
      "    \"text\": \"All of the kids were soexcited to read newbooks\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            90.27231440000003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            90.27231440000003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"3aa6b936c25149406306a980f2dfa329\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"12e5eab9b18ab354b01c0f114af2824a\",\n",
      "    \"text\": \"On our class trip we allwore our school uniformsI got to read manydifferent book that Ihad never read before.I really enjoyed beingon this trip\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            90.27231440000003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            90.27231440000003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"3aa6b936c25149406306a980f2dfa329\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"b554be674e0526fccd8b38ac0fd5e2ba\",\n",
      "    \"text\": \"The meeting was veryinformative and welearned a lot.GILL\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            90.27231440000003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            90.27231440000003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"3aa6b936c25149406306a980f2dfa329\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"99219620baddcb9b4fcb64f4fddb0f03\",\n",
      "    \"text\": \"MiniGPT-5Two-StageEven the guy behind uswas great and fun to bearound.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            90.27231440000003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            90.27231440000003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"3aa6b936c25149406306a980f2dfa329\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"9cc54fdf5ff4ebe02bdf0eb9f63b975e\",\n",
      "    \"text\": \"Celebrating with all ofour friendsHer best friend evencame.Even my dad got inon the act.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            90.27231440000003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            90.27231440000003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"3aa6b936c25149406306a980f2dfa329\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"dcb291f6b02a32667dbf2720d525f402\",\n",
      "    \"text\": \"One of my friendsread us a story fromone of the books.GT\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            90.27231440000003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            90.27231440000003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 21,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"0857276615f0d709b857ba1333a0a4fd\",\n",
      "    \"text\": \"MiniGPT-5Two-StageThis book was aboutanimals and it had lots ofpictures too.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            90.27231440000003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            90.27231440000003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"dcb291f6b02a32667dbf2720d525f402\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"c3707003e291ed1ed7218a8b678b0881\",\n",
      "    \"text\": \"The happy coupleenjoying theirengagement.GTThis is the crew righthere.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            90.27231440000003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            90.27231440000003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"dcb291f6b02a32667dbf2720d525f402\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"281f9ad7fc819b02f1c74b0d6f84a052\",\n",
      "    \"text\": \"MiniGPT-5Two-StageWe all gathered todiscuss the program\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            90.27231440000003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            90.27231440000003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"dcb291f6b02a32667dbf2720d525f402\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"148d509e01ac3a0e668c89bdf57ec5ae\",\n",
      "    \"text\": \"We got to the town hallmeeting early and therewere a lot of people.Here's us watchingthe introduction.Everyone had a lot ofquestions and themeeting was very long\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            90.27231440000003\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            689.567\n",
      "          ],\n",
      "          [\n",
      "            484.2127552437,\n",
      "            90.27231440000003\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"dcb291f6b02a32667dbf2720d525f402\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"508c9edd6a6c0a9ec442ccae68ff4fa8\",\n",
      "    \"text\": \"Figure 8: More qualitative examples from MiniGPT-5 and baselines on VIST validation set for free multimodal generation.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            699.3903216\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            720.3119216\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999984,\n",
      "            720.3119216\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999984,\n",
      "            699.3903216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 21,\n",
      "      \"parent_id\": \"dcb291f6b02a32667dbf2720d525f402\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Footer\",\n",
      "    \"element_id\": \"79421236bca7133570fd200818cc5a73\",\n",
      "    \"text\": \"21\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            301.019,\n",
      "            751.9393216\n",
      "          ],\n",
      "          [\n",
      "            301.019,\n",
      "            761.9019216\n",
      "          ],\n",
      "          [\n",
      "            310.98159999999996,\n",
      "            761.9019216\n",
      "          ],\n",
      "          [\n",
      "            310.98159999999996,\n",
      "            751.9393216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 21,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"4e87fb7b47c2272d9f78022384be4e65\",\n",
      "    \"text\": \"It the final FlashbackFridayz of 2019and we are looking back with a themeof TravelFaves2019. Tag and retweetyour hosts and guest hosts; Shareyous and tag you friends.Travelfaves2019 ours is thegorgeous waterfall in Costa RicaLuxurious views! Throwback toour trip to New Orleans lastJanuary where we stopped by theTabasco Factory in Avery IslandMiniGPT-5GT\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            129.9446903999999\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            649.896\n",
      "          ],\n",
      "          [\n",
      "            484.2035878217,\n",
      "            649.896\n",
      "          ],\n",
      "          [\n",
      "            484.2035878217,\n",
      "            129.9446903999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 22,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"d43699bf50601d268cae365c9c968ebe\",\n",
      "    \"text\": \"Our travelfaves2019what's yoursThe Greate Wall of ChinaGILL\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            129.9446903999999\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            649.896\n",
      "          ],\n",
      "          [\n",
      "            484.2035878217,\n",
      "            649.896\n",
      "          ],\n",
      "          [\n",
      "            484.2035878217,\n",
      "            129.9446903999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 22,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"08f2d2ec7fb01c545fdaa90f8137181c\",\n",
      "    \"text\": \"Haha I know what youmean! I'm just about tofinish the last Harry Potterbook! I'm so excited forthe next one!GILL\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            129.9446903999999\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            649.896\n",
      "          ],\n",
      "          [\n",
      "            484.2035878217,\n",
      "            649.896\n",
      "          ],\n",
      "          [\n",
      "            484.2035878217,\n",
      "            129.9446903999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 22,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"65a171466caf36bc19c1d3958f33cf4f\",\n",
      "    \"text\": \"So cute!! I'm justabout to get into bedand finish off theGoblet of Fire for themillionth time!\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            129.9446903999999\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            649.896\n",
      "          ],\n",
      "          [\n",
      "            484.2035878217,\n",
      "            649.896\n",
      "          ],\n",
      "          [\n",
      "            484.2035878217,\n",
      "            129.9446903999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 22,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"3475aefe052d547cd8d059e7afa3be97\",\n",
      "    \"text\": \"You would get on withmy 3 year old then heis obsessed withHarry potter haha\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            129.9446903999999\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            649.896\n",
      "          ],\n",
      "          [\n",
      "            484.2035878217,\n",
      "            649.896\n",
      "          ],\n",
      "          [\n",
      "            484.2035878217,\n",
      "            129.9446903999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 22,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"64b31c0db70d0dab7b19d0d90fb93305\",\n",
      "    \"text\": \"What I find so funnyis everyone has astrong opinion of meand no one realisesI'm actually a soppy,over dramatic buggerthat :growing_heart:Harry PotterI've read all the books at least 10times each!Harry PotterHaha he has the full box setand home and at his Nanna's:) he even tries to head butthis lamp like dobby:face_with_tears_of_joy::see-no-evil_monkey:MiniGPT-5GT\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            129.9446903999999\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            649.896\n",
      "          ],\n",
      "          [\n",
      "            484.2035878217,\n",
      "            649.896\n",
      "          ],\n",
      "          [\n",
      "            484.2035878217,\n",
      "            129.9446903999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 22,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"571ddc92447fd0d7426dec1348b0817e\",\n",
      "    \"text\": \"Travelfaves2019 we have seenquite a number of gorgeousAfrica\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            127.801,\n",
      "            129.9446903999999\n",
      "          ],\n",
      "          [\n",
      "            127.801,\n",
      "            649.896\n",
      "          ],\n",
      "          [\n",
      "            484.2035878217,\n",
      "            649.896\n",
      "          ],\n",
      "          [\n",
      "            484.2035878217,\n",
      "            129.9446903999999\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 22,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"bdbc4b82ee2d235c32ad8059daf6c49c\",\n",
      "    \"text\": \"Figure 9: More qualitative examples from MiniGPT-5 on MMDialog test set for free multimodal dialog generation.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            659.7193216000001\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            680.6399216\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999997,\n",
      "            680.6399216\n",
      "          ],\n",
      "          [\n",
      "            504.0033873999997,\n",
      "            659.7193216000001\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 22,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Footer\",\n",
      "    \"element_id\": \"a148ade70f78b0bbbb107f8f1e4633f8\",\n",
      "    \"text\": \"22\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            301.019,\n",
      "            751.9393216\n",
      "          ],\n",
      "          [\n",
      "            301.019,\n",
      "            761.9019216\n",
      "          ],\n",
      "          [\n",
      "            310.98159999999996,\n",
      "            761.9019216\n",
      "          ],\n",
      "          [\n",
      "            310.98159999999996,\n",
      "            751.9393216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 22,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"d2ec3795043d46c9c96703549457083f\",\n",
      "    \"text\": \"womens handssprinkle a doughwith \\ufb02our close up\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            186.72162057499997\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            593.119\n",
      "          ],\n",
      "          [\n",
      "            504.0275897125,\n",
      "            593.119\n",
      "          ],\n",
      "          [\n",
      "            504.0275897125,\n",
      "            186.72162057499997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 23,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"1cea40c0f941cec17dfa8c6ce9993e38\",\n",
      "    \"text\": \"MiniGPT-5SD 2GILLGT\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            186.72162057499997\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            593.119\n",
      "          ],\n",
      "          [\n",
      "            504.0275897125,\n",
      "            593.119\n",
      "          ],\n",
      "          [\n",
      "            504.0275897125,\n",
      "            186.72162057499997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 23,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"65c1865aecff7ec104ff9215ac0e0abe\",\n",
      "    \"text\": \"MiniGPT-5 SD 2GILLGT\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            186.72162057499997\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            593.119\n",
      "          ],\n",
      "          [\n",
      "            504.0275897125,\n",
      "            593.119\n",
      "          ],\n",
      "          [\n",
      "            504.0275897125,\n",
      "            186.72162057499997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 23,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"f367e31f1279d01c5fe79b63d805919e\",\n",
      "    \"text\": \"MiniGPT-5SD 2GILLGT\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            186.72162057499997\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            593.119\n",
      "          ],\n",
      "          [\n",
      "            504.0275897125,\n",
      "            593.119\n",
      "          ],\n",
      "          [\n",
      "            504.0275897125,\n",
      "            186.72162057499997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 23,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"cd594a86864fa46dd875c61a80301fd5\",\n",
      "    \"text\": \"MiniGPT-5SD 2GILLGT\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            186.72162057499997\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            593.119\n",
      "          ],\n",
      "          [\n",
      "            504.0275897125,\n",
      "            593.119\n",
      "          ],\n",
      "          [\n",
      "            504.0275897125,\n",
      "            186.72162057499997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 23,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"084d395e1b34e80918aa6763d976dfbb\",\n",
      "    \"text\": \"happy youngbusinessman with afolder running up adrawn stairs along aconcrete wall\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            186.72162057499997\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            593.119\n",
      "          ],\n",
      "          [\n",
      "            504.0275897125,\n",
      "            593.119\n",
      "          ],\n",
      "          [\n",
      "            504.0275897125,\n",
      "            186.72162057499997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"cd594a86864fa46dd875c61a80301fd5\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"b5ff44ba8c9de2af1fb3e18212d1f79b\",\n",
      "    \"text\": \"boy looking in theencyclopediathrough amagnifying glass\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            186.72162057499997\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            593.119\n",
      "          ],\n",
      "          [\n",
      "            504.0275897125,\n",
      "            593.119\n",
      "          ],\n",
      "          [\n",
      "            504.0275897125,\n",
      "            186.72162057499997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"cd594a86864fa46dd875c61a80301fd5\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"36521cc152e028307cf68c2e6518cfb0\",\n",
      "    \"text\": \"we all knowsuperman , comicbook characters ,but history is full ofless impressiveheroes\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            186.72162057499997\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            593.119\n",
      "          ],\n",
      "          [\n",
      "            504.0275897125,\n",
      "            593.119\n",
      "          ],\n",
      "          [\n",
      "            504.0275897125,\n",
      "            186.72162057499997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"cd594a86864fa46dd875c61a80301fd5\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"da2922603d7d3c8f2741d538f08da0fa\",\n",
      "    \"text\": \"sun\\ufb02owers have adeep sentimentalmeaning for me\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            186.72162057499997\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            593.119\n",
      "          ],\n",
      "          [\n",
      "            504.0275897125,\n",
      "            593.119\n",
      "          ],\n",
      "          [\n",
      "            504.0275897125,\n",
      "            186.72162057499997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"cd594a86864fa46dd875c61a80301fd5\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"5280cd8b96e44b60b10fa63b5f46e089\",\n",
      "    \"text\": \"MiniGPT-5SD 2GILLGT\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            186.72162057499997\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            593.119\n",
      "          ],\n",
      "          [\n",
      "            504.0275897125,\n",
      "            593.119\n",
      "          ],\n",
      "          [\n",
      "            504.0275897125,\n",
      "            186.72162057499997\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 23,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"UncategorizedText\",\n",
      "    \"element_id\": \"34d7db64ba91b02623be34157fe10480\",\n",
      "    \"text\": \"Figure 10: More qualitative examples from MiniGPT-5 and baselines on CC3M validation set for single text-to-image generation.\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            108.0,\n",
      "            602.9423216\n",
      "          ],\n",
      "          [\n",
      "            108.0,\n",
      "            623.8639216\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999984,\n",
      "            623.8639216\n",
      "          ],\n",
      "          [\n",
      "            504.00338739999984,\n",
      "            602.9423216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 23,\n",
      "      \"parent_id\": \"5280cd8b96e44b60b10fa63b5f46e089\",\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"Footer\",\n",
      "    \"element_id\": \"805113430f05ce7e961e9aa7163a9e8c\",\n",
      "    \"text\": \"23\",\n",
      "    \"metadata\": {\n",
      "      \"coordinates\": {\n",
      "        \"points\": [\n",
      "          [\n",
      "            301.019,\n",
      "            751.9393216\n",
      "          ],\n",
      "          [\n",
      "            301.019,\n",
      "            761.9019216\n",
      "          ],\n",
      "          [\n",
      "            310.98159999999996,\n",
      "            761.9019216\n",
      "          ],\n",
      "          [\n",
      "            310.98159999999996,\n",
      "            751.9393216\n",
      "          ]\n",
      "        ],\n",
      "        \"system\": \"PixelSpace\",\n",
      "        \"layout_width\": 612,\n",
      "        \"layout_height\": 792\n",
      "      },\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"MINIGPT_5.pdf\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-05-05T10:57:29\",\n",
      "      \"page_number\": 23,\n",
      "      \"filetype\": \"application/pdf\"\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Convert each element to a dictionary\n",
    "element_dict = [el.to_dict() for el in elements]\n",
    "# Dump the list of dictionaries into a JSON string\n",
    "output = json.dumps(element_dict, indent=2)\n",
    "# Print the resulting JSON string\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'unstructured.documents.elements' from 'c:\\\\Users\\\\divak\\\\anaconda3\\\\envs\\\\myenv\\\\lib\\\\site-packages\\\\unstructured\\\\documents\\\\elements.py'>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets investigate a bit more\n",
    "unstructured.documents.elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's use python sdk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os module for operating system dependent functionality\n",
    "# import load_dotenv and find_dotenv functions from dotenv module\n",
    "# to specify environment variables in a .env file\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os module to access environment variables\n",
    "import os\n",
    "\n",
    "# Get the value of saas_api_key_auth environment variable\n",
    "saas_api_key_auth = os.environ.get('saas_api_key_auth')\n",
    "\n",
    "# Get the value of saas_server_url environment variable\n",
    "saas_server_url = os.environ.get('saas_server_url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the UnstructuredClient class\n",
    "# and pass in the API key authentication and server URL\n",
    "client = UnstructuredClient(\n",
    "    api_key_auth=saas_api_key_auth,  # Replace this with your actual API key\n",
    "    server_url=saas_server_url  # Replace this with your actual server URL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the PDF filename\n",
    "filename = \"data\\MINIGPT_5.pdf\"\n",
    "\n",
    "# Open the file and read its content\n",
    "with open(filename, \"rb\") as f:\n",
    "    files = shared.Files(\n",
    "        content=f.read(),  # Read the content of the file\n",
    "        file_name=filename,  # Set the file name\n",
    "    )\n",
    "\n",
    "# This block of code is redundant, as it does the same thing as the previous block\n",
    "# with open(filename, \"rb\") as f:\n",
    "#     files = shared.Files(\n",
    "#         content=f.read(),\n",
    "#         file_name=filename,\n",
    "#     )\n",
    "\n",
    "# Define the partition parameters using the file\n",
    "req = shared.PartitionParameters(files=files)\n",
    "\n",
    "# Try to partition the file, catch and print any SDKError\n",
    "try:\n",
    "    resp = client.general.partition(req)\n",
    "except SDKError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PartitionResponse(content_type='application/json', status_code=200, raw_response=<Response [200]>, elements=[{'type': 'Title', 'element_id': 'd99ad376d3c673278a6c8b90e4facb15', 'text': 'MINIGPT-5: INTERLEAVED VISION-AND-LANGUAGE GENERATION VIA GENERATIVE VOKENS', 'metadata': {'languages': ['eng'], 'page_number': 1, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'd5d4430ca05ac3791e755e87c1c256d8', 'text': 'Kaizhi Zheng∗, Xuehai He∗ , and Xin Eric Wang', 'metadata': {'languages': ['eng'], 'page_number': 1, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '9d1274315ba7eae03960265c08d5edaa', 'text': 'University of California, Santa Cruz https://github.com/eric-ai-lab/MiniGPT-5', 'metadata': {'languages': ['eng'], 'page_number': 1, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '07cd30f6f89754a2c217419880a91514', 'text': '4 2 0 2', 'metadata': {'languages': ['eng'], 'page_number': 1, 'parent_id': '9d1274315ba7eae03960265c08d5edaa', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '452202c3d8a420d49447943b87c30d0e', 'text': 'r a', 'metadata': {'languages': ['eng'], 'page_number': 1, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '114f549a188a6b894dd25f3f91e45747', 'text': 'M 5 1', 'metadata': {'languages': ['eng'], 'page_number': 1, 'parent_id': '452202c3d8a420d49447943b87c30d0e', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'cfae0d4248f7142f7b17f826cd7a5192', 'text': ']', 'metadata': {'languages': ['eng'], 'page_number': 1, 'parent_id': '452202c3d8a420d49447943b87c30d0e', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '19d05c4115a6b94b3b470e7c10e29698', 'text': 'V C . s c [', 'metadata': {'languages': ['eng'], 'page_number': 1, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '87290badddf80fb0a105ecccb54d177b', 'text': '3 v 9 3 2 2 0 . 0 1 3 2 : v i X r a', 'metadata': {'languages': ['eng'], 'page_number': 1, 'parent_id': '19d05c4115a6b94b3b470e7c10e29698', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '3d1626989d3e923485561f1e5bdeaa58', 'text': 'ABSTRACT', 'metadata': {'languages': ['eng'], 'page_number': 1, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '79c81b6766d8f90b73e9c616b3971089', 'text': 'The effectiveness of Multimodal Large Language Models (MLLMs) demonstrates a profound capability in multimodal understanding. However, the simultaneous generation of images with coherent texts is still underdeveloped. Addressing this, we introduce a novel interleaved vision-and-language generation method, centered around the concept of “generative vokens”. These vokens serve as piv- otal elements contributing to coherent image-text outputs. Our method is marked by a unique two-stage training strategy for description-free multimodal genera- tion, which does not necessitate extensive descriptions of images. We integrate classifier-free guidance to enhance the alignment of generated images and texts, ensuring more seamless and contextually relevant multimodal interactions. Our model, MiniGPT-5, exhibits substantial improvement over the baseline models on multimodal generation datasets, including MMDialog and VIST. The human eval- uation shows MiniGPT-5 is better than the baseline model on more than 56% cases for multimodal generation, highlighting its efficacy across diverse benchmarks.', 'metadata': {'languages': ['eng'], 'page_number': 1, 'parent_id': '3d1626989d3e923485561f1e5bdeaa58', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '6b86b273ff34fce19d6b804eff5a3f57', 'text': '1', 'metadata': {'languages': ['eng'], 'page_number': 1, 'parent_id': '3d1626989d3e923485561f1e5bdeaa58', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '348348036267fa046df6956d6bff62c9', 'text': 'INTRODUCTION', 'metadata': {'languages': ['eng'], 'page_number': 1, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'b34dabb17a8fe351ae4c08aec04a5201', 'text': 'The development of large-scale vision-and-language models is significantly impacting a wide range of fields like automated dialogue systems and digital content creation. With the surge in research and development in this domain, the current state-of-the-art Large Language Models (LLMs) (OpenAI, 2023; Chiang et al., 2023; Ouyang et al., 2022) and vision-and-language models such as (Wu et al., 2023a; Li et al., 2023c; Tsimpoukelli et al., 2021; Alayrac et al., 2022) fall short in generating coherent multimodal outputs. This limitation becomes particularly evident in tasks that demand an integrated handling of vision and language, essential for the next generation Large Language Models (LLMs).', 'metadata': {'languages': ['eng'], 'links': [{'text': 'OpenAI', 'url': 'cite.openai2023gpt4', 'start_index': 286}, {'text': '2023', 'url': 'cite.openai2023gpt4', 'start_index': 294}, {'text': 'Chiangetal .,', 'url': 'cite.vicuna2023', 'start_index': 300}, {'text': '2023', 'url': 'cite.vicuna2023', 'start_index': 315}, {'text': 'Ouyangetal .,', 'url': 'cite.training_lm', 'start_index': 321}, {'text': '2022', 'url': 'cite.training_lm', 'start_index': 336}, {'text': 'Wuetal', 'url': 'cite.visualchatgpt', 'start_index': 382}, {'text': '2023a', 'url': 'cite.visualchatgpt', 'start_index': 393}, {'text': 'Lietal .,', 'url': 'cite.li2023blip', 'start_index': 400}, {'text': '2023c', 'url': 'cite.li2023blip', 'start_index': 411}, {'text': 'Tsimpoukellietal .,', 'url': 'cite.frozen', 'start_index': 418}, {'text': '2021', 'url': 'cite.frozen', 'start_index': 439}, {'text': 'Alayracetal .,', 'url': 'cite.alayrac2022flamingo', 'start_index': 445}, {'text': '2022', 'url': 'cite.alayrac2022flamingo', 'start_index': 461}], 'page_number': 1, 'parent_id': '348348036267fa046df6956d6bff62c9', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '64d9d5e9ccbbd5290872abe7586c626b', 'text': 'Our work, as illustrated in Fig. 1, seeks to address these shortcomings by enhancing the integration of text and image generation in LLMs. The challenges in developing a multimodal LLM capable of interleaved vision and language generation are manifold. First, LLMs typically lack mechanisms to directly produce images, prompting us to introduce “generative vokens” that bridge the gap be- tween textual and visual feature spaces. Second, the constraint of data scarcity, especially in vision- and-language tasks (Sharma et al., 2018) lacking extensive detailed descriptions of images (Huang et al., 2016), is countered by our unique description-free training approach. Third, maintaining both image-text and image-image consistency poses a significant challenge, which we address through dual-loss strategies. Finally, as we push forward the boundaries with LLMs, the large memory re- quirements urge us to devise more efficient end-to-end strategies and create an efficient training pipeline accessible for the community, especially in downstream tasks.', 'metadata': {'languages': ['eng'], 'links': [{'text': '1', 'url': 'figure.caption.1', 'start_index': 33}, {'text': 'Sharmaetal .,', 'url': 'cite.sharma2018conceptual', 'start_index': 513}, {'text': '2018', 'url': 'cite.sharma2018conceptual', 'start_index': 528}, {'text': '(', 'url': 'cite.huang2016visual', 'start_index': 584}, {'text': 'etal .,', 'url': 'cite.huang2016visual', 'start_index': 591}, {'text': '2016', 'url': 'cite.huang2016visual', 'start_index': 599}], 'page_number': 1, 'parent_id': '348348036267fa046df6956d6bff62c9', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '2a1ee488f031fdc96b87bad37795fe9f', 'text': 'Specifically, to overcome these challenges, we present MiniGPT-5, a novel approach for interleaved vision-and-language generation. By combing the Stable Diffusion with LLMs through special vi- sual tokens (Tan & Bansal, 2020) – “generative vokens”, we develop a new approach for multimodal generation. Our two-stage training methodology emphasizes a description-free foundational phase,', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Tan & Bansal', 'url': 'cite.tan2020vokenization', 'start_index': 205}, {'text': '2020', 'url': 'cite.tan2020vokenization', 'start_index': 219}], 'page_number': 1, 'parent_id': '348348036267fa046df6956d6bff62c9', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'df8423e293ff039f30ed34fc2890ea0f', 'text': '∗These authors contributed equally to this work.', 'metadata': {'languages': ['eng'], 'page_number': 1, 'parent_id': '348348036267fa046df6956d6bff62c9', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Footer', 'element_id': '6b86b273ff34fce19d6b804eff5a3f57', 'text': '1', 'metadata': {'languages': ['eng'], 'page_number': 1, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'c77a44c8e4ba4cb2417b666ebc5659d9', 'text': 'enabling effective model training even with limited caption-grounded images. This strategy, dis- tinct from existing works, pivots on generic stages free from image annotations. To ensure that the generated text and images are in harmony, our dual-loss strategy comes into play, further enhanced by our innovative generative voken approach and classifier-free guidance. Our parameter-efficient fine-tuning strategy optimizes training efficiency and addresses memory constraints.', 'metadata': {'languages': ['eng'], 'page_number': 2, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '45154ea5110bc9047747da87c259d349', 'text': 'As shown in Fig. 2, leveraging ViT (Vision Transformer) and Qformer (Li et al., 2023c), alongside Large Language Models, we adapt multimodal inputs into generative vokens, seamlessly combined with the high-resolution Stable Diffusion 2.1 model (Rombach et al., 2022b) for context-aware im- Incorporating images as auxiliary input with instruction tuning approaches and age generation. pioneering both the text and image generation loss, we amplify the synergy between text and visu- als. We experiment on the CC3M (Sharma et al., 2018), VIST (Huang et al., 2016), and MMDi- alog (Feng et al., 2022) datasets. Notably, MiniGPT-5 shows superior performance across the two multimodal generation datasets.', 'metadata': {'languages': ['eng'], 'links': [{'text': '2', 'url': 'figure.caption.2', 'start_index': 17}, {'text': 'Lietal .,', 'url': 'cite.li2023blip', 'start_index': 69}, {'text': '2023c', 'url': 'cite.li2023blip', 'start_index': 80}, {'text': 'Rombachetal .,', 'url': 'cite.rombach2021highresolution', 'start_index': 245}, {'text': '2022b', 'url': 'cite.rombach2021highresolution', 'start_index': 261}, {'text': 'Sharmaetal .,', 'url': 'cite.sharma2018conceptual', 'start_index': 515}, {'text': '2018', 'url': 'cite.sharma2018conceptual', 'start_index': 530}, {'text': 'Huangetal .,', 'url': 'cite.huang2016visual', 'start_index': 543}, {'text': '2016', 'url': 'cite.huang2016visual', 'start_index': 557}, {'text': 'Fengetal .,', 'url': 'cite.feng2022mmdialog', 'start_index': 580}, {'text': '2022', 'url': 'cite.feng2022mmdialog', 'start_index': 593}], 'page_number': 2, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'f3c985c13d008b20c5649d80ae4768bc', 'text': 'In summary, our contributions are primarily threefold:', 'metadata': {'languages': ['eng'], 'page_number': 2, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'ListItem', 'element_id': 'e22329d68aaa1583c3db75ecfdc3ab41', 'text': 'We introduce a novel framework that leverages “generative vokens” to unify LLMs with Stable Diffusion, facilitating interleaved vision-and-language generation without relying on detailed image descriptions. We bridge the modality gap and improve the generation quality by using the loss of the latent diffusion model, the text generation loss, and the caption alignment loss together during training.', 'metadata': {'languages': ['eng'], 'page_number': 2, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'ListItem', 'element_id': '453b2637ce4e456ab2c94b81c62cade5', 'text': 'We propose a new two-stage training strategy for description-free multimodal generation. The first stage focuses on extracting high-quality text-aligned visual features from large text-image pairs, while the second stage ensures optimal coordination between visual and textual prompts during generation. The inclusion of classifier-free guidance during training enhances the overall generation quality.', 'metadata': {'languages': ['eng'], 'page_number': 2, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'ListItem', 'element_id': '99dc08e9a92a7d30b07f9aa09568cfe4', 'text': 'MiniGPT-5 achieves significant improvements over baseline methods on interleaved vision- and-language datasets, including VIST and MMDialog, and comparable results to the state- of-the-art on the single text-image pair dataset, CC3M. The human evaluation further shows that, compared with the two-stage baseline, MiniGPT-5 can provide better generation in perspectives of appropriate texts (55%), high-quality images (53%), and coherent multi- modal outputs (56%).', 'metadata': {'languages': ['eng'], 'page_number': 2, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'fe3a08cf7b0ae89bd864e8029526b21d', 'text': '2 RELATED WORK', 'metadata': {'languages': ['eng'], 'page_number': 2, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '47645a86118e738fb236b5324bea43e2', 'text': 'Large Language Models As Large Language Models (LLMs) become increasingly impactful and accessible, a growing body of research has emerged to extend these pretrained LLMs into the realm of multimodal comprehension tasks (Zhu et al., 2023; Li et al., 2023c; Dai et al., 2023; OpenAI, 2023; Li et al., 2023a; Alayrac et al., 2022; Li et al., 2023b). For example, to reproduce the impres- sive multimodal comprehension ability in GPT-4 (OpenAI, 2023), MiniGPT-4 (Zhu et al., 2023) proposes a projection layer to align pretrained vision component of BLIP-2 (Li et al., 2023c) with an advanced open-source large language model, Vicuna (Chiang et al., 2023). In our work, we utilize the MiniGPT-4 as the base model and extend the model’s capabilities to multimodal generation.', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Zhuetal .,', 'url': 'cite.zhu2023minigpt', 'start_index': 221}, {'text': '2023', 'url': 'cite.zhu2023minigpt', 'start_index': 233}, {'text': 'Lietal .,', 'url': 'cite.li2023blip', 'start_index': 239}, {'text': '2023c', 'url': 'cite.li2023blip', 'start_index': 250}, {'text': 'Daietal .,', 'url': 'cite.instructblip', 'start_index': 257}, {'text': '2023', 'url': 'cite.instructblip', 'start_index': 269}, {'text': 'OpenAI', 'url': 'cite.openai2023gpt4', 'start_index': 275}, {'text': '2023', 'url': 'cite.openai2023gpt4', 'start_index': 283}, {'text': 'Lietal .,', 'url': 'cite.li2023otter', 'start_index': 289}, {'text': '2023a', 'url': 'cite.li2023otter', 'start_index': 300}, {'text': 'Alayracetal .,', 'url': 'cite.alayrac2022flamingo', 'start_index': 307}, {'text': '2022', 'url': 'cite.alayrac2022flamingo', 'start_index': 323}, {'text': 'Lietal .,', 'url': 'cite.li-etal-2023-lavis', 'start_index': 329}, {'text': '2023b', 'url': 'cite.li-etal-2023-lavis', 'start_index': 340}, {'text': 'OpenAI', 'url': 'cite.openai2023gpt4', 'start_index': 434}, {'text': '2023', 'url': 'cite.openai2023gpt4', 'start_index': 442}, {'text': 'Zhuetal .,', 'url': 'cite.zhu2023minigpt', 'start_index': 460}, {'text': '2023', 'url': 'cite.zhu2023minigpt', 'start_index': 472}, {'text': 'Lietal .,', 'url': 'cite.li2023blip', 'start_index': 554}, {'text': '2023c', 'url': 'cite.li2023blip', 'start_index': 565}, {'text': 'Chiangetal .,', 'url': 'cite.vicuna2023', 'start_index': 631}, {'text': '2023', 'url': 'cite.vicuna2023', 'start_index': 646}], 'page_number': 2, 'parent_id': 'fe3a08cf7b0ae89bd864e8029526b21d', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '58f894d32f041f18dbc740f22d6cacc5', 'text': 'Text-to-Image Generation To transform textual descriptions into their corresponding visual repre- sentations, text-to-image models (Reed et al., 2016; Dhariwal & Nichol, 2021; Saharia et al., 2022; Rombach et al., 2022b;a; Gu et al., 2023; Nichol et al., 2021; Ramesh et al., 2021; Yu et al., 2022; Chang et al., 2023) employ complex architectures and sophisticated algorithms, bridging the gap be- tween textual information and visual content. These models are adept at interpreting the semantics of input text and translating them into coherent and pertinent images. A notable recent contribution in this field is Stable Diffusion V2 (Rombach et al., 2022b), which employs a diffusion process to generate conditional image features and subsequently reconstructs images from these features. Our research aims to leverage this pretrained model, enhancing its capabilities to accommodate both multimodal input and output.', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Reedetal .,', 'url': 'cite.reed2016generative', 'start_index': 132}, {'text': '2016', 'url': 'cite.reed2016generative', 'start_index': 145}, {'text': 'Dhariwal & Nichol', 'url': 'cite.dhariwal2021diffusion', 'start_index': 151}, {'text': '2021', 'url': 'cite.dhariwal2021diffusion', 'start_index': 170}, {'text': 'Sahariaetal .,', 'url': 'cite.saharia2022photorealistic', 'start_index': 176}, {'text': '2022', 'url': 'cite.saharia2022photorealistic', 'start_index': 192}, {'text': 'Rombachetal .,', 'url': 'cite.rombach2021highresolution', 'start_index': 198}, {'text': '2022b', 'url': 'cite.rombach2021highresolution', 'start_index': 214}, {'text': 'a', 'url': 'cite.rombach2022high', 'start_index': 220}, {'text': 'Guetal .,', 'url': 'cite.gu2023photoswap', 'start_index': 223}, {'text': '2023', 'url': 'cite.gu2023photoswap', 'start_index': 234}, {'text': 'Nicholetal .,', 'url': 'cite.nichol2021glide', 'start_index': 240}, {'text': '2021', 'url': 'cite.nichol2021glide', 'start_index': 255}, {'text': 'Rameshetal .,', 'url': 'cite.ramesh2021zero', 'start_index': 261}, {'text': '2021', 'url': 'cite.ramesh2021zero', 'start_index': 276}, {'text': 'Yuetal .,', 'url': 'cite.yu2022scaling', 'start_index': 282}, {'text': '2022', 'url': 'cite.yu2022scaling', 'start_index': 293}, {'text': 'Changetal .,', 'url': 'cite.chang2023muse', 'start_index': 299}, {'text': '2023', 'url': 'cite.chang2023muse', 'start_index': 313}, {'text': 'Rombachetal .,', 'url': 'cite.rombach2021highresolution', 'start_index': 636}, {'text': '2022b', 'url': 'cite.rombach2021highresolution', 'start_index': 652}], 'page_number': 2, 'parent_id': 'fe3a08cf7b0ae89bd864e8029526b21d', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '4e4e2d076d385269293cbbea412c0d5f', 'text': 'Multimodal Generation with Large Language Models To augment the LLM’s capabilities in seamlessly integrating vision and language generation, recent studies have introduced a variety of', 'metadata': {'languages': ['eng'], 'page_number': 2, 'parent_id': 'fe3a08cf7b0ae89bd864e8029526b21d', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Footer', 'element_id': 'd4735e3a265e16eee03f59718b9b5d03', 'text': '2', 'metadata': {'languages': ['eng'], 'page_number': 2, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '0a2377651792c7246c23f40ec78599c0', 'text': 'Every one elsearrived soonafter.', 'metadata': {'languages': ['eng'], 'page_number': 3, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '4dfa18944a291bf9aa00bc5555ef136d', 'text': \"We didn't realizethat there wasmore to be doneand everyonehad their roles.\", 'metadata': {'languages': ['eng'], 'page_number': 3, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '71336acd82746d3006cefc83d4d8b22b', 'text': 'What should happen then?', 'metadata': {'languages': ['eng'], 'page_number': 3, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '74fceeb8d8578836dcc7bf90205ab36f', 'text': 'My sister arrivedearly to help mewith the familybar bq.', 'metadata': {'languages': ['eng'], 'page_number': 3, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'b6fcf5dc5af94913501b399ad75ccbf7', 'text': 'We were gladwhen it was overand relaxed alittle bit.', 'metadata': {'languages': ['eng'], 'page_number': 3, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'b841779d95fb90f4d9e00d3445cc7112', 'text': 'MiniGPT-5Multimodal InputMultimodal Output', 'metadata': {'languages': ['eng'], 'page_number': 3, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'd8eebe48c969e6674ac405f713ca799f', 'text': 'Everyone washungry so we gota lot of food.', 'metadata': {'languages': ['eng'], 'page_number': 3, 'parent_id': 'b841779d95fb90f4d9e00d3445cc7112', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '817abb362c24597b26b5be00c49297e2', 'text': 'Figure 1: MiniGPT-5 is a unified model for interleaved vision-and-language comprehension and generation. Besides the original multimodal comprehension and text generation abilities, MiniGPT- 5 can provide appropriate, coherent multimodal outputs.', 'metadata': {'languages': ['eng'], 'page_number': 3, 'parent_id': 'b841779d95fb90f4d9e00d3445cc7112', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'f6b6fc6e21a1b2be35555ecb25574b77', 'text': 'innovative methods (Ge et al., 2023; Sun et al., 2021; Koh et al., 2023; Sun et al., 2023b; Yu et al., 2023; Aiello et al., 2023; Wu et al., 2023c). For instance, CM3Leon (Yu et al., 2023) presents a retrieval-augmented, decoder-only architecture designed for both text-to-image and image-to-text applications. Similarly, Emu (Sun et al., 2023b) employs the pretrained EVA-CLIP (Sun et al., 2023a) model to convert images into one-dimensional features and fine-tunes the LLAMA (Touvron et al., 2023) model to generate cohesive text and image features through autoregressive techniques. On the other hand, NextGPT (Wu et al., 2023c), GILL (Koh et al., 2023) and SEED (Ge et al., 2023) explore the concept of mapping vokens into the text feature space of a pretrained Stable Diffusion model; GILL and NextGPT employ an encoder-decoder framework, while SEED utilizes a trainable Q-Former structure. In contrast to these approaches, our model takes a more direct route by aligning voken features with visual information. Additionally, we introduce several training strategies to enhance image quality and contextual coherence.', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Geetal .,', 'url': 'cite.ge2023planting', 'start_index': 20}, {'text': '2023', 'url': 'cite.ge2023planting', 'start_index': 31}, {'text': 'Sunetal .,', 'url': 'cite.sun2021multimodal', 'start_index': 37}, {'text': '2021', 'url': 'cite.sun2021multimodal', 'start_index': 49}, {'text': 'Kohetal .,', 'url': 'cite.koh2023generating', 'start_index': 55}, {'text': '2023', 'url': 'cite.koh2023generating', 'start_index': 67}, {'text': 'Sunetal .,', 'url': 'cite.Emu', 'start_index': 73}, {'text': '2023b', 'url': 'cite.Emu', 'start_index': 85}, {'text': 'Yuetal', 'url': 'cite.yu2023scaling', 'start_index': 92}, {'text': '2023', 'url': 'cite.yu2023scaling', 'start_index': 103}, {'text': 'Aielloetal .,', 'url': 'cite.aiello2023jointly', 'start_index': 109}, {'text': '2023', 'url': 'cite.aiello2023jointly', 'start_index': 124}, {'text': 'Wuetal .,', 'url': 'cite.wu2023nextgpt', 'start_index': 130}, {'text': '2023c', 'url': 'cite.wu2023nextgpt', 'start_index': 141}, {'text': 'Yuetal .,', 'url': 'cite.yu2023scaling', 'start_index': 172}, {'text': '2023', 'url': 'cite.yu2023scaling', 'start_index': 183}, {'text': 'Sunetal .,', 'url': 'cite.Emu', 'start_index': 327}, {'text': '2023b', 'url': 'cite.Emu', 'start_index': 339}, {'text': 'Sunetal', 'url': 'cite.sun2023eva', 'start_index': 379}, {'text': '2023a', 'url': 'cite.sun2023eva', 'start_index': 391}, {'text': '( etal ., 2023 ) modeltogeneratecohesivetextandimagefeaturesthroughautoregressivetechniques', 'url': 'cite.touvron2023llama', 'start_index': 476}, {'text': 'etal .,', 'url': 'cite.touvron2023llama', 'start_index': 485}, {'text': '2023', 'url': 'cite.touvron2023llama', 'start_index': 493}, {'text': 'Wuetal .,', 'url': 'cite.wu2023nextgpt', 'start_index': 613}, {'text': '2023c', 'url': 'cite.wu2023nextgpt', 'start_index': 624}, {'text': 'Kohetal .,', 'url': 'cite.koh2023generating', 'start_index': 638}, {'text': '2023', 'url': 'cite.koh2023generating', 'start_index': 650}, {'text': 'Geetal .,', 'url': 'cite.ge2023planting', 'start_index': 666}, {'text': '2023', 'url': 'cite.ge2023planting', 'start_index': 677}], 'page_number': 3, 'parent_id': 'b841779d95fb90f4d9e00d3445cc7112', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'a694abcba154d7e0f16411f0976b65e5', 'text': '3 METHOD', 'metadata': {'languages': ['eng'], 'page_number': 3, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'c08ecef591c8414a37d06432293d11ee', 'text': 'In order to endow Large Language Models with multimodal generation capabilities, we introduce a new framework that integrates pretrained multimodal Large Language Models and text-to-image generation models. Central to our approach is the introduction of “generative vokens”, special visual tokens that effectively bridge the textual and visual domains during the training process. Addition- ally, we implement a two-stage training method combined with a classifier-free guidance strategy to enhance the quality and coherence of generated outputs. Fig. 2 provides an overview of our model structure. MiniGPT-5 primarily consists of two modules: the Integrated Vision-Language Encod- ing Module, utilizing the pretrained multimodal large language model (MiniGPT-4) for handling multimodal inputs, and the Multimodal Output Generation module, employing Stable Diffusion for generating visual outputs.', 'metadata': {'languages': ['eng'], 'links': [{'text': '.', 'url': 'figure.caption.2', 'start_index': 549}], 'page_number': 3, 'parent_id': 'a694abcba154d7e0f16411f0976b65e5', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '4cd6157fb0434cf5b78c33f16e886688', 'text': 'Recent advancements in multimodal Large Language Models, such as MiniGPT-4 (Zhu et al., 2023), have primarily concentrated on multimodal comprehension, enabling the processing of images as sequential input. The Integrated Vision-Language Encoding Module is designed to extend the capa- bilities of LLMs from mere comprehension to active generation in multimodal contexts. Generative', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Zhuetal .,', 'url': 'cite.zhu2023minigpt', 'start_index': 76}, {'text': '2023', 'url': 'cite.zhu2023minigpt', 'start_index': 88}], 'page_number': 3, 'parent_id': 'a694abcba154d7e0f16411f0976b65e5', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '621f732f140493538c8f62721e025ad4', 'text': '3.1 MULTIMODAL UNDERSTANDING MODULE', 'metadata': {'languages': ['eng'], 'page_number': 3, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Footer', 'element_id': '4e07408562bedb8b60ce05c1decfe3ad', 'text': '3', 'metadata': {'languages': ['eng'], 'page_number': 3, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '10b1f6a1b0b515502e58ebbd843ac9a9', 'text': '\"A discus gotstuck up on theroof.\"', 'metadata': {'languages': ['eng'], 'page_number': 4, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '11d2c29f8b8f0129b92a3f3538c52c24', 'text': 'TransformerDecoder', 'metadata': {'languages': ['eng'], 'page_number': 4, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '2b5b1f45790b9882d4f9e3f5aa9fbd8e', 'text': 'Linear LayerVoken Features', 'metadata': {'languages': ['eng'], 'page_number': 4, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '32b7f87982e4e680386ba9ffad76b4eb', 'text': 'TextTokenizer', 'metadata': {'languages': ['eng'], 'page_number': 4, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '489c85b8190daa50b7704c6411191385', 'text': 'PEFT', 'metadata': {'languages': ['eng'], 'page_number': 4, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '4be5ba6bb93c77f95d571ae377b3025c', 'text': 'Learnable Queries', 'metadata': {'languages': ['eng'], 'page_number': 4, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '5197d3c54433ae1b75d526fbf61b6621', 'text': 'SDUnet', 'metadata': {'languages': ['eng'], 'page_number': 4, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '55e2e545bc2309ddcea8e0f490ac28d3', 'text': 'ImageEncoder', 'metadata': {'languages': ['eng'], 'page_number': 4, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '8da9e2f989f77d97523346ec9c04db58', 'text': 'TransformerEncoderFeature Mapper', 'metadata': {'languages': ['eng'], 'page_number': 4, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '92029c3bd7baa4ffc29397858a297bb5', 'text': 'Zt', 'metadata': {'languages': ['eng'], 'page_number': 4, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '977328c6a44e78eed86f423f7ec0df1b', 'text': '\"Why not try getting it down with a soccerball? [IMG 1] ... [IMG n]\"', 'metadata': {'languages': ['eng'], 'page_number': 4, 'parent_id': '92029c3bd7baa4ffc29397858a297bb5', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '9ada8e83c1186cd632fb2ac8195abc11', 'text': 'Noise', 'metadata': {'languages': ['eng'], 'page_number': 4, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'ae35cf8d69f4652fbe9dc56e5e19907f', 'text': 'SD ImageEncoder', 'metadata': {'languages': ['eng'], 'page_number': 4, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'b9b3d33f80c1dfea793abe269bc4b07d', 'text': 'VokenPositioningLossVokenAlignmentLossGT Output TextMultimodal InputGT Output Image', 'metadata': {'languages': ['eng'], 'page_number': 4, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'bbeebd879e1dff6918546dc0c179fdde', 'text': 'Z', 'metadata': {'languages': ['eng'], 'page_number': 4, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'ed6bb5cba943b4cf4134f1d3b271248d', 'text': 'LLM (Vicuna)', 'metadata': {'languages': ['eng'], 'page_number': 4, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'f3eb07f6868904e42886b860ef4218c0', 'text': 'EstimatedNoise', 'metadata': {'languages': ['eng'], 'page_number': 4, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'fa9f0eeed0805f46f3480f48fec20f6e', 'text': 'Output Hidden State', 'metadata': {'languages': ['eng'], 'page_number': 4, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'cb76fc605b58fcc6e79316ecab4748b4', 'text': 'Figure 2: The overview structure of MiniGPT-5 pipeline. We leverage the pretrained multimodal large language model (MiniGPT-4) and text-to-image generation model (Stable Diffusion 2.1) to create a unified multimodal generation pipeline. The input image encoder includes a ViT, Qformer, and linear layer, pretrained by MiniGPT-4. The orange blocks include learnable parameters, while the blue blocks are fixed during training. More details can be found in Section 3.', 'metadata': {'languages': ['eng'], 'page_number': 4, 'parent_id': 'fa9f0eeed0805f46f3480f48fec20f6e', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '4f418181e3383f64ceb719d5cd72d548', 'text': 'vokens play a crucial role in this module, enabling the translation of raw visual inputs into a format that LLMs can process and utilize for subsequent generation tasks.', 'metadata': {'languages': ['eng'], 'page_number': 4, 'parent_id': 'fa9f0eeed0805f46f3480f48fec20f6e', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '18e24963d1b854f5dd25e3aecfe6bbcb', 'text': 'Multimodal Encoding Each text token is embedded into a vector etext ∈ Rd, while the pretrained visual encoder transforms each input image into the feature eimg ∈ R32×d. These embeddings are concatenated to create the input prompt features.', 'metadata': {'languages': ['eng'], 'page_number': 4, 'parent_id': 'fa9f0eeed0805f46f3480f48fec20f6e', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '845f88054f9e77f50cb170d00dd73301', 'text': 'Generative Vokens Since the original LLM’s V vocabulary only includes the textual tokens, we need to construct a bridge between the LLM and the generative model. Therefore, we introduce a set of special tokens Vimg = {[IMG1], [IMG2], . . . , [IMGn]} (by default n = 8) as generative vokens into the LLM’s vocabulary V . The LLM’s output hidden state for these vokens is harnessed for subsequent image generation, and the positions of these vokens can represent the insertion of the in- terleaved images. With all pretrained weights θpretrained in MiniGPT-4 fixed, the trainable parameters include extra input embedding θvoken input and output embedding θvoken output.', 'metadata': {'languages': ['eng'], 'page_number': 4, 'parent_id': 'fa9f0eeed0805f46f3480f48fec20f6e', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'b69f4fadb030e84ad561297aa1b45b7c', 'text': 'Parameter-Efficient Fine-Tuning (PEFT) Parameter-efficient fine-tuning (PEFT) (Houlsby et al., 2019; Hu et al., 2021; Li & Liang, 2021) is critical in training Large Language Models (LLMs), employed to adapt LLMs to downstream tasks without the need for extensive retraining. In PEFT, rather than updating all the parameters of a model, only a small subset of parameters is trained. This subset typically includes task-specific components or lightweight layers added to the original model architecture (Zhang et al., 2021; Houlsby et al., 2019; Hu et al., 2021; Dettmers et al., 2023). We apply PEFT to the MiniGPT-4 (Zhu et al., 2023) encoder, enhancing its ability to process and generate multimodal content based on given instructions or prompts. More specifically, this involves the use of prefix tuning (Li & Liang, 2021) and LoRAHu et al. (2021) over the entire language encoder – Vicuna (Chiang et al., 2023) used in MiniGPT-4. Additionally, we implement learnable queries at the input of the transformer decoder, a conventional approach in sequence-to-sequence transformer architectures, to further improve the model’s multimodal generation capabilities. We also adopted learnable queries at the input of the transformer decoder as a conventional setting for sequence-to-sequence transformer architectures (Vaswani et al., 2017a). Learnable queries in the decoder allow the model to have dynamic, adaptable representations for initiating the generation process. This is particularly useful when the model needs to generate outputs based on a mix of visual and textual inputs. Combined with the instruction tuning (Ouyang et al., 2022), it notably amplifies multimodal generation performance across various datasets.', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Houlsbyetal', 'url': 'cite.houlsby2019parameter', 'start_index': 76}, {'text': '2019', 'url': 'cite.houlsby2019parameter', 'start_index': 92}, {'text': 'Huetal .,', 'url': 'cite.hu2021lora', 'start_index': 98}, {'text': '2021', 'url': 'cite.hu2021lora', 'start_index': 109}, {'text': 'Li & Liang', 'url': 'cite.li2021prefix', 'start_index': 115}, {'text': '2021', 'url': 'cite.li2021prefix', 'start_index': 127}, {'text': 'Zhangetal .,', 'url': 'cite.tip_adapter', 'start_index': 499}, {'text': '2021', 'url': 'cite.tip_adapter', 'start_index': 513}, {'text': 'Houlsbyetal .,', 'url': 'cite.houlsby2019parameter', 'start_index': 519}, {'text': '2019', 'url': 'cite.houlsby2019parameter', 'start_index': 535}, {'text': 'Huetal .,', 'url': 'cite.hu2021lora', 'start_index': 541}, {'text': '2021', 'url': 'cite.hu2021lora', 'start_index': 552}, {'text': 'Dettmersetal .,', 'url': 'cite.dettmers2023qlora', 'start_index': 558}, {'text': '2023', 'url': 'cite.dettmers2023qlora', 'start_index': 575}, {'text': 'Zhuetal .,', 'url': 'cite.zhu2023minigpt', 'start_index': 614}, {'text': '2023', 'url': 'cite.zhu2023minigpt', 'start_index': 626}, {'text': 'Li & Liang', 'url': 'cite.li2021prefix', 'start_index': 803}, {'text': '2021', 'url': 'cite.li2021prefix', 'start_index': 815}, {'text': '-', 'url': 'cite.hu2021lora', 'start_index': 925}, {'text': '2021', 'url': 'cite.hu2021lora', 'start_index': 840}, {'text': 'Chiangetal .,', 'url': 'cite.vicuna2023', 'start_index': 889}, {'text': '2023', 'url': 'cite.vicuna2023', 'start_index': 904}, {'text': 'Vaswanietal .,', 'url': 'cite.transformer', 'start_index': 1309}, {'text': '2017a', 'url': 'cite.transformer', 'start_index': 1325}, {'text': 'Ouyangetal .,', 'url': 'cite.training_lm', 'start_index': 1616}, {'text': '2022', 'url': 'cite.training_lm', 'start_index': 1631}], 'page_number': 4, 'parent_id': 'fa9f0eeed0805f46f3480f48fec20f6e', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Footer', 'element_id': '4b227777d4dd1fc61c6f884f48641d02', 'text': '4', 'metadata': {'languages': ['eng'], 'page_number': 4, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '35ad4b2d88b9b6b1cf0668c4f69f829a', 'text': '3.2 MUTIMODAL GENERATION MODULE', 'metadata': {'languages': ['eng'], 'page_number': 5, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '284c7be36f3dd00a66013b1884aedbf7', 'text': 'To accurately align the generative vokens with the text-to-image generation models, we formulate a compact mapping module for dimension matching and incorporate several supervised losses, includ- ing voken positioning loss and voken alignment loss. The voken positioning loss assists the model in learning the correct positioning of tokens, while the voken alignment loss directly aligns the vo- kens with the appropriate conditional generation features of the diffusion model. Since the gradients of generative vokens’ features can be directly calculated from images, shown on the right side of Fig. 2, our method does not need comprehensive descriptions of images, leading to description-free learning.', 'metadata': {'languages': ['eng'], 'links': [{'text': '2', 'url': 'figure.caption.2', 'start_index': 601}], 'page_number': 5, 'parent_id': '35ad4b2d88b9b6b1cf0668c4f69f829a', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '5550bbfe7ae4e71b5962bcf16c1d9659', 'text': 'Voken Positioning We first jointly generate both text and vokens in the text space by follow- ing next-word prediction in autoregressive language model (Vaswani et al., 2017b). During the training, we append the vokens Vimg to the positions of ground truth images and train the model to predict vokens within text generation. Specifically, the generated tokens are represented as W = {w1, w2, . . . , wm}, where wi ∈ V ∪ Vimg, and the causal language modeling loss is defined as:', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Vaswanietal .,', 'url': 'cite.vaswani2017attention', 'start_index': 152}, {'text': '2017b', 'url': 'cite.vaswani2017attention', 'start_index': 168}], 'page_number': 5, 'parent_id': '35ad4b2d88b9b6b1cf0668c4f69f829a', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '7e94e2aeec2553b8b9ec545aa2f221da', 'text': 'Ltext := −', 'metadata': {'languages': ['eng'], 'page_number': 5, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'aa8c521d05bdbbfb56c7c2b7bfecb7c5', 'text': 'm (cid:88)', 'metadata': {'languages': ['eng'], 'page_number': 5, 'parent_id': '7e94e2aeec2553b8b9ec545aa2f221da', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '8ed5f55df7e976aa56d3cbf5ac59e5eb', 'text': 'logp(wi|etext, eimg, w1, . . . , wi−1;', 'metadata': {'languages': ['eng'], 'page_number': 5, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '3762bf925b6f0e5b69f0ab26eb347bd6', 'text': 'i=1', 'metadata': {'languages': ['eng'], 'page_number': 5, 'parent_id': '8ed5f55df7e976aa56d3cbf5ac59e5eb', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '2942176dcfedc6c9c70ca4cce9838c48', 'text': 'θpretrained, θvoken input, θvoken output), where wi ∈ V ∪ Vimg', 'metadata': {'languages': ['eng'], 'page_number': 5, 'parent_id': '8ed5f55df7e976aa56d3cbf5ac59e5eb', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '6aaacd9f9e2028dfb27c4131a2876f32', 'text': 'Voken Alignment for Image Generation Next, we align the output hidden state hvoken, shown in Fig. 2, with the conditional feature space of the text-to-image generation model. To map the voken feature hvoken to a feasible image generation conditional feature etext encoder ∈ RL× ˆd (where L is the maximum input length of text-to-image generation text encoder, and ˆd is the dimension of encoder output feature in text-to-image generation model). We construct a feature mapper module, including a two-layer MLP model θMLP, a four-layer encoder-decoder transformer model θenc-dec, and a learnable decoder feature sequence q. The mapping feature ˆhvoken is then given by:', 'metadata': {'languages': ['eng'], 'links': [{'text': '2', 'url': 'figure.caption.2', 'start_index': 98}], 'page_number': 5, 'parent_id': '8ed5f55df7e976aa56d3cbf5ac59e5eb', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '10d5cca801335bb5d82b99de19dca678', 'text': 'ˆhvoken := θenc-dec(θMLP(hvoken), q) ∈ RL× ˆd', 'metadata': {'languages': ['eng'], 'page_number': 5, 'parent_id': '8ed5f55df7e976aa56d3cbf5ac59e5eb', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'df956ff68f91809eb4e016cb44d9e596', 'text': 'To generate appropriate images, the mapping feature ˆhvoken is used as a conditional input in the denoising process. Intuitively, ˆhvoken should represent the corresponding conditional features that conduct the diffusion model to generate the ground truth image. We employ the latent diffusion model (LDM) loss as voken alignment loss for training the image generation module. During the training, the ground truth image is first converted to latent feature z0 through the pretrained VAE (Variational Autoencoder) (Kingma & Welling, 2013). Then, we obtain the noisy latent feature zt by adding noise ϵ to z0. A pretrained U-Net model ϵθ is used to calculate the conditional LDM loss as: (cid:20)(cid:13) (cid:13) (cid:13)ϵ − ϵθ', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Kingma & Welling', 'url': 'cite.vae', 'start_index': 514}, {'text': '2013', 'url': 'cite.vae', 'start_index': 532}], 'page_number': 5, 'parent_id': '8ed5f55df7e976aa56d3cbf5ac59e5eb', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'a84525e6c73d6a7e8f9eae1c15a94717', 'text': '(cid:21)', 'metadata': {'languages': ['eng'], 'page_number': 5, 'parent_id': '8ed5f55df7e976aa56d3cbf5ac59e5eb', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'b7c91fd010238e0c5ead2bfc2e85d981', 'text': '(cid:17)(cid:13) 2 (cid:13) (cid:13) 2', 'metadata': {'languages': ['eng'], 'page_number': 5, 'parent_id': '8ed5f55df7e976aa56d3cbf5ac59e5eb', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'ba17d9e81390ecd77cf7542d02d5402b', 'text': '(cid:16)', 'metadata': {'languages': ['eng'], 'page_number': 5, 'parent_id': '8ed5f55df7e976aa56d3cbf5ac59e5eb', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '4879ea55709b1e72c9a339b4a1d41e17', 'text': 'zt, t, ˆhvoken', 'metadata': {'languages': ['eng'], 'page_number': 5, 'parent_id': '8ed5f55df7e976aa56d3cbf5ac59e5eb', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'afcdc60f3537d95d0d019fff2519134f', 'text': 'LLDM := Eϵ∼N (0,1),t', 'metadata': {'languages': ['eng'], 'page_number': 5, 'parent_id': '8ed5f55df7e976aa56d3cbf5ac59e5eb', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '091f32993f9d9be8c17c1b72c0e591fb', 'text': 'To summarize, the voken positioning loss enables the model to learn the accurate placement of tokens. Without this component, the model lacks the essential capability to predict when vokens should be generated during inference. Additionally, the voken alignment loss ensures the direct correspondence between vokens and the appropriate conditional generation characteristics of the diffusion model. In the absence of this loss, the model is unable to learn semantic vokens from images directly. This comprehensive approach ensures a coherent understanding and generation of both textual and visual elements, leveraging the capabilities of pretrained models, specialized tokens, and innovative training techniques.', 'metadata': {'languages': ['eng'], 'page_number': 5, 'parent_id': '8ed5f55df7e976aa56d3cbf5ac59e5eb', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'f3a5c4c54a08165e043096fc69b830b3', 'text': '3.3 TRAINING STRATEGY', 'metadata': {'languages': ['eng'], 'page_number': 5, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'd16feb0593ce1e0f07e83bbdb108e072', 'text': 'Given the non-negligible domain shift between text and image domains, we observe that direct training on a limited interleaved text-and-image dataset can result in misaligning generated texts', 'metadata': {'languages': ['eng'], 'page_number': 5, 'parent_id': 'f3a5c4c54a08165e043096fc69b830b3', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'fd0ad9026eee596b7072a762941f60be', 'text': '(1)', 'metadata': {'languages': ['eng'], 'page_number': 5, 'parent_id': 'f3a5c4c54a08165e043096fc69b830b3', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '0e77e68ba5473d98840c3212f4a8cb80', 'text': '(2)', 'metadata': {'languages': ['eng'], 'page_number': 5, 'parent_id': 'f3a5c4c54a08165e043096fc69b830b3', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '46f789d1efeefad080846917a6a4a761', 'text': '(3)', 'metadata': {'languages': ['eng'], 'page_number': 5, 'parent_id': 'f3a5c4c54a08165e043096fc69b830b3', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Footer', 'element_id': 'ef2d127de37b942baad06145e54b0c61', 'text': '5', 'metadata': {'languages': ['eng'], 'page_number': 5, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'd2ea6c30a691f1c14f2db565488d7858', 'text': 'and images and diminished image quality. Consequently, we adopt a two-stage training strategy: an initial pretraining stage focusing on coarse feature alignment for unimodal generation, followed by a fine-tuning stage dedicated to intricate feature learning for multimodal generation. Furthermore, to amplify the effectiveness of the generative tokens throughout the diffusion process, we incorporate the idea of classifier-free guidance (Ho & Salimans, 2022) technique through the whole training process.', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Ho & Salimans', 'url': 'cite.classifier_free_guidance', 'start_index': 437}, {'text': '2022', 'url': 'cite.classifier_free_guidance', 'start_index': 452}], 'page_number': 6, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'cc20e3962f9598e6c680e766ad9aebf0', 'text': 'Two-stage Training Strategy Recognizing the non-trivial domain shift between pure-text gener- ation and text-image generation, we propose a two-stage training strategy: Pretraining Stage and Fine-tuning Stage. Initially, we align the voken feature with image generation features in single text-image pair datasets, such as CC3M, where each data sample only contains one text and one im- age, and the text is usually the caption of the image. During this stage, we utilize captions as LLM input, enabling LLM to generate vokens. Since these datasets include the image descriptive infor- mation, we also introduce an auxiliary loss to aid voken alignment, minimizing the distance between the generative feature ˆhvoken and the caption feature from the text encoder τθ in the text-to-image generation model:', 'metadata': {'languages': ['eng'], 'page_number': 6, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '3eb8d5fc4cbe455c02cb0b93a7463e3f', 'text': 'LCAP := MSE(ˆhvoken, τθ(c)) The pretraining stage loss is expressed as LPretrain = λ1 ∗Ltext +λ2 ∗LLDM +λ3 ∗LCAP, with selected values λ1 = 0.01, λ2 = 1, λ3 = 0.1 to rescale the loss into a similar numerical range.', 'metadata': {'languages': ['eng'], 'page_number': 6, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'a49997a8730c08c7b3fd3ec137bc5a73', 'text': 'After the pretraining stage, the model is capable of generating images for single text descriptions but struggles with interleaved vision-and-language generation, which includes multiple text-image pairs and requires complicated reasoning for both text and image generation. To address this, in the fine-tuning stage, we further fine-tune our model with PEFT parameters by interleaved vision- and-language datasets, such as VIST, where the data sample has several steps with text-image and texts are sequentially relevant. During this stage, we construct three types of tasks from the dataset, encompassing (1) text-only generation: given the next image, generating the related text; (2) image- only generation: given the next text, generating the related image, and (3) multimodal generation: generating text-image pair by given context. The fine-tuning stage loss is given by LFine-tune = λ1 ∗ Ltext + λ2 ∗ LLDM. More implementation details can be found in Appendix A.', 'metadata': {'languages': ['eng'], 'links': [{'text': 'multimodalgeneration generatingtext - imagepairbygivencontext . Thefine - tuningstagelossisgivenbyLFine - tune λ1 ∗ Ltext + λ2 ∗ LLDM . MoreimplementationdetailscanbefoundinAppendixA', 'url': 'appendix.A', 'start_index': 769}], 'page_number': 6, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '7d407ad1fe53af0b4f9c5cb4370417d3', 'text': 'Classifier-Free Guidance (CFG) To enhance the coherence between the generated text and im- ages, we first leverage the idea of Classifier-free Guidance for multimodal generation. Classifier- free guidance is introduced in the text-to-image diffusion process. This method observes that the generation model Pθ can achieve improved conditional results by training on both conditional and unconditional generation with conditioning dropout. In our context, we want the model to focus directly on the output features hvoken from LLM. Instead of using original stable diffusion uncondi- tional distributions (dropping ˆhvoken), the whole feature mapper also needs to be included during the unconditional process. Therefore, our objective is to accentuate the trainable condition hvoken and the generation model is fixed. During training, we replace hvoken with zero features h0 ∈ 0n×d with a 10% probability, obtaining the unconditional feature ˆh0 = θenc-dec(θMLP(h0), q). During inference, ˆh0 serves as negative prompting, and the refined denoising process is:', 'metadata': {'languages': ['eng'], 'page_number': 6, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'cbe3b52ccdb46fd15e9f52b372fc95b5', 'text': '(4)', 'metadata': {'languages': ['eng'], 'page_number': 6, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '97ce6126f9bad63aac5ddf4679f0612c', 'text': '(5)', 'metadata': {'languages': ['eng'], 'page_number': 6, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'ba17d9e81390ecd77cf7542d02d5402b', 'text': '(cid:16)', 'metadata': {'languages': ['eng'], 'page_number': 6, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '2244cbd6a8f540a402e0e7a291285607', 'text': 'log (cid:99)Pθ (cid:16)', 'metadata': {'languages': ['eng'], 'page_number': 6, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'adbccba1f4f9f51c98fb2bcaff038706', 'text': 'γ', 'metadata': {'languages': ['eng'], 'page_number': 6, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'ed058146bab545d3120c2fdf46134680', 'text': 'log Pθ', 'metadata': {'languages': ['eng'], 'page_number': 6, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '6ecd1d94bfac201a342d8efa4cae843b', 'text': '(cid:17)', 'metadata': {'languages': ['eng'], 'page_number': 6, 'parent_id': 'ed058146bab545d3120c2fdf46134680', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'fa0ef9607fdc9c0a5485ffee93f54678', 'text': '= log Pθ (cid:16)', 'metadata': {'languages': ['eng'], 'page_number': 6, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '0e09f902051a2cc9afb93cdaba4080ff', 'text': '− log Pθ', 'metadata': {'languages': ['eng'], 'page_number': 6, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'ba17d9e81390ecd77cf7542d02d5402b', 'text': '(cid:16)', 'metadata': {'languages': ['eng'], 'page_number': 6, 'parent_id': '0e09f902051a2cc9afb93cdaba4080ff', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '16201aee4ebe86529c09bb6e19379da9', 'text': 'ϵt | zt+1, ˆh0', 'metadata': {'languages': ['eng'], 'page_number': 6, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '16201aee4ebe86529c09bb6e19379da9', 'text': 'ϵt | zt+1, ˆh0', 'metadata': {'languages': ['eng'], 'page_number': 6, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '6ecd1d94bfac201a342d8efa4cae843b', 'text': '(cid:17)', 'metadata': {'languages': ['eng'], 'page_number': 6, 'parent_id': '16201aee4ebe86529c09bb6e19379da9', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '6a1f93315ec0650adf9a35b40571aecd', 'text': '(cid:17)(cid:17)', 'metadata': {'languages': ['eng'], 'page_number': 6, 'parent_id': '16201aee4ebe86529c09bb6e19379da9', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'a318c24216defe206feeb73ef5be0003', 'text': '+', 'metadata': {'languages': ['eng'], 'page_number': 6, 'parent_id': '16201aee4ebe86529c09bb6e19379da9', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'cad8ea75d9eb562da24b75d67277d806', 'text': 'ϵt | zt+1, ˆhvoken, ˆh0 (cid:17) (cid:16)', 'metadata': {'languages': ['eng'], 'page_number': 6, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '440d337b184e9983ae2a1df67ac76d43', 'text': 'ϵt | zt+1, ˆhvoken', 'metadata': {'languages': ['eng'], 'page_number': 6, 'parent_id': 'cad8ea75d9eb562da24b75d67277d806', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '4f26edd0d82502405db1ff3abbac5d95', 'text': '4 EXPERIMENTS', 'metadata': {'languages': ['eng'], 'page_number': 6, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '0aab5cea3fbf4cabf5c85c142d700299', 'text': 'To assess the efficacy of our model, we conducted a series of evaluations across multiple bench- marks. These experiments aim to address several key questions: (1) Can our model generate plausi- ble images and reasonable texts? (2) How does our model compare with state-of-the-art models in both single-turn and multi-turn interleaved vision-and-language generation tasks? (3) What impact does the design of each module have on overall performance? Below we will discuss the experimen- tal setup and present a comprehensive analysis of our model’s performance. We use three datasets: CC3M (Sharma et al., 2018), VIST (Huang et al., 2016), and MMDialog (Feng et al., 2022). More details about datasets and data format can be found in Appendix B.', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Sharmaetal .,', 'url': 'cite.sharma2018conceptual', 'start_index': 589}, {'text': '2018', 'url': 'cite.sharma2018conceptual', 'start_index': 604}, {'text': 'Huangetal .,', 'url': 'cite.huang2016visual', 'start_index': 617}, {'text': '2016', 'url': 'cite.huang2016visual', 'start_index': 631}, {'text': 'Fengetal .,', 'url': 'cite.feng2022mmdialog', 'start_index': 652}, {'text': '2022', 'url': 'cite.feng2022mmdialog', 'start_index': 665}, {'text': 'sperformance . Weusethreedatasets CC3M ( Sharmaetal ., 2018 ), VIST ( Huangetal ., 2016 ), andMMDialog ( Fengetal ., 2022 ). detailsaboutdatasetsanddataformatcanbefoundinAppendixB', 'url': 'appendix.B', 'start_index': 545}], 'page_number': 6, 'parent_id': '4f26edd0d82502405db1ff3abbac5d95', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Footer', 'element_id': 'e7f6c011776e8db7cd330b54174fd76f', 'text': '6', 'metadata': {'languages': ['eng'], 'page_number': 6, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'dc5e4619a4e67f99db6c5d6f5be5f784', 'text': 'Table 1: Image generation on VIST. Given the historical context, models need to generate im- ages for each step. FID scores evaluate the vi- sual diversities between generated and ground truth images within each story sequence.', 'metadata': {'languages': ['eng'], 'page_number': 7, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '5e2c614c23f02239bc03c6c04fcb6819', 'text': 'Model', 'metadata': {'languages': ['eng'], 'page_number': 7, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'ff6f0ce218ddf400a85e5e6aca5f7789', 'text': 'CLIP-I (↑)', 'metadata': {'languages': ['eng'], 'page_number': 7, 'parent_id': '5e2c614c23f02239bc03c6c04fcb6819', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '0d6339d2b85b7d5ad6801154a96ace83', 'text': 'FID (↓)', 'metadata': {'languages': ['eng'], 'page_number': 7, 'parent_id': '5e2c614c23f02239bc03c6c04fcb6819', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '3a6e05ee6e5027f1c02c483ce0ec60ac', 'text': 'SD 2.1 (Rombach et al., 2022b) Fine-tuned SD 2.1 Two-stage Baseline GILL (Koh et al., 2023) MiniGPT-5 (Prefix Tuning) MiniGPT-5 (LoRA)', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Rombachetal .,', 'url': 'cite.rombach2021highresolution', 'start_index': 8}, {'text': '2022b', 'url': 'cite.rombach2021highresolution', 'start_index': 24}, {'text': 'Kohetal .,', 'url': 'cite.koh2023generating', 'start_index': 74}, {'text': '2023', 'url': 'cite.koh2023generating', 'start_index': 86}], 'page_number': 7, 'parent_id': '5e2c614c23f02239bc03c6c04fcb6819', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '45660126e2517ac25eb6fbae06b0c87e', 'text': '0.59 0.61 0.57 0.60 0.65 0.66', 'metadata': {'languages': ['eng'], 'page_number': 7, 'parent_id': '5e2c614c23f02239bc03c6c04fcb6819', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'e857551f95b9a9224c4784e28d06a037', 'text': '393.49 390.25 403.06 381.88 381.55 366.62', 'metadata': {'languages': ['eng'], 'page_number': 7, 'parent_id': '5e2c614c23f02239bc03c6c04fcb6819', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'b811f358a7d2015057ffeef8c06f5e84', 'text': 'Table 2: Narration Generation on VIST. We added LoRA fine-tuning for GILL, MiniGPT- 4, and MiniGPT-5 with the same LoRA config- uration. The results show that adding genera- tive vokens does not hurt the performance on the multimodal comprehension tasks.', 'metadata': {'languages': ['eng'], 'page_number': 7, 'parent_id': '5e2c614c23f02239bc03c6c04fcb6819', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '5e2c614c23f02239bc03c6c04fcb6819', 'text': 'Model', 'metadata': {'languages': ['eng'], 'page_number': 7, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '4de783274939a1bfba725362ac5869e4', 'text': 'S-BERT (↑) Rouge-L (↑) Meteor (↑)', 'metadata': {'languages': ['eng'], 'page_number': 7, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'd103f3454708dddb70a6e2feae2cc2de', 'text': 'GILL (Koh et al., 2023) MiniGPT-4 (Zhu et al., 2023) MiniGPT-5', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Zhuetal .,', 'url': 'cite.zhu2023minigpt', 'start_index': 35}, {'text': '2023', 'url': 'cite.zhu2023minigpt', 'start_index': 47}], 'page_number': 7, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '40437008c91591c8d26c77b505b3d2a7', 'text': '0.3864 0.6273 0.6315', 'metadata': {'languages': ['eng'], 'page_number': 7, 'parent_id': 'd103f3454708dddb70a6e2feae2cc2de', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '1d0fc6c8b66a2c86bfb2d1f325fbcd94', 'text': '0.1784 0.3401 0.3373', 'metadata': {'languages': ['eng'], 'page_number': 7, 'parent_id': 'd103f3454708dddb70a6e2feae2cc2de', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'c73776212623012eca79e471ddf9ef9e', 'text': '0.1951 0.3296 0.3263', 'metadata': {'languages': ['eng'], 'page_number': 7, 'parent_id': 'd103f3454708dddb70a6e2feae2cc2de', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '915c956b56eac6aaf7eaf34e617bca39', 'text': '4.1 EXPERIMENTAL SETUP', 'metadata': {'languages': ['eng'], 'page_number': 7, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '8f66419e3a9782ec5a789d3b5b6d32a6', 'text': 'Baselines For a comprehensive evaluation of our performance in multimodal generation, we con- the Fine-tuned Unimodal ducted comparative analyses with several prominent baseline models: Generation Models, Two-stage Baseline, GILL, and Divter.', 'metadata': {'languages': ['eng'], 'page_number': 7, 'parent_id': '915c956b56eac6aaf7eaf34e617bca39', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'ListItem', 'element_id': '363834972355ed636ca42fe3a6f44b1b', 'text': 'Fine-tuned Unimodal Generation Models: To facilitate fair comparisons in both image and text generation, we fine-tuned two separate models, Stable Diffusion 2.1 and MiniGPT- 4 (Zhu et al., 2023), utilizing the VIST dataset. Within the Stable Diffusion 2.1 (Rombach et al., 2022b) model, the U-Net parameters were fine-tuned. For MiniGPT-4’s LLM part, LoRA parameters were fine-tuned.', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Zhuetal .,', 'url': 'cite.zhu2023minigpt', 'start_index': 178}, {'text': '2023', 'url': 'cite.zhu2023minigpt', 'start_index': 190}, {'text': '( etal ., 2022b ) model , theU - Netparameterswerefine - tuned . ForMiniGPT - 4 ’ sLLMpart', 'url': 'cite.rombach2021highresolution', 'start_index': 257}, {'text': 'etal .,', 'url': 'cite.rombach2021highresolution', 'start_index': 266}, {'text': '2022b', 'url': 'cite.rombach2021highresolution', 'start_index': 274}], 'page_number': 7, 'parent_id': '915c956b56eac6aaf7eaf34e617bca39', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'ListItem', 'element_id': '36c9a59391878be8209a1aa14b108c51', 'text': 'Two-stage Baseline: A common approach in multimodal generation involves first employ- ing Large Language Models (LLMs) to create image captions, which are then fed into text-to-image models for image generation (Wu et al., 2023b). We create such a two-stage baseline for comparison with our end-to-end method by fine-tuning MiniGPT-4 for caption generation and Stable Diffusion 2.1 for text-to-image generation. Given the absence of image descriptions in the VIST dataset, we incorporate a SOTA image captioning model, InstructBLIP-13B (Dai et al., 2023), to generate synthetic captions for supervision.', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Wuetal .,', 'url': 'cite.wu2023visual', 'start_index': 213}, {'text': '2023b', 'url': 'cite.wu2023visual', 'start_index': 224}, {'text': 'Daietal .,', 'url': 'cite.instructblip', 'start_index': 537}, {'text': '2023', 'url': 'cite.instructblip', 'start_index': 549}], 'page_number': 7, 'parent_id': '915c956b56eac6aaf7eaf34e617bca39', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'ListItem', 'element_id': 'f92ddb5c7a68864cad6e3bd3a34ad193', 'text': 'GILL1 (Koh et al., 2023): GILL is a recent innovation that allows the LLM to generate vokens using a pre-trained text-to-image generation model for single-image generation, where GILL minimizes the Mean Squared Error (MSE) loss between the text-to-image text encoding feature and voken features, similar to LCAP in our approach. For fine-tuning on multimodal datasets, since GILL requires image captions for training, we use Descriptions of Images-in-Isolation (DII) (Huang et al., 2016) in the VIST fine-tuning and generate captions for MMDialog fine-tuning. Contrarily, MiniGPT-5 does not related on all caption data during multimodal generation fine-tuning.', 'metadata': {'languages': ['eng'], 'links': [{'text': '(', 'url': 'Hfootnote.1', 'start_index': 8}, {'text': 'Kohetal .,', 'url': 'cite.koh2023generating', 'start_index': 9}, {'text': '2023', 'url': 'cite.koh2023generating', 'start_index': 21}, {'text': 'Huangetal .,', 'url': 'cite.huang2016visual', 'start_index': 469}, {'text': '2016', 'url': 'cite.huang2016visual', 'start_index': 483}], 'page_number': 7, 'parent_id': '915c956b56eac6aaf7eaf34e617bca39', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'ListItem', 'element_id': '81a291d0ce51b079ecbb44df8d1e05ef', 'text': 'Divter (Sun et al., 2021): Divter is a state-of-the-art conversational agent developed for multimodal dialogue contexts. It introduces a customized transformer structure for gener- ating multimodal responses. Divter’s methodology includes pretraining on a vast corpus of text-only dialogues and text-image pairs, followed by fine-tuning on a selected set of multimodal response data. The MMDialog dataset regards Divter’s method as the baseline.', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Sunetal .,', 'url': 'cite.sun2021multimodal', 'start_index': 10}, {'text': '2021', 'url': 'cite.sun2021multimodal', 'start_index': 22}], 'page_number': 7, 'parent_id': '915c956b56eac6aaf7eaf34e617bca39', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'c71a8464f7e4bbc1905fd28dd0a15e83', 'text': 'Metrics To comprehensively assess the model performance across image, text, and multimodal dimensions, we employ a diverse set of metrics. For evaluating the quality and diversity of generated images, we utilize the Inception Score (IS) (Salimans et al., 2016), and Fr´echet Inception Distance (FID) (Heusel et al., 2017). Textual performance is gauged through metrics such as BLEU (Papineni et al., 2002), Rouge-L (Lin, 2004), METEOR (Banerjee & Lavie, 2005), and Sentence-BERT (S- BERT) (Reimers & Gurevych, 2019) scores.', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Salimansetal .,', 'url': 'cite.salimans2016improved', 'start_index': 238}, {'text': '2016', 'url': 'cite.salimans2016improved', 'start_index': 255}, {'text': 'Heuseletal .,', 'url': 'cite.heusel2017gans', 'start_index': 301}, {'text': '2017', 'url': 'cite.heusel2017gans', 'start_index': 316}, {'text': '( etal ., 2002 ), Rouge - L ( Lin , 2004 ), METEOR ( Banerjee & Lavie , 2005 ), andSentence - BERT ( S', 'url': 'cite.papineni2002bleu', 'start_index': 382}, {'text': 'etal .,', 'url': 'cite.papineni2002bleu', 'start_index': 392}, {'text': '2002', 'url': 'cite.papineni2002bleu', 'start_index': 400}, {'text': 'Lin', 'url': 'cite.lin2004rouge', 'start_index': 416}, {'text': '2004', 'url': 'cite.lin2004rouge', 'start_index': 421}, {'text': 'Banerjee & Lavie', 'url': 'cite.banerjee2005meteor', 'start_index': 436}, {'text': '2005', 'url': 'cite.banerjee2005meteor', 'start_index': 454}, {'text': 'Reimers & Gurevych', 'url': 'cite.reimers2019sentence', 'start_index': 490}, {'text': '2019', 'url': 'cite.reimers2019sentence', 'start_index': 510}], 'page_number': 7, 'parent_id': '915c956b56eac6aaf7eaf34e617bca39', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '9c2f2df2e3a24c942f517ee6f3e77608', 'text': 'From the multimodal perspective, we leverage CLIP-based metrics (Rombach et al., 2022b) to assess the similarities between generated content and ground truth. CLIP-I evaluates the similarity between', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Rombachetal .,', 'url': 'cite.rombach2021highresolution', 'start_index': 65}, {'text': '2022b', 'url': 'cite.rombach2021highresolution', 'start_index': 81}], 'page_number': 7, 'parent_id': '915c956b56eac6aaf7eaf34e617bca39', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '76ebab19a4d5f4df604d8b01cef1d378', 'text': '1Given the variations in the valid data within the CC3M dataset, we made adjustments to ensure fair com- parisons. Specifically, we retrained it on our specific CC3M data, following the guidelines in their official implementation (https://github.com/kohjingyu/gill).', 'metadata': {'languages': ['eng'], 'page_number': 7, 'parent_id': '915c956b56eac6aaf7eaf34e617bca39', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Footer', 'element_id': '7902699be42c8a8e46fbbb4501726517', 'text': '7', 'metadata': {'languages': ['eng'], 'page_number': 7, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '38c5f45d77014b3ba4e617ee51e2e38f', 'text': 'Table 3: Multimodal Story Generation. VIST Human Evaluation on 5,000 samples comparing MiniGPT-5 with both Two-stage Baseline and GILL, across Language Continuity, Image Quality, and Multimodal Coherence aspects. The results highlight the superiority of MiniGPT-5 in more than half cases.', 'metadata': {'languages': ['eng'], 'page_number': 8, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '5d30640afdac84ac0ea06b85b734d180', 'text': 'Two-Stage Baseline', 'metadata': {'languages': ['eng'], 'page_number': 8, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '104a88ba97ba94cb46347d539be6f60e', 'text': 'GILL (Koh et al., 2023)', 'metadata': {'languages': ['eng'], 'page_number': 8, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '5e2c614c23f02239bc03c6c04fcb6819', 'text': 'Model', 'metadata': {'languages': ['eng'], 'page_number': 8, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '2659c5fab8f0d32d0ba69a75712f13b0', 'text': 'MiniGPT-5 Baseline', 'metadata': {'languages': ['eng'], 'page_number': 8, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '127f9c9b8aab555837e0d328bb6f8687', 'text': 'Tie MiniGPT-5 Baseline', 'metadata': {'languages': ['eng'], 'page_number': 8, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'a66eab2f9c529bfe2f3adcfd5ec310d6', 'text': 'Tie', 'metadata': {'languages': ['eng'], 'page_number': 8, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '2fcf6eece31ce7e248840647e1ba1c8e', 'text': 'Language Continuity (%) Image Quality (%) Multimodal Coherence (%)', 'metadata': {'languages': ['eng'], 'page_number': 8, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '9d1b710a841983942fff7c968fbfab71', 'text': '55.22 52.43 56.90', 'metadata': {'languages': ['eng'], 'page_number': 8, 'parent_id': '2fcf6eece31ce7e248840647e1ba1c8e', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '51742d70ffff7360b292faa76162541b', 'text': '34.89 37.79 28.88', 'metadata': {'languages': ['eng'], 'page_number': 8, 'parent_id': '2fcf6eece31ce7e248840647e1ba1c8e', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'b8b02eb97691901f2412411ca98435d3', 'text': '9.89 9.78 14.22', 'metadata': {'languages': ['eng'], 'page_number': 8, 'parent_id': '2fcf6eece31ce7e248840647e1ba1c8e', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'fe9405cd417a813634ee96d74b15a151', 'text': '54.18 54.25 55.32', 'metadata': {'languages': ['eng'], 'page_number': 8, 'parent_id': '2fcf6eece31ce7e248840647e1ba1c8e', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '404eddc677cf23311a782fa38f0ef6d3', 'text': '35.31 35.41 30.34', 'metadata': {'languages': ['eng'], 'page_number': 8, 'parent_id': '2fcf6eece31ce7e248840647e1ba1c8e', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'bef9f8cdab465d57655b618909a95da0', 'text': '10.51 10.34 14.33', 'metadata': {'languages': ['eng'], 'page_number': 8, 'parent_id': '2fcf6eece31ce7e248840647e1ba1c8e', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'e24501686c28d2bd1c1529885a7fc40b', 'text': 'generated and ground-truth image features. To address potential misalignments in the multimodal generation, such as when the ground truth is text-only, but the output is multimodal, we utilize MM-Relevance (Feng et al., 2022). This metric calculates the F1 score based on CLIP similarities, providing a nuanced evaluation of multimodal coherence.', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Fengetal .,', 'url': 'cite.feng2022mmdialog', 'start_index': 207}, {'text': '2022', 'url': 'cite.feng2022mmdialog', 'start_index': 220}], 'page_number': 8, 'parent_id': '2fcf6eece31ce7e248840647e1ba1c8e', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'b040e457325627e770282970439fcfa0', 'text': 'Recognizing that the generated multimodal output might be meaningful yet differ from the ground truth, we also incorporate human evaluation to assess the model’s performance. We examine the model’s effectiveness from three perspectives: (1) Language Continuity: assessing if the produced text aligns seamlessly with the provided context; (2) Image Quality: evaluating the clarity and rel- evance of the generated image; and (3) Multimodal Coherence: determining if the combined text- image output is consistent with the initial context.', 'metadata': {'languages': ['eng'], 'page_number': 8, 'parent_id': '2fcf6eece31ce7e248840647e1ba1c8e', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'e8bb2c963827ca5b0e8880de55186354', 'text': '4.2 MAIN RESULTS', 'metadata': {'languages': ['eng'], 'page_number': 8, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '068405df19ee4c39230a793d52bbeef2', 'text': 'In this subsection, we present the performance of different models on the VIST (Huang et al., 2016) and MMDialg (Feng et al., 2022) datasets. Our evaluations span all vision, language, and multi- modality domains to showcase the versatility and robustness of the proposed models.', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Huangetal .,', 'url': 'cite.huang2016visual', 'start_index': 80}, {'text': '2016', 'url': 'cite.huang2016visual', 'start_index': 94}, {'text': 'Fengetal .,', 'url': 'cite.feng2022mmdialog', 'start_index': 113}, {'text': '2022', 'url': 'cite.feng2022mmdialog', 'start_index': 126}], 'page_number': 8, 'parent_id': 'e8bb2c963827ca5b0e8880de55186354', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '194efb55089f1417c59949166ffca3f0', 'text': 'Unimodal Generation with Multimodal Input To evaluate the model performance on image gen- eration and text generation, we systematically provide models with prior history context and subse- quently assess the generated images and narrations at each following step. Tables 1 and 2 outline the results of these experiments on the VIST validation set, showing the performance in both image and language metrics, respectively. The findings demonstrate that MiniGPT-5 can generate coher- ent, high-quality images utilizing long-horizontal multimodal input prompts across all data, without compromising the original model’s ability for multimodal comprehension, indicating the efficacy of our model in diverse settings.', 'metadata': {'languages': ['eng'], 'links': [{'text': '5cangeneratecoher', 'url': 'table.caption.3', 'start_index': 460}, {'text': ',', 'url': 'table.caption.3', 'start_index': 573}], 'page_number': 8, 'parent_id': 'e8bb2c963827ca5b0e8880de55186354', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '4438578f8fa460d8662eb992979daece', 'text': 'Multimodal Generation with Multimodal Input To assess the quality of multimodal generation, we test both our model and the baselines on the VIST validation set by human evaluation. Given a preceding multimodal sequence, models are tasked with producing the subsequent scenario for each task. We select a random sample of 5,000 sequences, with each requiring evaluation by two workers. These evaluators are tasked with determining the superior multimodal output based on three criteria: Language Continuity, Image Quality, and Multimodal Coherence. This assessment is facilitated using Amazon Mechanical Turk (Crowston, 2012), with a representative example (Fig. 4) provided in the Appendix. As depicted in Table 3, our model, MiniGPT-5, is found to generate more fitting text narrations in around 55% of instances, deliver superior image quality in around 53% of cases, and produce more coherent multimodal outputs in around 56% of the scenarios. This data distinctly showcases its enhanced multimodal generation capabilities compared to the two-stage baseline, which must generate intermediate image captions first.', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Crowston', 'url': 'cite.crowston2012amazon', 'start_index': 609}, {'text': '2012', 'url': 'cite.crowston2012amazon', 'start_index': 619}, {'text': '4', 'url': 'figure.caption.11', 'start_index': 662}, {'text': ',', 'url': 'table.caption.4', 'start_index': 713}], 'page_number': 8, 'parent_id': 'e8bb2c963827ca5b0e8880de55186354', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '0f6f49e559c0664eb58c1cbf28043c0a', 'text': 'Multimodal Dialog Generation on MMDialog We conduct an evaluation of our method on the MMDialog dataset to determine the effectiveness of generating precise and appropriate multimodal information in multi-turn conversational scenarios. The model is required to generate either uni- modal or multimodal responses based on the previous turns during the conversations. Our results, as presented in Table 4, demonstrate that MiniGPT-5 outperforms the baseline model Divter in terms of generating more accurate textual responses. While the image qualities of the generated responses are similar, MiniGPT-5 excels in MM-Relevance compared to the baselines. This indicates that our', 'metadata': {'languages': ['eng'], 'links': [{'text': ',', 'url': 'table.caption.5', 'start_index': 402}], 'page_number': 8, 'parent_id': 'e8bb2c963827ca5b0e8880de55186354', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Footer', 'element_id': '2c624232cdd221771294dfbb310aca00', 'text': '8', 'metadata': {'languages': ['eng'], 'page_number': 8, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'e505ff8b668df5d73810c52ff5a7cc1d', 'text': 'Table 4: Multimodal generation results on MMDialog test set. In order to compare with their base- line, we use the same metrics reported in MMDialog (Feng et al., 2022).', 'metadata': {'languages': ['eng'], 'page_number': 9, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '5e2c614c23f02239bc03c6c04fcb6819', 'text': 'Model', 'metadata': {'languages': ['eng'], 'page_number': 9, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '15d058fd08ebc2b2a0368cf49b714c54', 'text': 'IS (↑) BLEU-1 (↑) BLEU-2 (↑) Rouge-L (↑) MM-Relevance (↑)', 'metadata': {'languages': ['eng'], 'page_number': 9, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '40415151e39a873053299d2f7977be18', 'text': 'Divter (Sun et al., 2021) GILL (Koh et al., 2023) MiniGPT-5', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Sunetal .,', 'url': 'cite.sun2021multimodal', 'start_index': 8}, {'text': '2021', 'url': 'cite.sun2021multimodal', 'start_index': 20}, {'text': 'Kohetal .,', 'url': 'cite.koh2023generating', 'start_index': 32}, {'text': '2023', 'url': 'cite.koh2023generating', 'start_index': 44}], 'page_number': 9, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'f447adeb5c93c8fb71b55765e0421488', 'text': '20.53 23.78 20.23', 'metadata': {'languages': ['eng'], 'page_number': 9, 'parent_id': '40415151e39a873053299d2f7977be18', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'e14a0874d6532cec14d77cb5da8b29c9', 'text': '0.0944 0.2912 0.3369', 'metadata': {'languages': ['eng'], 'page_number': 9, 'parent_id': '40415151e39a873053299d2f7977be18', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'b675ef180c9fb6769c47d4f3ffc9aea2', 'text': '0.0745 0.1945 0.2323', 'metadata': {'languages': ['eng'], 'page_number': 9, 'parent_id': '40415151e39a873053299d2f7977be18', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '2b2aff58b082cb5e2e080711c77b1155', 'text': '0.1119 0.1207 0.1176', 'metadata': {'languages': ['eng'], 'page_number': 9, 'parent_id': '40415151e39a873053299d2f7977be18', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '1184c286a82be400b67a7f90d0670c29', 'text': '0.62 0.64 0.67', 'metadata': {'languages': ['eng'], 'page_number': 9, 'parent_id': '40415151e39a873053299d2f7977be18', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'b6327a44fb7be4cf05914d301846d6e8', 'text': 'Table 5: Evaluation of different method designs for image generation qualities on the CC3M vali- dation set. The results show that all of our designs can help the model better align with the stable diffusion model in the pertaining stage.', 'metadata': {'languages': ['eng'], 'page_number': 9, 'parent_id': '40415151e39a873053299d2f7977be18', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '5e2c614c23f02239bc03c6c04fcb6819', 'text': 'Model', 'metadata': {'languages': ['eng'], 'page_number': 9, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'da310f3db024f5d0893f5bfee4a89d71', 'text': 'CLIP-I (↑) CLIP-T (↑)', 'metadata': {'languages': ['eng'], 'page_number': 9, 'parent_id': '5e2c614c23f02239bc03c6c04fcb6819', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '1c014e95a75860c7f8724d8a2793f18c', 'text': 'IS (↑)', 'metadata': {'languages': ['eng'], 'page_number': 9, 'parent_id': '5e2c614c23f02239bc03c6c04fcb6819', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '0d6339d2b85b7d5ad6801154a96ace83', 'text': 'FID (↓)', 'metadata': {'languages': ['eng'], 'page_number': 9, 'parent_id': '5e2c614c23f02239bc03c6c04fcb6819', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'f1641b46c312d47a5f00322db1442dd0', 'text': 'MiniGPT-5 MiniGPT-5 (w/o CFG) MiniGPT-5 (w/o LCAP ) MiniGPT-5 (w/o LLDM )', 'metadata': {'languages': ['eng'], 'page_number': 9, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '687132481f383775ae290cad7a5b7b0a', 'text': '0.61 0.60 0.54 0.58', 'metadata': {'languages': ['eng'], 'page_number': 9, 'parent_id': 'f1641b46c312d47a5f00322db1442dd0', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '2f9623c1f0503cf097a736425daec348', 'text': '0.22 0.22 0.16 0.20', 'metadata': {'languages': ['eng'], 'page_number': 9, 'parent_id': 'f1641b46c312d47a5f00322db1442dd0', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'be91ecadb645d3767fee6d34c4aaf9f7', 'text': '28.09 23.41 21.27 24.79', 'metadata': {'languages': ['eng'], 'page_number': 9, 'parent_id': 'f1641b46c312d47a5f00322db1442dd0', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '9969ed244719c80ac9fa1ec163aedc0d', 'text': '31.47 33.73 40.24 34.65', 'metadata': {'languages': ['eng'], 'page_number': 9, 'parent_id': 'f1641b46c312d47a5f00322db1442dd0', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '205ccdb5f3f986dea0cc776aaa1cb8c1', 'text': 'model can better learn how to position image generation and produce highly coherent multimodal responses appropriately.', 'metadata': {'languages': ['eng'], 'page_number': 9, 'parent_id': 'f1641b46c312d47a5f00322db1442dd0', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'f0cb7c6948d35f108f4ecd57926a2b8d', 'text': '4.3 ABLATION STUDIES', 'metadata': {'languages': ['eng'], 'page_number': 9, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '0414c3857473d38e2b58ce8d987b7916', 'text': 'To further evaluate the effectiveness of our design, we conducted several ablation studies, and more ablation studies can be found in Appendix C.', 'metadata': {'languages': ['eng'], 'links': [{'text': ', weconductedseveralablationstudies , ablationstudiescanbefoundinAppendixC', 'url': 'appendix.C', 'start_index': 51}], 'page_number': 9, 'parent_id': 'f0cb7c6948d35f108f4ecd57926a2b8d', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'cd3e48556087518468ed130ee936e853', 'text': 'Evaluation of Classifier-Free Guidance (CFG) To assess the effectiveness of the CFG strategy, we trained our model without CFG dropoff. During inference, the model utilized the original CFG denoising process, which utilized the empty caption feature from Stable Diffusion’s text encoder as negative prompt features. The results in Table 5 demonstrate that all metrics are worse without CFG, indicating that the CFG training strategy improves the image generation quality.', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Duringinference', 'url': 'table.caption.7', 'start_index': 135}], 'page_number': 9, 'parent_id': 'f0cb7c6948d35f108f4ecd57926a2b8d', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '86202d2a138f6026702b279967d5db3a', 'text': 'Evaluation of Different Loss Guidance As described in Sec. 3.3, we introduced an auxiliary loss, denoted as LCAP for CC3M training. To assess the impact of this loss and determine if the single caption loss alone can generate high-quality images like GILL, we trained our model without the caption loss LCAP (alignment between the mapped generative voken features and the caption fea- tures from stable diffusion text encoder) and the conditional latent diffusion loss LLDM (alignment between the mapped generative voken features and conditional features for latent diffusion process of ground truth images) separately. The results, as shown in Table 5, indicate that the caption loss significantly aids in generating better images, and the voken alignment loss further enhances coher- ence and image quality performance.', 'metadata': {'languages': ['eng'], 'links': [{'text': '3 . 3', 'url': 'subsection.3.3', 'start_index': 59}, {'text': ',', 'url': 'table.caption.7', 'start_index': 652}], 'page_number': 9, 'parent_id': 'f0cb7c6948d35f108f4ecd57926a2b8d', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'e0d71af426e79cf4b3253b1b5c4c298c', 'text': 'Influence of Input Types for Image Generation To assess the impact of various types of input data for image generation, models are tasked with generating the final-step images based on specific prompts and comparing them with ground truth images by CLIP-I metric. All models are fine-tuned on data with full multimodal context and tested on various input types. As indicated in Table 6, the MiniGPT-5 model exhibits exceptional proficiency in producing semantically precise images compared to other models. Furthermore, we observed increased CLIP similarities when more in- formation was provided in the input, signifying the models’ enhanced ability to process diverse, long-horizon multimodal inputs.', 'metadata': {'languages': ['eng'], 'links': [{'text': '- ondatawithfullmultimodalcontextandtestedonvariousinputtypes . AsindicatedinTable6', 'url': 'table.caption.8', 'start_index': 279}], 'page_number': 9, 'parent_id': 'f0cb7c6948d35f108f4ecd57926a2b8d', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'c832276247cfc971d7c8970559ef0dd7', 'text': 'Instead of multimodal input, we also test single text-to-image generation qualities on the CC3M validation set, as displayed in Table 7. The results indicate that although our model can have better generation on multi-turn multimodal scenarios, Stable Diffusion 2 achieves the best outcomes across', 'metadata': {'languages': ['eng'], 'links': [{'text': '.', 'url': 'table.caption.9', 'start_index': 135}], 'page_number': 9, 'parent_id': 'f0cb7c6948d35f108f4ecd57926a2b8d', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '8804f95a76096f2c5da86dd4be74cb86', 'text': 'Text-to-Image Generation Qualities on CC3M', 'metadata': {'languages': ['eng'], 'page_number': 9, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Footer', 'element_id': '19581e27de7ced00ff1ce50b2047e7a5', 'text': '9', 'metadata': {'languages': ['eng'], 'page_number': 9, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '1f24392117d47c9f7ac1eba65b8aab07', 'text': 'SD 2', 'metadata': {'languages': ['eng'], 'page_number': 10, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '1f5c3e14ece5c0d30023b55e0876f074', 'text': 'VSIT -- Image Generation', 'metadata': {'languages': ['eng'], 'page_number': 10, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '253489fe5558250ef026f513831b92b3', 'text': 'VSIT -- Multimodal Generation', 'metadata': {'languages': ['eng'], 'page_number': 10, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '2ddf9cf9d7d88fde96b0bb3bd01fb02f', 'text': 'A Maya example,couple comingsoon to 8th-century king andwife, lady fromTikal, dancing.', 'metadata': {'languages': ['eng'], 'page_number': 10, 'parent_id': '253489fe5558250ef026f513831b92b3', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '38de5d67a933ee26518726ceac54ee86', 'text': 'I bought a bookabout the history ofthe museumGILL', 'metadata': {'languages': ['eng'], 'page_number': 10, 'parent_id': '253489fe5558250ef026f513831b92b3', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '3a04e3f9db9c794d687a5b3194aadc07', 'text': \"MiniGPT-5Two-StageIt's a great place tospend some time in.\", 'metadata': {'languages': ['eng'], 'page_number': 10, 'parent_id': '253489fe5558250ef026f513831b92b3', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '3d4173e8fd9c0d5fe9c14e72950753a0', 'text': 'I went to thenatural historymuseum today.their evolution displaywas interesting.They had manyinteresting things ondisplay.', 'metadata': {'languages': ['eng'], 'page_number': 10, 'parent_id': '253489fe5558250ef026f513831b92b3', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '3e6ceff311428e8167efd1484d99da11', 'text': 'first, we wentto the park.', 'metadata': {'languages': ['eng'], 'page_number': 10, 'parent_id': '253489fe5558250ef026f513831b92b3', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '4ecf72da83b5862df91a8d33536dec57', 'text': 'MiniGPT-5GT', 'metadata': {'languages': ['eng'], 'page_number': 10, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '4ecf72da83b5862df91a8d33536dec57', 'text': 'MiniGPT-5GT', 'metadata': {'languages': ['eng'], 'page_number': 10, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '7942d4a2b357fd1fce179c4da4b686a3', 'text': 'MMDialog -- Multimodal Dialog Generation', 'metadata': {'languages': ['eng'], 'page_number': 10, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '7cf98897f87d2463a64df0e9c0f423a3', 'text': \"ID of perfectthough art:complementarity,complicity,simplicity, security.No, it's not a loan. It was foundin the tomb of an 8th centuryMaya king and his wife at Tika!Loan, privatecollection. Addingcolor to gallery!Lovely depiction oftextiles, gestures.\", 'metadata': {'languages': ['eng'], 'page_number': 10, 'parent_id': '7942d4a2b357fd1fce179c4da4b686a3', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '7d0fe69f90650c61cc3587767ae1d8cd', 'text': 'They also have a giftshop.', 'metadata': {'languages': ['eng'], 'page_number': 10, 'parent_id': '7942d4a2b357fd1fce179c4da4b686a3', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '89c56c9bfbaffbeec44972dfc9a702ea', 'text': 'GILL', 'metadata': {'languages': ['eng'], 'page_number': 10, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '9bdbe6c8c1f0b9ce9f23c7b7312e6789', 'text': 'GILLYes, from a loan.', 'metadata': {'languages': ['eng'], 'page_number': 10, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'c7bc7ca4081e6e24c052ec89d69017d5', 'text': 'How gracefullcoming? From aloan?', 'metadata': {'languages': ['eng'], 'page_number': 10, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'cd749ebefd8c12ef24e30523edf603be', 'text': 'They had an area forcryptozoology.', 'metadata': {'languages': ['eng'], 'page_number': 10, 'parent_id': 'c7bc7ca4081e6e24c052ec89d69017d5', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'f392c4990f5c3ed9bc9cf7af9a7a7317', 'text': 'My favorite was this realcovered wagon from200 years ago.GT', 'metadata': {'languages': ['eng'], 'page_number': 10, 'parent_id': 'c7bc7ca4081e6e24c052ec89d69017d5', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'f8ed053d2a08ff2217c752dcfba18302', 'text': 'Two-stage', 'metadata': {'languages': ['eng'], 'page_number': 10, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'fc0eca7bfb8b78d171b34d5caab63362', 'text': 'then, we wentswimmingi looked cooolin my glassesat the poollater, we wentto visit mommywe playeddress up.', 'metadata': {'languages': ['eng'], 'page_number': 10, 'parent_id': 'f8ed053d2a08ff2217c752dcfba18302', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'fb4e59d77bb93fb0baa8eb788df9ab98', 'text': 'Figure 3: Qualitative examples from MiniGPT-5 and baselines on the VIST and MMDialog datasets. The orange blocks indicate the input prompts, while the green blocks include model outputs. The comparisons show that MiniGPT-5 can produce coherent and high-quality multimodal output. We would like to emphasize that MiniGPT-5 does not use any caption data during fine-tuning on VIST and MMDialog, which obeys to our description-free settings. More qualitative examples can be found in the Appendix D.', 'metadata': {'languages': ['eng'], 'page_number': 10, 'parent_id': 'f8ed053d2a08ff2217c752dcfba18302', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'c6661b93bbeed48820a2edc9c2c08797', 'text': 'all metrics for pure text-to-image generation. Since our model attempts to align with the pretrained text encoder of Stable Diffusion 2 in this stage, there is a slight gap in performance due to the limitation of data amount. Compared with the observations on the VIST dataset, we can conclude that MiniGPT-5 is better at extracting features from long-horizontal multimodal information instead', 'metadata': {'languages': ['eng'], 'page_number': 10, 'parent_id': 'f8ed053d2a08ff2217c752dcfba18302', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Footer', 'element_id': '4a44dc15364204a80fe80e9039455cc1', 'text': '10', 'metadata': {'languages': ['eng'], 'page_number': 10, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '46fda47e9a5977079c8d45705003471d', 'text': 'Table 6: Influence of prompts for image generation on CLIP-I metrics on VIST. We establish four distinct conditions for the final-step image generation: ‘No Context’ (solely the last step’s narration), ‘Text Context’ (inclusive of historical textual narrations), ‘Image Context’ (inclusive of historical images), and ‘Image-Text Context’ (inclusive of both historical images and narrations). From the results, MiniGPT-5 can generate more coherent images.', 'metadata': {'languages': ['eng'], 'page_number': 11, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '5e2c614c23f02239bc03c6c04fcb6819', 'text': 'Model', 'metadata': {'languages': ['eng'], 'page_number': 11, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '8a4087584c75799357ec7db2e4a4e096', 'text': 'No Context Text Context', 'metadata': {'languages': ['eng'], 'page_number': 11, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'df0ef4835a6786eb8aa0144a786041f3', 'text': 'Image Context', 'metadata': {'languages': ['eng'], 'page_number': 11, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '60aaae492a7d458cd227f51e82932d66', 'text': 'Image-Text Context', 'metadata': {'languages': ['eng'], 'page_number': 11, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '3a6e05ee6e5027f1c02c483ce0ec60ac', 'text': 'SD 2.1 (Rombach et al., 2022b) Fine-tuned SD 2.1 Two-stage Baseline GILL (Koh et al., 2023) MiniGPT-5 (Prefix Tuning) MiniGPT-5 (LoRA)', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Rombachetal .,', 'url': 'cite.rombach2021highresolution', 'start_index': 8}, {'text': '2022b', 'url': 'cite.rombach2021highresolution', 'start_index': 24}, {'text': 'Kohetal .,', 'url': 'cite.koh2023generating', 'start_index': 74}, {'text': '2023', 'url': 'cite.koh2023generating', 'start_index': 86}], 'page_number': 11, 'parent_id': '60aaae492a7d458cd227f51e82932d66', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '10b569245fef94493e6ad0f2900c0e76', 'text': '0.57 0.59 0.54 0.56 0.60 0.61', 'metadata': {'languages': ['eng'], 'page_number': 11, 'parent_id': '60aaae492a7d458cd227f51e82932d66', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '30d8446542856520fcb70defa99eb461', 'text': '0.59 0.61 0.56 0.59 0.63 0.64', 'metadata': {'languages': ['eng'], 'page_number': 11, 'parent_id': '60aaae492a7d458cd227f51e82932d66', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'ListItem', 'element_id': '270fbac44090c98e5fd1a493646b53cf', 'text': '- 0.57 0.60 0.68 0.69', 'metadata': {'languages': ['eng'], 'page_number': 11, 'parent_id': '60aaae492a7d458cd227f51e82932d66', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'ListItem', 'element_id': '288ca688585a4a08f0e4260686a70f84', 'text': '- 0.58 0.60 0.70 0.70', 'metadata': {'languages': ['eng'], 'page_number': 11, 'parent_id': '60aaae492a7d458cd227f51e82932d66', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '73c9ae7200f159a17e2f10ea1f9930c3', 'text': 'Table 7: Generation Qualities on CC3M and VIST. We find that MiniGPT-5 is better at extracting features from long-horizontal multimodal information than single text input.', 'metadata': {'languages': ['eng'], 'page_number': 11, 'parent_id': '60aaae492a7d458cd227f51e82932d66', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'e0ba593945c2591d506c3f93ea38b2bf', 'text': 'CC3M', 'metadata': {'languages': ['eng'], 'page_number': 11, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'a211f1c28c7b52099bd088d491e34b2c', 'text': 'VIST', 'metadata': {'languages': ['eng'], 'page_number': 11, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '5e2c614c23f02239bc03c6c04fcb6819', 'text': 'Model', 'metadata': {'languages': ['eng'], 'page_number': 11, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'ff6f0ce218ddf400a85e5e6aca5f7789', 'text': 'CLIP-I (↑)', 'metadata': {'languages': ['eng'], 'page_number': 11, 'parent_id': '5e2c614c23f02239bc03c6c04fcb6819', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '19a7d8591de2c6a4a225c2da0815c997', 'text': 'FID (↓) CLIP-I (↑)', 'metadata': {'languages': ['eng'], 'page_number': 11, 'parent_id': '5e2c614c23f02239bc03c6c04fcb6819', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '0d6339d2b85b7d5ad6801154a96ace83', 'text': 'FID (↓)', 'metadata': {'languages': ['eng'], 'page_number': 11, 'parent_id': '5e2c614c23f02239bc03c6c04fcb6819', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '279f18ceb06bd30755b7e31e799c313c', 'text': 'Stable Diffusion 2.1 (Rombach et al., 2022b) GILL (Koh et al., 2023) MiniGPT-5', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Rombachetal .,', 'url': 'cite.rombach2021highresolution', 'start_index': 22}, {'text': '2022b', 'url': 'cite.rombach2021highresolution', 'start_index': 38}, {'text': 'Kohetal .,', 'url': 'cite.koh2023generating', 'start_index': 51}, {'text': '2023', 'url': 'cite.koh2023generating', 'start_index': 63}], 'page_number': 11, 'parent_id': '5e2c614c23f02239bc03c6c04fcb6819', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'd2c0605f6015d2c402876c44472507dd', 'text': '0.64 0.57 0.61', 'metadata': {'languages': ['eng'], 'page_number': 11, 'parent_id': '5e2c614c23f02239bc03c6c04fcb6819', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '1b263ff7c1392e2fc4b07f8a5685d4c5', 'text': '26.39 36.85 31.47', 'metadata': {'languages': ['eng'], 'page_number': 11, 'parent_id': '5e2c614c23f02239bc03c6c04fcb6819', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '5185ecfaaa61aa60530d303e4b78ffc6', 'text': '0.59 0.60 0.66', 'metadata': {'languages': ['eng'], 'page_number': 11, 'parent_id': '5e2c614c23f02239bc03c6c04fcb6819', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '76018e1f0ff1bf81ee6b83f1d634872d', 'text': '393.49 381.88 366.62', 'metadata': {'languages': ['eng'], 'page_number': 11, 'parent_id': '5e2c614c23f02239bc03c6c04fcb6819', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '05807595aae710a7ba60263e3fe8b302', 'text': 'of single text input. This indicates potential future directions on efficiently aligning LLMs with generative models. On the other hand, our model outperforms another state-of-the-art multimodal generation model, GILL, on all metrics, further validating the effectiveness of our design.', 'metadata': {'languages': ['eng'], 'page_number': 11, 'parent_id': '5e2c614c23f02239bc03c6c04fcb6819', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'ea96249b7d70bb30292a9876e3569748', 'text': '5 CONCLUSION', 'metadata': {'languages': ['eng'], 'page_number': 11, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '1c630214ea4defc172eb5c8f55001edc', 'text': 'In this paper, we introduce MiniGPT-5, designed to augment the capabilities of LLMs for multi- modal generation by aligning the LLM with a pretrained text-to-image generation model. Our ap- proach demonstrates substantial improvements, as evidenced by comprehensive experiments. There are still some limitations of MiniGPT-5. For example, we still find the object texture hard to main- tain in the new generation, and the generated image quality still has space to improve. Through this work, we aspire to set a new benchmark for multimodal generative models, opening doors to applications previously deemed challenging due to the disjointed nature of existing image and text synthesis paradigms.', 'metadata': {'languages': ['eng'], 'page_number': 11, 'parent_id': 'ea96249b7d70bb30292a9876e3569748', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '704d8a18e343aa05fdc15cdefa27e6ac', 'text': 'REFERENCES', 'metadata': {'languages': ['eng'], 'page_number': 11, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'c277aa97a9f5d71e03ab7f5a3769db22', 'text': 'Emanuele Aiello, Lili Yu, Yixin Nie, Armen Aghajanyan, and Barlas Oguz. Jointly training large', 'metadata': {'languages': ['eng'], 'page_number': 11, 'parent_id': '704d8a18e343aa05fdc15cdefa27e6ac', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '78210efff9dff473cce1544fabca3091', 'text': 'autoregressive multimodal models. arXiv preprint arXiv:2309.15564, 2023.', 'metadata': {'languages': ['eng'], 'page_number': 11, 'parent_id': '704d8a18e343aa05fdc15cdefa27e6ac', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '84690906f797018e8209dfd604fc2176', 'text': 'Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds, et al. Flamingo: a visual language model for few-shot learning. Advances in Neural Information Processing Systems, 35:23716– 23736, 2022.', 'metadata': {'languages': ['eng'], 'page_number': 11, 'parent_id': '704d8a18e343aa05fdc15cdefa27e6ac', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'e08d2097acd914978f06dbfc434f80b2', 'text': 'Satanjeev Banerjee and Alon Lavie. Meteor: An automatic metric for mt evaluation with improved correlation with human judgments. In Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization, pp. 65–72, 2005.', 'metadata': {'languages': ['eng'], 'page_number': 11, 'parent_id': '704d8a18e343aa05fdc15cdefa27e6ac', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '843ecb5541c1821813f2d990d0ecb36d', 'text': 'Huiwen Chang, Han Zhang, Jarred Barber, AJ Maschinot, Jose Lezama, Lu Jiang, Ming-Hsuan Yang, Kevin Murphy, William T Freeman, Michael Rubinstein, et al. Muse: Text-to-image gen- eration via masked generative transformers. arXiv preprint arXiv:2301.00704, 2023.', 'metadata': {'languages': ['eng'], 'page_number': 11, 'parent_id': '704d8a18e343aa05fdc15cdefa27e6ac', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Footer', 'element_id': '4fc82b26aecb47d2868c4efbe3581732', 'text': '11', 'metadata': {'languages': ['eng'], 'page_number': 11, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '5c4151736a99a37d1a5f1ffee0775443', 'text': 'Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality, March 2023.', 'metadata': {'languages': ['eng'], 'page_number': 12, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'cecc6b97e59bf850fe1061c4bfd30169', 'text': 'Kevin Crowston. Amazon mechanical turk: A research tool for organizations and information sys- In Shaping the Future of ICT Research. Methods and Approaches: IFIP WG tems scholars. 8.2, Working Conference, Tampa, FL, USA, December 13-14, 2012. Proceedings, pp. 210–221. Springer, 2012.', 'metadata': {'languages': ['eng'], 'page_number': 12, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'c0053291f9670e60fd478206a8777dca', 'text': 'Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Junqi Zhao, Weisheng Wang, Boyang Li, Pascale Fung, and Steven Hoi. Instructblip: Towards general-purpose vision-language models with instruction tuning, 2023.', 'metadata': {'languages': ['eng'], 'page_number': 12, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'd419ea39e53019b4d7ff2cb140cc76d2', 'text': 'Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. Qlora: Efficient finetuning', 'metadata': {'languages': ['eng'], 'page_number': 12, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '05304b3145339bac9ffb5a3aa1a6f2f7', 'text': 'of quantized llms. arXiv preprint arXiv:2305.14314, 2023.', 'metadata': {'languages': ['eng'], 'page_number': 12, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '9770fc92f1e291e3aabc8416286c1f0f', 'text': 'Prafulla Dhariwal and Alexander Nichol. Diffusion models beat gans on image synthesis. Advances', 'metadata': {'languages': ['eng'], 'page_number': 12, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '437ee4d0ab2fb28f5d289bb871c95ef5', 'text': 'in neural information processing systems, 34:8780–8794, 2021.', 'metadata': {'languages': ['eng'], 'page_number': 12, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'fecfe9130958f6fc3ed9494c40a39f6c', 'text': 'Jiazhan Feng, Qingfeng Sun, Can Xu, Pu Zhao, Yaming Yang, Chongyang Tao, Dongyan Zhao, and Qingwei Lin. Mmdialog: A large-scale multi-turn dialogue dataset towards multi-modal open-domain conversation. arXiv preprint arXiv:2211.05719, 2022.', 'metadata': {'languages': ['eng'], 'page_number': 12, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '9e5a34b67f04bc404143fa9d68f11208', 'text': 'Yuying Ge, Yixiao Ge, Ziyun Zeng, Xintao Wang, and Ying Shan. Planting a seed of vision in large', 'metadata': {'languages': ['eng'], 'page_number': 12, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'd71055b03d28fcdb86cd182918da97fe', 'text': 'language model. arXiv preprint arXiv:2307.08041, 2023.', 'metadata': {'languages': ['eng'], 'page_number': 12, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '0a9aed00721192b42865b80e33e55e42', 'text': 'Jing Gu, Yilin Wang, Nanxuan Zhao, Tsu-Jui Fu, Wei Xiong, Qing Liu, Zhifei Zhang, He Zhang, Jianming Zhang, HyunJoon Jung, and Xin Eric Wang. Photoswap: Personalized subject swapping in images, 2023.', 'metadata': {'languages': ['eng'], 'page_number': 12, 'parent_id': 'd71055b03d28fcdb86cd182918da97fe', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'acf85de82023256f64525c6a1d5bf521', 'text': 'Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilibrium. Advances in neural information processing systems, 30, 2017.', 'metadata': {'languages': ['eng'], 'page_number': 12, 'parent_id': 'd71055b03d28fcdb86cd182918da97fe', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'c6d7a678875c4171834dfb47cbe2b3c5', 'text': 'Jonathan Ho and Tim Salimans.', 'metadata': {'languages': ['eng'], 'page_number': 12, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '8837592dbbd8865379515edc02688a99', 'text': 'Classifier-free diffusion guidance.', 'metadata': {'languages': ['eng'], 'page_number': 12, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'd8c1c5a4c7da832c74b0f77d5453d20c', 'text': 'arXiv preprint', 'metadata': {'languages': ['eng'], 'page_number': 12, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '5711522c1c3cbad7f05c180cc492aac5', 'text': 'arXiv:2207.12598, 2022.', 'metadata': {'languages': ['eng'], 'page_number': 12, 'parent_id': 'd8c1c5a4c7da832c74b0f77d5453d20c', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'd11603050717c4ebcfe6d175d916c5ff', 'text': 'Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De Laroussilhe, An- drea Gesmundo, Mona Attariyan, and Sylvain Gelly. Parameter-efficient transfer learning for nlp. In International Conference on Machine Learning, pp. 2790–2799. PMLR, 2019.', 'metadata': {'languages': ['eng'], 'page_number': 12, 'parent_id': 'd8c1c5a4c7da832c74b0f77d5453d20c', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'c88069dee3cf213e8bb3ee07de9f7ee4', 'text': 'Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, arXiv preprint', 'metadata': {'languages': ['eng'], 'page_number': 12, 'parent_id': 'd8c1c5a4c7da832c74b0f77d5453d20c', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'b80bc31812cc242154ab759e48f33b9e', 'text': 'and Weizhu Chen. Lora: Low-rank adaptation of large language models. arXiv:2106.09685, 2021.', 'metadata': {'languages': ['eng'], 'page_number': 12, 'parent_id': 'd8c1c5a4c7da832c74b0f77d5453d20c', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'e808d4023b6016ba38078064d981df1f', 'text': 'Ting-Hao K. Huang, Francis Ferraro, Nasrin Mostafazadeh, Ishan Misra, Jacob Devlin, Aishwarya Agrawal, Ross Girshick, Xiaodong He, Pushmeet Kohli, Dhruv Batra, et al. Visual storytelling. In 15th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL 2016), 2016.', 'metadata': {'languages': ['eng'], 'page_number': 12, 'parent_id': 'd8c1c5a4c7da832c74b0f77d5453d20c', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '3b6a19f2899b876a17be5b83b5b1fb13', 'text': 'Diederik P Kingma and Max Welling. Auto-encoding variational bayes.', 'metadata': {'languages': ['eng'], 'page_number': 12, 'parent_id': 'd8c1c5a4c7da832c74b0f77d5453d20c', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'd8c1c5a4c7da832c74b0f77d5453d20c', 'text': 'arXiv preprint', 'metadata': {'languages': ['eng'], 'page_number': 12, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '43c8d8b9d3562917a273d90a23694521', 'text': 'arXiv:1312.6114, 2013.', 'metadata': {'languages': ['eng'], 'page_number': 12, 'parent_id': 'd8c1c5a4c7da832c74b0f77d5453d20c', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'ae6bc396b3152d26b9c8466c3a35e003', 'text': 'Jing Yu Koh, Daniel Fried, and Ruslan Salakhutdinov. Generating images with multimodal language', 'metadata': {'languages': ['eng'], 'page_number': 12, 'parent_id': 'd8c1c5a4c7da832c74b0f77d5453d20c', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'a3f767bfc4c0317be4b61498b5e06282', 'text': 'models. arXiv preprint arXiv:2305.17216, 2023.', 'metadata': {'languages': ['eng'], 'page_number': 12, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '05e0f004dc6ef3aa2519a8c44ce8418c', 'text': 'Bo Li, Yuanhan Zhang, Liangyu Chen, Jinghao Wang, Jingkang Yang, and Ziwei Liu. Otter: A multi-modal model with in-context instruction tuning. arXiv preprint arXiv:2305.03726, 2023a.', 'metadata': {'languages': ['eng'], 'page_number': 12, 'parent_id': 'a3f767bfc4c0317be4b61498b5e06282', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '9b231d876e94a81e97a32226f03d465f', 'text': 'Dongxu Li, Junnan Li, Hung Le, Guangsen Wang, Silvio Savarese, and Steven C.H. Hoi. LAVIS: A one-stop library for language-vision intelligence. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations), pp. 31– 41, Toronto, Canada, July 2023b. Association for Computational Linguistics. URL https: //aclanthology.org/2023.acl-demo.3.', 'metadata': {'languages': ['eng'], 'links': [{'text': '), pp . 31 41 , Toronto , Canada , July2023b . AssociationforComputationalLinguistics . URLhttps', 'url': 'https://aclanthology.org/2023.acl-demo.3', 'start_index': 267}, {'text': '// aclanthology . org / 2023 . acl - demo . 3', 'url': 'https://aclanthology.org/2023.acl-demo.3', 'start_index': 365}], 'page_number': 12, 'parent_id': 'a3f767bfc4c0317be4b61498b5e06282', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Footer', 'element_id': '6b51d431df5d7f141cbececcf79edf3d', 'text': '12', 'metadata': {'languages': ['eng'], 'page_number': 12, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'f3aeae637a20affa1824daef686c5921', 'text': 'Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi. Blip-2: Bootstrapping language- arXiv preprint', 'metadata': {'languages': ['eng'], 'page_number': 13, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'cdf182b8d21931a20bf9efd3650af568', 'text': 'image pre-training with frozen image encoders and large language models. arXiv:2301.12597, 2023c.', 'metadata': {'languages': ['eng'], 'page_number': 13, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'f63fd3e30b750e4a5b6d1c1c2869d00f', 'text': 'Xiang Lisa Li and Percy Liang. Prefix-tuning: Optimizing continuous prompts for generation. arXiv', 'metadata': {'languages': ['eng'], 'page_number': 13, 'parent_id': 'cdf182b8d21931a20bf9efd3650af568', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '1712418d0c8aa28cbed565e9879b4225', 'text': 'preprint arXiv:2101.00190, 2021.', 'metadata': {'languages': ['eng'], 'page_number': 13, 'parent_id': 'cdf182b8d21931a20bf9efd3650af568', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '24545c21db875eda84224c2e65303d69', 'text': 'Chin-Yew Lin. Rouge: A package for automatic evaluation of summaries. In Text summarization', 'metadata': {'languages': ['eng'], 'page_number': 13, 'parent_id': 'cdf182b8d21931a20bf9efd3650af568', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'cca1ea1d9fe8332b25e7ab478dcca369', 'text': 'branches out, pp. 74–81, 2004.', 'metadata': {'languages': ['eng'], 'page_number': 13, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '5156fa171b52686bd1ae6078c8611880', 'text': 'Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, and Mark Chen. Glide: Towards photorealistic image generation and editing with text-guided diffusion models. arXiv preprint arXiv:2112.10741, 2021.', 'metadata': {'languages': ['eng'], 'page_number': 13, 'parent_id': 'cca1ea1d9fe8332b25e7ab478dcca369', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'e729b9c2f95313ec04f7616b35b78371', 'text': 'OpenAI. Gpt-4 technical report, 2023.', 'metadata': {'languages': ['eng'], 'page_number': 13, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '0217348c97ca2b0ef20000920556ba47', 'text': 'Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems, 35: 27730–27744, 2022.', 'metadata': {'languages': ['eng'], 'page_number': 13, 'parent_id': 'e729b9c2f95313ec04f7616b35b78371', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'e26da38961abc4040c565a5f9897a180', 'text': 'Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting on association for computational linguistics, pp. 311–318. Association for Computational Linguistics, 2002.', 'metadata': {'languages': ['eng'], 'page_number': 13, 'parent_id': 'e729b9c2f95313ec04f7616b35b78371', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '6c0738662deb5549b362886233a5db4b', 'text': 'Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever. Zero-shot text-to-image generation. In International Conference on Machine Learning, pp. 8821–8831. PMLR, 2021.', 'metadata': {'languages': ['eng'], 'page_number': 13, 'parent_id': 'e729b9c2f95313ec04f7616b35b78371', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'cbea1fff8b8b0ab42bbde7075635390d', 'text': 'Scott Reed, Zeynep Akata, Xinchen Yan, Lajanugen Logeswaran, Bernt Schiele, and Honglak Lee. Generative adversarial text to image synthesis. In International conference on machine learning, pp. 1060–1069. PMLR, 2016.', 'metadata': {'languages': ['eng'], 'page_number': 13, 'parent_id': 'e729b9c2f95313ec04f7616b35b78371', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'b681472ed3f84b7cd39ac1f33cd9140c', 'text': 'Nils Reimers and Iryna Gurevych. Sentence-bert: Sentence embeddings using siamese bert-', 'metadata': {'languages': ['eng'], 'page_number': 13, 'parent_id': 'e729b9c2f95313ec04f7616b35b78371', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '2b1e3066c13131bf353722899c75ed3d', 'text': 'networks. arXiv preprint arXiv:1908.10084, 2019.', 'metadata': {'languages': ['eng'], 'page_number': 13, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'c1ffcb72b8a6893c1517538d8b4adacd', 'text': 'Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj¨orn Ommer. High- resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF confer- ence on computer vision and pattern recognition, pp. 10684–10695, 2022a.', 'metadata': {'languages': ['eng'], 'page_number': 13, 'parent_id': '2b1e3066c13131bf353722899c75ed3d', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'adada18c39a4137f73cb5aa36264ca56', 'text': 'Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj¨orn Ommer. High-', 'metadata': {'languages': ['eng'], 'page_number': 13, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '366e26eeb6f5396e8d65cb75533ede0d', 'text': 'resolution image synthesis with latent diffusion models. In CVPR, 2022b.', 'metadata': {'languages': ['eng'], 'page_number': 13, 'parent_id': 'adada18c39a4137f73cb5aa36264ca56', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '9bb007434f1d9d8581506139c79e32e6', 'text': 'Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily L Denton, Kamyar Ghasemipour, Raphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans, et al. Photorealistic text-to-image diffusion models with deep language understanding. Advances in Neural Informa- tion Processing Systems, 35:36479–36494, 2022.', 'metadata': {'languages': ['eng'], 'page_number': 13, 'parent_id': 'adada18c39a4137f73cb5aa36264ca56', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '3653fc968f8238c80452231525447ab1', 'text': 'Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved techniques for training gans. Advances in neural information processing systems, 29, 2016.', 'metadata': {'languages': ['eng'], 'page_number': 13, 'parent_id': 'adada18c39a4137f73cb5aa36264ca56', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'c2f1e958f9aafdb9c1a24925072055d1', 'text': 'Piyush Sharma, Nan Ding, Sebastian Goodman, and Radu Soricut. Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 2556–2565, 2018.', 'metadata': {'languages': ['eng'], 'page_number': 13, 'parent_id': 'adada18c39a4137f73cb5aa36264ca56', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'ef13b6eee95f98a517ec58ebfca782e4', 'text': 'Qingfeng Sun, Yujing Wang, Can Xu, Kai Zheng, Yaming Yang, Huang Hu, Fei Xu, Jessica Zhang, Xiubo Geng, and Daxin Jiang. Multimodal dialogue response generation. arXiv preprint arXiv:2110.08515, 2021.', 'metadata': {'languages': ['eng'], 'page_number': 13, 'parent_id': 'adada18c39a4137f73cb5aa36264ca56', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'b3c3a2cce6183cf7c3de5d9bdd707f6d', 'text': 'Quan Sun, Yuxin Fang, Ledell Wu, Xinlong Wang, and Yue Cao. Eva-clip: Improved training', 'metadata': {'languages': ['eng'], 'page_number': 13, 'parent_id': 'adada18c39a4137f73cb5aa36264ca56', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '099adc4ba1a37d2668ad03cd47ee6d5b', 'text': 'techniques for clip at scale. arXiv preprint arXiv:2303.15389, 2023a.', 'metadata': {'languages': ['eng'], 'page_number': 13, 'parent_id': 'adada18c39a4137f73cb5aa36264ca56', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Footer', 'element_id': '3fdba35f04dc8c462986c992bcf87554', 'text': '13', 'metadata': {'languages': ['eng'], 'page_number': 13, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'de5dc25c299b3be8f6253acccc6738d1', 'text': 'Quan Sun, Qiying Yu, Yufeng Cui, Fan Zhang, Xiaosong Zhang, Yueze Wang, Hongcheng Gao, Jingjing Liu, Tiejun Huang, and Xinlong Wang. Generative pretraining in multimodality. 2023b.', 'metadata': {'languages': ['eng'], 'page_number': 14, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'f8889177a86ffbc7300290259c5190fd', 'text': 'Hao Tan and Mohit Bansal. Vokenization: Improving language understanding with contextualized,', 'metadata': {'languages': ['eng'], 'page_number': 14, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'd31eaf4d7761647903bde404773db5ff', 'text': 'visual-grounded supervision. arXiv preprint arXiv:2010.06775, 2020.', 'metadata': {'languages': ['eng'], 'page_number': 14, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'd4a6af662ae72818291ff04648e7a6d0', 'text': 'Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth´ee Lacroix, Baptiste Rozi`ere, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971, 2023.', 'metadata': {'languages': ['eng'], 'page_number': 14, 'parent_id': 'd31eaf4d7761647903bde404773db5ff', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '84224568483b039e934200fe30489bc0', 'text': 'Maria Tsimpoukelli, Jacob L Menick, Serkan Cabi, SM Eslami, Oriol Vinyals, and Felix Hill. Mul- timodal few-shot learning with frozen language models. Advances in Neural Information Pro- cessing Systems, 34:200–212, 2021.', 'metadata': {'languages': ['eng'], 'page_number': 14, 'parent_id': 'd31eaf4d7761647903bde404773db5ff', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '206d306ff335bd9360da2fe1736c39bf', 'text': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural informa- tion processing systems, 30, 2017a.', 'metadata': {'languages': ['eng'], 'page_number': 14, 'parent_id': 'd31eaf4d7761647903bde404773db5ff', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '05c1b75d1030f27af961d5f25622159f', 'text': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural informa- tion processing systems, pp. 5998–6008, 2017b.', 'metadata': {'languages': ['eng'], 'page_number': 14, 'parent_id': 'd31eaf4d7761647903bde404773db5ff', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '492d418a731b3df00ed3ae1ff4c97cc5', 'text': 'Chenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, and Nan Duan. Vi- arXiv preprint', 'metadata': {'languages': ['eng'], 'page_number': 14, 'parent_id': 'd31eaf4d7761647903bde404773db5ff', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'a34633378b3afe733f91b0b59243f720', 'text': 'sual chatgpt: Talking, drawing and editing with visual foundation models. arXiv:2303.04671, 2023a.', 'metadata': {'languages': ['eng'], 'page_number': 14, 'parent_id': 'd31eaf4d7761647903bde404773db5ff', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '492d418a731b3df00ed3ae1ff4c97cc5', 'text': 'Chenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, and Nan Duan. Vi- arXiv preprint', 'metadata': {'languages': ['eng'], 'page_number': 14, 'parent_id': 'd31eaf4d7761647903bde404773db5ff', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'a06e5178358cbffddc783b6a6f191068', 'text': 'sual chatgpt: Talking, drawing and editing with visual foundation models. arXiv:2303.04671, 2023b.', 'metadata': {'languages': ['eng'], 'page_number': 14, 'parent_id': 'd31eaf4d7761647903bde404773db5ff', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'a030e13f3c2c6c8915749a73bc939c54', 'text': 'Shengqiong Wu, Hao Fei, Leigang Qu, Wei Ji, and Tat-Seng Chua. Next-gpt: Any-to-any multi-', 'metadata': {'languages': ['eng'], 'page_number': 14, 'parent_id': 'd31eaf4d7761647903bde404773db5ff', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '2f908ba77b4de4483f76e63e048ac516', 'text': 'modal llm, 2023c.', 'metadata': {'languages': ['eng'], 'page_number': 14, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'e8a6ff4b779d156d49223389391ab068', 'text': 'Jiahui Yu, Yuanzhong Xu, Jing Yu Koh, Thang Luong, Gunjan Baid, Zirui Wang, Vijay Vasudevan, Alexander Ku, Yinfei Yang, Burcu Karagol Ayan, et al. Scaling autoregressive models for content- rich text-to-image generation. arXiv preprint arXiv:2206.10789, 2(3):5, 2022.', 'metadata': {'languages': ['eng'], 'page_number': 14, 'parent_id': '2f908ba77b4de4483f76e63e048ac516', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'd7edba67f49477aaeb1e8b5a214b0eb6', 'text': 'Lili Yu, Bowen Shi, Ramakanth Pasunuru, Benjamin Muller, Olga Golovneva, Tianlu Wang, Arun Babu, Binh Tang, Brian Karrer, Shelly Sheynin, et al. Scaling autoregressive multi-modal models: Pretraining and instruction tuning. arXiv preprint arXiv:2309.02591, 2023.', 'metadata': {'languages': ['eng'], 'page_number': 14, 'parent_id': '2f908ba77b4de4483f76e63e048ac516', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'ef41ff8dd2bddf9c88869b1bb13840f7', 'text': 'Renrui Zhang, Rongyao Fang, Peng Gao, Wei Zhang, Kunchang Li, Jifeng Dai, Yu Qiao, and Hong- sheng Li. Tip-adapter: Training-free clip-adapter for better vision-language modeling. arXiv preprint arXiv:2111.03930, 2021.', 'metadata': {'languages': ['eng'], 'page_number': 14, 'parent_id': '2f908ba77b4de4483f76e63e048ac516', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'a797ced1b68073cb7191ce0f9aab8c8c', 'text': 'Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny. Minigpt-4: En- hancing vision-language understanding with advanced large language models. arXiv preprint arXiv:2304.10592, 2023.', 'metadata': {'languages': ['eng'], 'page_number': 14, 'parent_id': '2f908ba77b4de4483f76e63e048ac516', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Footer', 'element_id': '8527a891e224136950ff32ca212b45bc', 'text': '14', 'metadata': {'languages': ['eng'], 'page_number': 14, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '4f18f0e6cc72b450f8e7371deff559f4', 'text': 'A IMPLEMENTATION DETAILS', 'metadata': {'languages': ['eng'], 'page_number': 15, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '59dbcedae609fb6bdb9dfcf15c3304f3', 'text': 'In the pretraining stage, we introduce additional voken embeddings at both the input and out- put layers of the Vicuna-7B model, while keeping the embeddings of other tokens fixed. These new embeddings – denoted as θvoken input and θvoken output – along with the feature mapper module (θMLP, θenc dec, q) are jointly trained on the CC3M dataset, which consists of single text-image pairs. Training is conducted using the AdamW optimizer over two epochs, with a batch size of 48, amount- ing to over 110,000 steps, and a learning rate of 2 × 10−4.', 'metadata': {'languages': ['eng'], 'page_number': 15, 'parent_id': '4f18f0e6cc72b450f8e7371deff559f4', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '3bdc15130d4d2bc428e9f807f2126f67', 'text': 'In the subsequent fine-tuning stage, we incorporate LoRA modules – denoted as θLoRA – into Vicuna for the generation of both tokens and vokens. We keep the MLP model θMLP and decoder query q fixed. The model is then fine-tuned on interleaved vision-and-language datasets, like VIST and MMDialog. The trainable parameters for this stage are θ = {θvoken input, θvoken output, θLoRA, θenc dec}. Training is carried out using the AdamW optimizer over four epochs, with a batch size of 32 and a learning rate of 2 × 10−5. Trainable parameters are nearly 6.6 million, and all training can be completed on a server equipped with 4 A6000 GPUs.', 'metadata': {'languages': ['eng'], 'page_number': 15, 'parent_id': '4f18f0e6cc72b450f8e7371deff559f4', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '062e0c05395c182757a6f48fec0c8822', 'text': 'B EXPERIMENTAL SETTINGS', 'metadata': {'languages': ['eng'], 'page_number': 15, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '5a93b3819997804dfff3393e122783f8', 'text': 'B.1 DATASETS', 'metadata': {'languages': ['eng'], 'page_number': 15, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '04f226ce045a5958a1781384bf99865c', 'text': 'CC3M (Sharma et al., 2018): Conceptual Captions (CC3M) dataset represents a remarkable col- lection of high-quality image captions, amassing approximately 3.3 million pairs of text and images from the internet. The CC3M dataset’s diverse content, quality assurance, and support for multi- modal learning make it a valuable asset for researchers and AI enthusiasts. Each dataset sample consists of an image accompanied by a corresponding text description, reflecting the richness of human language and visual perception. However, after accounting for license restrictions and elim- inating invalid image links, the dataset comprises approximately 2.2 million data pairs suitable for training purposes and 10 thousand data pairs designated for validation.', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Sharmaetal .,', 'url': 'cite.sharma2018conceptual', 'start_index': 6}, {'text': '2018', 'url': 'cite.sharma2018conceptual', 'start_index': 21}], 'page_number': 15, 'parent_id': '5a93b3819997804dfff3393e122783f8', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '2979e3ed29dacc7eea366d5752ab4e87', 'text': 'VIST (Huang et al., 2016): Visual Storytelling (VIST) dataset is an innovative compilation of visual narratives. The VIST dataset’s engaging content, narrative structure, and emphasis on se- quential understanding position it as an essential resource for researchers focusing on sequential image understanding. Each sequence within this dataset consists of five images accompanied by corresponding textual narratives, showcasing the intricate interplay between visual imagery and sto- rytelling. Designed to foster creativity and challenge conventional image-captioning models, the dataset provides a platform for training and validating algorithms capable of generating coherent and contextually relevant stories. After eliminating the invalid image links, we got over 65 thou- sand unique photos organized into more than 34 thousand storytelling sequences for training and 4 thousand sequences with 8 thousand images for validation.', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Huangetal .,', 'url': 'cite.huang2016visual', 'start_index': 6}, {'text': '2016', 'url': 'cite.huang2016visual', 'start_index': 20}], 'page_number': 15, 'parent_id': '5a93b3819997804dfff3393e122783f8', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '17270241fb5be8258a3c2db7a96fc223', 'text': 'MMDialog (Feng et al., 2022): Multi-Modal Dialogue (MMDialog) dataset stands as the largest collection of multimodal conversation dialogues. The MMDialog dataset’s extensive scale, real human-human chat content, and emphasis on multimodal open-domain conversations position it as an unparalleled asset for researchers and practitioners in artificial intelligence. Each dialogue within this dataset typically includes 2.59 images, integrated anywhere within the conversation, showcasing the complex interplay between text and visual elements. Designed to mirror real-world conversational dynamics, the dataset is a robust platform for developing, training, and validating algorithms capable of understanding and generating coherent dialogues that seamlessly blend textual and visual information.', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Fengetal .,', 'url': 'cite.feng2022mmdialog', 'start_index': 10}, {'text': '2022', 'url': 'cite.feng2022mmdialog', 'start_index': 23}], 'page_number': 15, 'parent_id': '5a93b3819997804dfff3393e122783f8', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'e7d9ca6c37a55242928c3f2db7a87a96', 'text': 'B.2 DATA FORMAT', 'metadata': {'languages': ['eng'], 'page_number': 15, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '4e81c56efd1bef8bf9c740b875e25795', 'text': 'Pretraining Stage In the pretraining stage, we aim to synchronize the generative voken with the text-to-image model’s conditional feature, focusing on single-turn text-image pairs. To achieve this, we utilize data from the CC3M dataset, constructing training samples by appending vokens as image placeholders after the captions, such as “a big black dog [IMG1] . . . [IMGn].” The Language Model (LLM) is then tasked with only generating these placeholders for text creation, and the correspond-', 'metadata': {'languages': ['eng'], 'page_number': 15, 'parent_id': 'e7d9ca6c37a55242928c3f2db7a87a96', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Footer', 'element_id': 'e629fa6598d732768f7c726b4b621285', 'text': '15', 'metadata': {'languages': ['eng'], 'page_number': 15, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '4c4f271789570df7924729a78fa97f1e', 'text': 'ing output hidden features are further employed to compute the conditional generation loss with the ground truth image.', 'metadata': {'languages': ['eng'], 'page_number': 16, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'ade4266b1f2bf86bdab73d2c960f79a4', 'text': 'Fine-tuning Stage In this stage, we utilize the VIST and MMDialog datasets, which contain multi-turn multimodal data. During training, we integrate placeholders for input images, such as ’<Img><ImageHere></Img>’, into the input text prompts when applicable. These prompts also encompass various instructions corresponding to different task types, with outputs manifesting as pure-text, pure-voken, or text-voken combinations. Below, we present example templates in the VIST dataset to illustrate the different task types:', 'metadata': {'languages': ['eng'], 'page_number': 16, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'ListItem', 'element_id': '15684154df4acaf0570fbeffda4ee11d', 'text': 'Text Generation: Input: “<History Context> What happens in the next scene image: <Img><ImageHere></Img>”; Output: “<Text Description>”', 'metadata': {'languages': ['eng'], 'page_number': 16, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'ListItem', 'element_id': '36273b7cb4b1620e5e5d494f588a316b', 'text': 'Image Generation: Input: “<History Context> Generate an image with the scene de- scription: [Text Description]”; Output: “[IMG1]...[IMGn]”', 'metadata': {'languages': ['eng'], 'page_number': 16, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'ListItem', 'element_id': '4ccddae04d312ae7e712cd081ff70dde', 'text': 'Text-Image Generation: Input: “<History Context> What should happen then?”; Output: “<Text Description> [IMG1]...[IMGn]”', 'metadata': {'languages': ['eng'], 'page_number': 16, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'e2fcd0b5ff6a2d0dfcfc791edf60a374', 'text': 'By structuring the input and output in this manner, we create a flexible framework that accommo- dates various multimodal tasks, enhancing the model’s ability to interpret and generate textual and visual content. The history context in the VIST dataset includes all previous story steps with texts and images. In the MMDialog dataset, due to the limitation of computational resources, we only use up to one previous turn as the history context, and all data are formatted into the dialog.', 'metadata': {'languages': ['eng'], 'page_number': 16, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '3f9f93f7a7569fef1f1581fadb1ce640', 'text': 'C MORE EXPERIMENTS', 'metadata': {'languages': ['eng'], 'page_number': 16, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '580e71b952089fac440e26429ad3b751', 'text': 'C.1 EVALUATION OF GUIDANCE SCALE', 'metadata': {'languages': ['eng'], 'page_number': 16, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'e97528e0c605d809998a913eb98328d2', 'text': 'Since our model incorporates CFG, evaluating how different guidance scales affect image generation is crucial. Therefore, we plotted several line charts in Fig 5 to depict the changes in metrics with varying guidance scales. The figures reveal that the stable diffusion model and our model generate better images as the guidance scale increases. However, when the scale exceeds 10, the image semantic coherence stabilizes while the image quality declines. This suggests that the guidance scale should be set within a reasonable range for optimal image generation.', 'metadata': {'languages': ['eng'], 'links': [{'text': 'whenthescaleexceeds10', 'url': 'figure.caption.12', 'start_index': 354}], 'page_number': 16, 'parent_id': '580e71b952089fac440e26429ad3b751', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '0f45004b38c4bbe65bf6be1335371606', 'text': 'C.2 EVALUATION OF VOKEN NUMBER', 'metadata': {'languages': ['eng'], 'page_number': 16, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '034a6e08e4cf2b354e4b15aa76a4b77e', 'text': 'The voken features in our model are directly utilized as conditions in the text-to-image model, leading to the expectation that an increase in the number of vokens would enhance the model’s representative capabilities. To validate this hypothesis, we experimented by training the model with varying numbers of vokens, ranging from 1 to 8. As illustrated in Fig 6, the model’s performance consistently improves with adding more vokens. This improvement is particularly noticeable when the number of vokens is increased from 1 to 4, highlighting the significant role that vokens play in enhancing the model’s effectiveness.', 'metadata': {'languages': ['eng'], 'links': [{'text': ',', 'url': 'figure.caption.14', 'start_index': 362}], 'page_number': 16, 'parent_id': '0f45004b38c4bbe65bf6be1335371606', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '48b0cd2cac353a47b882e6400109e585', 'text': 'C.3 ABLATION OF MODEL DESIGNS', 'metadata': {'languages': ['eng'], 'page_number': 16, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'e9d5a1432b7d695316386fcbe3003b96', 'text': 'This section explores alternatives to the transformer encoder/decoder architecture discussed in the main paper. Specifically, we experimented with two additional settings: Fixed Queries, and Decoder-Only model where learnable queries are fed into the transformer decoder. For the fixed queries design, we initialize queries the same as learnable queries experiments in the main paper and keep them fixed during training. In the decoder-only approach, we utilize solely the transformer decoder and apply padding to the decoder’s output, ensuring that the token length reaches 77. This length adjustment allows the output to be compatible with the Stable Diffusion encoder. The results of these experiments are detailed in Table 8. From the results of MiniGPT-5 with fixed queries, we find there exists a slight trade-off between image-text coherence and image qualities, where fixed queries can lead to higher image metrics (IS and FID) but lower CLIP similarities. Meanwhile, MiniGPT-5 consistently outperforms the Decoder-Only results in all four evaluation metrics, vali- dating the robustness and efficacy of MiniGPT-5’s transformer encoder/decoder architecture design.', 'metadata': {'languages': ['eng'], 'links': [{'text': '.', 'url': 'table.caption.13', 'start_index': 725}], 'page_number': 16, 'parent_id': '48b0cd2cac353a47b882e6400109e585', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Footer', 'element_id': 'b17ef6d19c7a5b1ee83b907c595526dc', 'text': '16', 'metadata': {'languages': ['eng'], 'page_number': 16, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'd09a9b966c0556635fd92554d712dfd9', 'text': 'Figure 4: Screenshot for human evaluation interface on the Amazon Mechanical Turk crowdsource evaluation platform. Output 1 is generated by MiniGPT-5, while output 2 is generated by the two- stage baseline.', 'metadata': {'languages': ['eng'], 'page_number': 17, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '5e2c614c23f02239bc03c6c04fcb6819', 'text': 'Model', 'metadata': {'languages': ['eng'], 'page_number': 17, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'da310f3db024f5d0893f5bfee4a89d71', 'text': 'CLIP-I (↑) CLIP-T (↑)', 'metadata': {'languages': ['eng'], 'page_number': 17, 'parent_id': '5e2c614c23f02239bc03c6c04fcb6819', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '1c014e95a75860c7f8724d8a2793f18c', 'text': 'IS (↑)', 'metadata': {'languages': ['eng'], 'page_number': 17, 'parent_id': '5e2c614c23f02239bc03c6c04fcb6819', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '0d6339d2b85b7d5ad6801154a96ace83', 'text': 'FID (↓)', 'metadata': {'languages': ['eng'], 'page_number': 17, 'parent_id': '5e2c614c23f02239bc03c6c04fcb6819', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '77603e74fdccc1ddb7aabf116fdd84cc', 'text': 'MiniGPT-5 MiniGPT-5 (Fixed Queries) MiniGPT-5 (Decoder-Only)', 'metadata': {'languages': ['eng'], 'page_number': 17, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '4b7bd146e800aa65da2a46040864bc2f', 'text': '0.61 0.60 0.58', 'metadata': {'languages': ['eng'], 'page_number': 17, 'parent_id': '77603e74fdccc1ddb7aabf116fdd84cc', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '006e5fefd06da5ae6c91d695422df6c6', 'text': '0.22 0.21 0.20', 'metadata': {'languages': ['eng'], 'page_number': 17, 'parent_id': '77603e74fdccc1ddb7aabf116fdd84cc', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '9cb58245ab0263d9862f0cd768246069', 'text': '28.09 28.55 24.74', 'metadata': {'languages': ['eng'], 'page_number': 17, 'parent_id': '77603e74fdccc1ddb7aabf116fdd84cc', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'b2a86141a2f0a82e764d369327fbc5cf', 'text': '31.47 30.56 34.88', 'metadata': {'languages': ['eng'], 'page_number': 17, 'parent_id': '77603e74fdccc1ddb7aabf116fdd84cc', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'bd813f4f06254b33e8d6d147a98e5cf0', 'text': 'Table 8: Evaluation of different model designs for image generation qualities on the CC3M valida- tion set.', 'metadata': {'languages': ['eng'], 'page_number': 17, 'parent_id': '77603e74fdccc1ddb7aabf116fdd84cc', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '3998d6318d4a2c160c89db7f86edd08b', 'text': 'D MORE QUALITATIVE EXAMPLES', 'metadata': {'languages': ['eng'], 'page_number': 17, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'a970be082a3f3af3fe9d8bea6771b9dc', 'text': 'In this section, we provide additional qualitative examples to further demonstrate the capabilities of MiniGPT-5. Figures 7,8,9, and 10 showcase these examples across various datasets and settings.', 'metadata': {'languages': ['eng'], 'links': [{'text': ',', 'url': 'figure.caption.15', 'start_index': 123}, {'text': '8', 'url': 'figure.caption.16', 'start_index': 124}, {'text': '9', 'url': 'figure.caption.17', 'start_index': 126}, {'text': 'and10showcasetheseexamplesacrossvariousdatasetsandsettings', 'url': 'figure.caption.18', 'start_index': 129}], 'page_number': 17, 'parent_id': '3998d6318d4a2c160c89db7f86edd08b', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '44c9be24d9d85843a02e3f2e939e9798', 'text': 'Figure 7 presents a comparative analysis on the VIST validation set, illustrating how MiniGPT-5 outperforms baseline models in terms of image generation quality and alignment with multimodal inputs. The examples highlight the superiority of MiniGPT-5 in generating images that closely match the given text prompts.', 'metadata': {'languages': ['eng'], 'links': [{'text': '.', 'url': 'figure.caption.15', 'start_index': 197}], 'page_number': 17, 'parent_id': '3998d6318d4a2c160c89db7f86edd08b', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Footer', 'element_id': '4523540f1504cd17100c4835e85b7eef', 'text': '17', 'metadata': {'languages': ['eng'], 'page_number': 17, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '853a10e958cb62eb97934ca2c05485aa', 'text': '(a) FID vs CFG Scale', 'metadata': {'languages': ['eng'], 'page_number': 18, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '23910f8217782ea2c8defe3dcdfd93fa', 'text': '(b) IS vs CFG Scale', 'metadata': {'languages': ['eng'], 'page_number': 18, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '6b5badbd04252a861aa7c30ff50628d6', 'text': '(c) CLIP-T vs CFG Scale', 'metadata': {'languages': ['eng'], 'page_number': 18, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '713a2db4869cc2e5aeb731aa69504fb2', 'text': '(d) CLIP-I vs CFG Scale', 'metadata': {'languages': ['eng'], 'page_number': 18, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '0848d02fff63145c777bf9705faea1f9', 'text': 'Figure 5: Line charts for various metrics vs Classifier-free Guidance (CFG) scale on CC3M. The results suggest that our CFG strategy can exhibit comparable effectiveness to the CFG strategy employed in SD2, with the appropriate CFG scale significantly enhancing both image quality and coherence.', 'metadata': {'languages': ['eng'], 'page_number': 18, 'parent_id': '713a2db4869cc2e5aeb731aa69504fb2', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '9f398a0024d8a355470508355dcbab9a', 'text': '(a) FID vs nvoken', 'metadata': {'languages': ['eng'], 'page_number': 18, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '3442e57e6abb8214cde9e98d1e6e6c97', 'text': '(b) IS vs nvoken', 'metadata': {'languages': ['eng'], 'page_number': 18, 'parent_id': '9f398a0024d8a355470508355dcbab9a', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'ff9072398e9948062f35cfd8145219f5', 'text': '(c) CLIP-T vs nvoken', 'metadata': {'languages': ['eng'], 'page_number': 18, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'e9b3a85650d02cc24e3240952f7e0a1b', 'text': '(d) CLIP-I vs nvoken', 'metadata': {'languages': ['eng'], 'page_number': 18, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '5fe5e15dc571343c9277343bbd3d9e04', 'text': 'Figure 6: Line charts for various metrics vs the number of vokens on CC3M. As the number of vokens increases, the image quality and CLIP scores improve. In this work, our default voken number is 8.', 'metadata': {'languages': ['eng'], 'page_number': 18, 'parent_id': 'e9b3a85650d02cc24e3240952f7e0a1b', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '9646848ac4c2657dbad3f8b9885d3cc5', 'text': 'In Figure 8, we focus on the performance of MiniGPT-5 in free multimodal generation scenarios. The results clearly indicate an improvement over the Two-Stage baseline, emphasizing MiniGPT-5’s ability to perform consistent and creative multimodal generation.', 'metadata': {'languages': ['eng'], 'links': [{'text': ',', 'url': 'figure.caption.16', 'start_index': 11}], 'page_number': 18, 'parent_id': 'e9b3a85650d02cc24e3240952f7e0a1b', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Footer', 'element_id': '4ec9599fc203d176a301536c2e091a19', 'text': '18', 'metadata': {'languages': ['eng'], 'page_number': 18, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '8609d00619cebe9cc4e02992de118291', 'text': 'Figure 9 showcases the application of MiniGPT-5 in the context of the MMDialog test set. Here, the emphasis is on free multimodal dialog generation, with MiniGPT-5 displaying a decent performance in generating coherent and contextually relevant multimodal dialogues.', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Figure9showcasestheapplicationofMiniGPT', 'url': 'figure.caption.17', 'start_index': 0}], 'page_number': 19, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '0c3a4d2b2bdbadb425dbf17289531a67', 'text': 'Lastly, Figure 10 highlights MiniGPT-5’s performance in single text-to-image generation tasks on the CC3M validation set. The examples underline the model’s proficiency in generating visually accurate and contextually appropriate images from textual descriptions, surpassing the performance of baseline models.', 'metadata': {'languages': ['eng'], 'links': [{'text': 'Figure10highlightsMiniGPT - 5 ’ sperformanceinsingletext - to - theCC3Mvalidationset', 'url': 'figure.caption.18', 'start_index': 8}], 'page_number': 19, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'dc33b6468123b1e5db89270d60182d39', 'text': 'Each figure includes a clear depiction of input prompts (indicated in orange blocks) and the corre- sponding model outputs (in green blocks), providing a comprehensive view of MiniGPT-5’s capa- bilities across different multimodal generation tasks.', 'metadata': {'languages': ['eng'], 'page_number': 19, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Footer', 'element_id': '9400f1b21cb527d7fa3d3eabba93557a', 'text': '19', 'metadata': {'languages': ['eng'], 'page_number': 19, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '4f2de210b0fdfdb3f62f72151ccbd3c5', 'text': 'i took my wife outfor our anniversarydinner.our first coursewas a light butdelicious salad.following oursalad we hadsquash bisquefor our main coursewe had a beautifullyplated salmon.to end ourwonderfulnight we had aparfait fordessert.', 'metadata': {'languages': ['eng'], 'page_number': 20, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '5462f0b66ae570a295ff5477e7058d66', 'text': 'GILLSD 2Two-stageMiniGPT-5GT', 'metadata': {'languages': ['eng'], 'page_number': 20, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '5462f0b66ae570a295ff5477e7058d66', 'text': 'GILLSD 2Two-stageMiniGPT-5GT', 'metadata': {'languages': ['eng'], 'page_number': 20, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '5462f0b66ae570a295ff5477e7058d66', 'text': 'GILLSD 2Two-stageMiniGPT-5GT', 'metadata': {'languages': ['eng'], 'page_number': 20, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'a7a55ad59be0b2966793830a50f28b48', 'text': \"we didn't expectsuch beautyoutdoors.the bridge wasall i thought itwould be.the view of thewater wereamazing.the bridge wasbreath taking.we all agreedthe food wasfantastic.\", 'metadata': {'languages': ['eng'], 'page_number': 20, 'parent_id': '5462f0b66ae570a295ff5477e7058d66', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'd19a15f87189e1d24584c7cad98a7437', 'text': \"i had a photosession with myfavorite doll.she is sophilosophicalsometimes.the cat likesher too, theywere having agood time.the cat really likesher, he even gaveher a kiss !she finishedthe sessionposing withher guitar,she's such agoodmusician.\", 'metadata': {'languages': ['eng'], 'page_number': 20, 'parent_id': '5462f0b66ae570a295ff5477e7058d66', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '4f2bc83c319ab644f57658af0fec7ad4', 'text': 'Figure 7: Comparative examples from MiniGPT-5 and baselines on the VIST validation set for image generation with multimodal input. Orange blocks denote input prompts, while green blocks show model outputs.', 'metadata': {'languages': ['eng'], 'page_number': 20, 'parent_id': '5462f0b66ae570a295ff5477e7058d66', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Footer', 'element_id': 'f5ca38f748a1d6eaf726b8a42fb575c3', 'text': '20', 'metadata': {'languages': ['eng'], 'page_number': 20, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '082e847dfb57207126932fff1b51a9d0', 'text': 'Jacob and his son.', 'metadata': {'languages': ['eng'], 'page_number': 21, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '2cf1de29f4f6d9167423051b15b19cb8', 'text': 'Everyone was ingreate spirits', 'metadata': {'languages': ['eng'], 'page_number': 21, 'parent_id': '082e847dfb57207126932fff1b51a9d0', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '3b6e3e588cb964f7b55b17ceaf3ed548', 'text': 'MiniGPT-5Two-StageThis book was aboutanimals and it had lots ofpictures too.', 'metadata': {'languages': ['eng'], 'page_number': 21, 'parent_id': '082e847dfb57207126932fff1b51a9d0', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '45dc296ae9ad9938735ba6cdf141665d', 'text': 'The happy coupleenjoying theirengagement.GTThis is the crew righthere.', 'metadata': {'languages': ['eng'], 'page_number': 21, 'parent_id': '082e847dfb57207126932fff1b51a9d0', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '52dfc4ee5a6ee87e3a96a67b234a3d6d', 'text': 'The first book I readhad lots of coolpictures in it.', 'metadata': {'languages': ['eng'], 'page_number': 21, 'parent_id': '082e847dfb57207126932fff1b51a9d0', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '542f7b830325d21f868f7c34b9404255', 'text': 'Celebrating with all ofour friendsHer best friend evencame.Even my dad got inon the act.', 'metadata': {'languages': ['eng'], 'page_number': 21, 'parent_id': '082e847dfb57207126932fff1b51a9d0', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '5ea50ee9933655dea5bea024506a222f', 'text': 'I really enjoyedreading the book.GILL', 'metadata': {'languages': ['eng'], 'page_number': 21, 'parent_id': '082e847dfb57207126932fff1b51a9d0', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '7bd7984b8e53e57aecdb85800566c4f5', 'text': 'MiniGPT-5Two-StageEven the guy behind uswas great and fun to bearound.', 'metadata': {'languages': ['eng'], 'page_number': 21, 'parent_id': '082e847dfb57207126932fff1b51a9d0', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '7eb04b11f584d3e85c0b90dfa8c87db4', 'text': 'The meeting was veryinformative and welearned a lot.GILL', 'metadata': {'languages': ['eng'], 'page_number': 21, 'parent_id': '082e847dfb57207126932fff1b51a9d0', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '96715370e3674efdd7d4fbc3148b347c', 'text': 'All of the kids were soexcited to read newbooks', 'metadata': {'languages': ['eng'], 'page_number': 21, 'parent_id': '082e847dfb57207126932fff1b51a9d0', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '9c1b3c05a4442ab7545d29429f3609aa', 'text': 'We had a greattime.GILL', 'metadata': {'languages': ['eng'], 'page_number': 21, 'parent_id': '082e847dfb57207126932fff1b51a9d0', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'a58606c89caa5f9bd69c676835641cff', 'text': 'One of my friendsread us a story fromone of the books.GT', 'metadata': {'languages': ['eng'], 'page_number': 21, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'ba5663c7210e6d9a677d7dae17ab754f', 'text': 'Me and tanner takinga selfie together afterthe meeting.GTMe bondrit duringintermission.', 'metadata': {'languages': ['eng'], 'page_number': 21, 'parent_id': 'a58606c89caa5f9bd69c676835641cff', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'd7927b9704b2ff9ddc9d2fbe0ea11dea', 'text': \"We got to the town hallmeeting early and therewere a lot of people.Here's us watchingthe introduction.Everyone had a lot ofquestions and themeeting was very long\", 'metadata': {'languages': ['eng'], 'page_number': 21, 'parent_id': 'a58606c89caa5f9bd69c676835641cff', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'db253e1c3b2deea0059f427a4fd2b601', 'text': 'On our class trip we allwore our school uniformsI got to read manydifferent book that Ihad never read before.I really enjoyed beingon this trip', 'metadata': {'languages': ['eng'], 'page_number': 21, 'parent_id': 'a58606c89caa5f9bd69c676835641cff', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'db3aef08717c6a92ffcbc9c3525004c0', 'text': 'MiniGPT-5Two-StageWe all gathered todiscuss the program', 'metadata': {'languages': ['eng'], 'page_number': 21, 'parent_id': 'a58606c89caa5f9bd69c676835641cff', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': '80c2c112151be3197e2f62c4bd214410', 'text': 'Figure 8: More qualitative examples from MiniGPT-5 and baselines on VIST validation set for free multimodal generation.', 'metadata': {'languages': ['eng'], 'page_number': 21, 'parent_id': 'a58606c89caa5f9bd69c676835641cff', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Footer', 'element_id': '6f4b6612125fb3a0daecd2799dfd6c9c', 'text': '21', 'metadata': {'languages': ['eng'], 'page_number': 21, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '0492afdea7c22dee896c4a11314b87f5', 'text': \"So cute!! I'm justabout to get into bedand finish off theGoblet of Fire for themillionth time!\", 'metadata': {'languages': ['eng'], 'page_number': 22, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '205615eca7803162b454770aad7d9a50', 'text': 'Travelfaves2019 we have seenquite a number of gorgeousAfrica', 'metadata': {'languages': ['eng'], 'page_number': 22, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '2783597e6cc82fed8580917db125fe32', 'text': \"Haha I know what youmean! I'm just about tofinish the last Harry Potterbook! I'm so excited forthe next one!GILL\", 'metadata': {'languages': ['eng'], 'page_number': 22, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '32c6ab477f221fed1da34ff4544a186a', 'text': \"What I find so funnyis everyone has astrong opinion of meand no one realisesI'm actually a soppy,over dramatic buggerthat :growing_heart:Harry PotterI've read all the books at least 10times each!Harry PotterHaha he has the full box setand home and at his Nanna's:) he even tries to head butthis lamp like dobby:face_with_tears_of_joy::see-no-evil_monkey:MiniGPT-5GT\", 'metadata': {'languages': ['eng'], 'page_number': 22, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '776e34ede441181c32569fe04fc8ea11', 'text': 'You would get on withmy 3 year old then heis obsessed withHarry potter haha', 'metadata': {'languages': ['eng'], 'page_number': 22, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '7d713a1d5b0bded254d8d33281fc92c9', 'text': \"Our travelfaves2019what's yoursThe Greate Wall of ChinaGILL\", 'metadata': {'languages': ['eng'], 'page_number': 22, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'aec69fb94ba9e2ef3f097eda62f58415', 'text': 'It the final FlashbackFridayz of 2019and we are looking back with a themeof TravelFaves2019. Tag and retweetyour hosts and guest hosts; Shareyous and tag you friends.Travelfaves2019 ours is thegorgeous waterfall in Costa RicaLuxurious views! Throwback toour trip to New Orleans lastJanuary where we stopped by theTabasco Factory in Avery IslandMiniGPT-5GT', 'metadata': {'languages': ['eng'], 'page_number': 22, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'd3a0c00ba63e17ae9857c906588079a6', 'text': 'Figure 9: More qualitative examples from MiniGPT-5 on MMDialog test set for free multimodal dialog generation.', 'metadata': {'languages': ['eng'], 'page_number': 22, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Footer', 'element_id': '785f3ec7eb32f30b90cd0fcf3657d388', 'text': '22', 'metadata': {'languages': ['eng'], 'page_number': 22, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '191ef12e0e9cc5d987983cce9553d2ab', 'text': 'MiniGPT-5SD 2GILLGT', 'metadata': {'languages': ['eng'], 'page_number': 23, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '191ef12e0e9cc5d987983cce9553d2ab', 'text': 'MiniGPT-5SD 2GILLGT', 'metadata': {'languages': ['eng'], 'page_number': 23, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '191ef12e0e9cc5d987983cce9553d2ab', 'text': 'MiniGPT-5SD 2GILLGT', 'metadata': {'languages': ['eng'], 'page_number': 23, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': '191ef12e0e9cc5d987983cce9553d2ab', 'text': 'MiniGPT-5SD 2GILLGT', 'metadata': {'languages': ['eng'], 'page_number': 23, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '2c382e96cff133ea91f1511fbe168ecd', 'text': 'womens handssprinkle a doughwith ﬂour close up', 'metadata': {'languages': ['eng'], 'page_number': 23, 'parent_id': '191ef12e0e9cc5d987983cce9553d2ab', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': '7759dfdb37d32a93b0b5257ea612f005', 'text': 'we all knowsuperman , comicbook characters ,but history is full ofless impressiveheroes', 'metadata': {'languages': ['eng'], 'page_number': 23, 'parent_id': '191ef12e0e9cc5d987983cce9553d2ab', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Title', 'element_id': 'ae542a05033cf21803bb2f27faee8f01', 'text': 'MiniGPT-5 SD 2GILLGT', 'metadata': {'languages': ['eng'], 'page_number': 23, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'bef3c90b2a19e0f27282d50e4b09f128', 'text': 'happy youngbusinessman with afolder running up adrawn stairs along aconcrete wall', 'metadata': {'languages': ['eng'], 'page_number': 23, 'parent_id': 'ae542a05033cf21803bb2f27faee8f01', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'd00437afd77caba2d33687bae934a7f3', 'text': 'sunﬂowers have adeep sentimentalmeaning for me', 'metadata': {'languages': ['eng'], 'page_number': 23, 'parent_id': 'ae542a05033cf21803bb2f27faee8f01', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'NarrativeText', 'element_id': 'e9b8aeaf844bf5f64b398bd407759616', 'text': 'boy looking in theencyclopediathrough amagnifying glass', 'metadata': {'languages': ['eng'], 'page_number': 23, 'parent_id': 'ae542a05033cf21803bb2f27faee8f01', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'UncategorizedText', 'element_id': 'cd20872a19e9ea726bf7651677ddb670', 'text': 'Figure 10: More qualitative examples from MiniGPT-5 and baselines on CC3M validation set for single text-to-image generation.', 'metadata': {'languages': ['eng'], 'page_number': 23, 'parent_id': 'ae542a05033cf21803bb2f27faee8f01', 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}, {'type': 'Footer', 'element_id': '535fa30d7e25dd8a49f1536779734ec8', 'text': '23', 'metadata': {'languages': ['eng'], 'page_number': 23, 'filename': 'data\\\\MINIGPT_5.pdf', 'filetype': 'application/pdf'}}])\n"
     ]
    }
   ],
   "source": [
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'Title',\n",
       "  'element_id': 'd99ad376d3c673278a6c8b90e4facb15',\n",
       "  'text': 'MINIGPT-5: INTERLEAVED VISION-AND-LANGUAGE GENERATION VIA GENERATIVE VOKENS',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'd5d4430ca05ac3791e755e87c1c256d8',\n",
       "  'text': 'Kaizhi Zheng∗, Xuehai He∗ , and Xin Eric Wang',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '9d1274315ba7eae03960265c08d5edaa',\n",
       "  'text': 'University of California, Santa Cruz https://github.com/eric-ai-lab/MiniGPT-5',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '07cd30f6f89754a2c217419880a91514',\n",
       "  'text': '4 2 0 2',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '9d1274315ba7eae03960265c08d5edaa',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '452202c3d8a420d49447943b87c30d0e',\n",
       "  'text': 'r a',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '114f549a188a6b894dd25f3f91e45747',\n",
       "  'text': 'M 5 1',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '452202c3d8a420d49447943b87c30d0e',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'cfae0d4248f7142f7b17f826cd7a5192',\n",
       "  'text': ']',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '452202c3d8a420d49447943b87c30d0e',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '19d05c4115a6b94b3b470e7c10e29698',\n",
       "  'text': 'V C . s c [',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '87290badddf80fb0a105ecccb54d177b',\n",
       "  'text': '3 v 9 3 2 2 0 . 0 1 3 2 : v i X r a',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '19d05c4115a6b94b3b470e7c10e29698',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '3d1626989d3e923485561f1e5bdeaa58',\n",
       "  'text': 'ABSTRACT',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '79c81b6766d8f90b73e9c616b3971089',\n",
       "  'text': 'The effectiveness of Multimodal Large Language Models (MLLMs) demonstrates a profound capability in multimodal understanding. However, the simultaneous generation of images with coherent texts is still underdeveloped. Addressing this, we introduce a novel interleaved vision-and-language generation method, centered around the concept of “generative vokens”. These vokens serve as piv- otal elements contributing to coherent image-text outputs. Our method is marked by a unique two-stage training strategy for description-free multimodal genera- tion, which does not necessitate extensive descriptions of images. We integrate classifier-free guidance to enhance the alignment of generated images and texts, ensuring more seamless and contextually relevant multimodal interactions. Our model, MiniGPT-5, exhibits substantial improvement over the baseline models on multimodal generation datasets, including MMDialog and VIST. The human eval- uation shows MiniGPT-5 is better than the baseline model on more than 56% cases for multimodal generation, highlighting its efficacy across diverse benchmarks.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '3d1626989d3e923485561f1e5bdeaa58',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '6b86b273ff34fce19d6b804eff5a3f57',\n",
       "  'text': '1',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '3d1626989d3e923485561f1e5bdeaa58',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '348348036267fa046df6956d6bff62c9',\n",
       "  'text': 'INTRODUCTION',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'b34dabb17a8fe351ae4c08aec04a5201',\n",
       "  'text': 'The development of large-scale vision-and-language models is significantly impacting a wide range of fields like automated dialogue systems and digital content creation. With the surge in research and development in this domain, the current state-of-the-art Large Language Models (LLMs) (OpenAI, 2023; Chiang et al., 2023; Ouyang et al., 2022) and vision-and-language models such as (Wu et al., 2023a; Li et al., 2023c; Tsimpoukelli et al., 2021; Alayrac et al., 2022) fall short in generating coherent multimodal outputs. This limitation becomes particularly evident in tasks that demand an integrated handling of vision and language, essential for the next generation Large Language Models (LLMs).',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'OpenAI',\n",
       "     'url': 'cite.openai2023gpt4',\n",
       "     'start_index': 286},\n",
       "    {'text': '2023', 'url': 'cite.openai2023gpt4', 'start_index': 294},\n",
       "    {'text': 'Chiangetal .,', 'url': 'cite.vicuna2023', 'start_index': 300},\n",
       "    {'text': '2023', 'url': 'cite.vicuna2023', 'start_index': 315},\n",
       "    {'text': 'Ouyangetal .,', 'url': 'cite.training_lm', 'start_index': 321},\n",
       "    {'text': '2022', 'url': 'cite.training_lm', 'start_index': 336},\n",
       "    {'text': 'Wuetal', 'url': 'cite.visualchatgpt', 'start_index': 382},\n",
       "    {'text': '2023a', 'url': 'cite.visualchatgpt', 'start_index': 393},\n",
       "    {'text': 'Lietal .,', 'url': 'cite.li2023blip', 'start_index': 400},\n",
       "    {'text': '2023c', 'url': 'cite.li2023blip', 'start_index': 411},\n",
       "    {'text': 'Tsimpoukellietal .,', 'url': 'cite.frozen', 'start_index': 418},\n",
       "    {'text': '2021', 'url': 'cite.frozen', 'start_index': 439},\n",
       "    {'text': 'Alayracetal .,',\n",
       "     'url': 'cite.alayrac2022flamingo',\n",
       "     'start_index': 445},\n",
       "    {'text': '2022', 'url': 'cite.alayrac2022flamingo', 'start_index': 461}],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '348348036267fa046df6956d6bff62c9',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '64d9d5e9ccbbd5290872abe7586c626b',\n",
       "  'text': 'Our work, as illustrated in Fig. 1, seeks to address these shortcomings by enhancing the integration of text and image generation in LLMs. The challenges in developing a multimodal LLM capable of interleaved vision and language generation are manifold. First, LLMs typically lack mechanisms to directly produce images, prompting us to introduce “generative vokens” that bridge the gap be- tween textual and visual feature spaces. Second, the constraint of data scarcity, especially in vision- and-language tasks (Sharma et al., 2018) lacking extensive detailed descriptions of images (Huang et al., 2016), is countered by our unique description-free training approach. Third, maintaining both image-text and image-image consistency poses a significant challenge, which we address through dual-loss strategies. Finally, as we push forward the boundaries with LLMs, the large memory re- quirements urge us to devise more efficient end-to-end strategies and create an efficient training pipeline accessible for the community, especially in downstream tasks.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': '1', 'url': 'figure.caption.1', 'start_index': 33},\n",
       "    {'text': 'Sharmaetal .,',\n",
       "     'url': 'cite.sharma2018conceptual',\n",
       "     'start_index': 513},\n",
       "    {'text': '2018', 'url': 'cite.sharma2018conceptual', 'start_index': 528},\n",
       "    {'text': '(', 'url': 'cite.huang2016visual', 'start_index': 584},\n",
       "    {'text': 'etal .,', 'url': 'cite.huang2016visual', 'start_index': 591},\n",
       "    {'text': '2016', 'url': 'cite.huang2016visual', 'start_index': 599}],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '348348036267fa046df6956d6bff62c9',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '2a1ee488f031fdc96b87bad37795fe9f',\n",
       "  'text': 'Specifically, to overcome these challenges, we present MiniGPT-5, a novel approach for interleaved vision-and-language generation. By combing the Stable Diffusion with LLMs through special vi- sual tokens (Tan & Bansal, 2020) – “generative vokens”, we develop a new approach for multimodal generation. Our two-stage training methodology emphasizes a description-free foundational phase,',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Tan & Bansal',\n",
       "     'url': 'cite.tan2020vokenization',\n",
       "     'start_index': 205},\n",
       "    {'text': '2020', 'url': 'cite.tan2020vokenization', 'start_index': 219}],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '348348036267fa046df6956d6bff62c9',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'df8423e293ff039f30ed34fc2890ea0f',\n",
       "  'text': '∗These authors contributed equally to this work.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'parent_id': '348348036267fa046df6956d6bff62c9',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Footer',\n",
       "  'element_id': '6b86b273ff34fce19d6b804eff5a3f57',\n",
       "  'text': '1',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 1,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'c77a44c8e4ba4cb2417b666ebc5659d9',\n",
       "  'text': 'enabling effective model training even with limited caption-grounded images. This strategy, dis- tinct from existing works, pivots on generic stages free from image annotations. To ensure that the generated text and images are in harmony, our dual-loss strategy comes into play, further enhanced by our innovative generative voken approach and classifier-free guidance. Our parameter-efficient fine-tuning strategy optimizes training efficiency and addresses memory constraints.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 2,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '45154ea5110bc9047747da87c259d349',\n",
       "  'text': 'As shown in Fig. 2, leveraging ViT (Vision Transformer) and Qformer (Li et al., 2023c), alongside Large Language Models, we adapt multimodal inputs into generative vokens, seamlessly combined with the high-resolution Stable Diffusion 2.1 model (Rombach et al., 2022b) for context-aware im- Incorporating images as auxiliary input with instruction tuning approaches and age generation. pioneering both the text and image generation loss, we amplify the synergy between text and visu- als. We experiment on the CC3M (Sharma et al., 2018), VIST (Huang et al., 2016), and MMDi- alog (Feng et al., 2022) datasets. Notably, MiniGPT-5 shows superior performance across the two multimodal generation datasets.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': '2', 'url': 'figure.caption.2', 'start_index': 17},\n",
       "    {'text': 'Lietal .,', 'url': 'cite.li2023blip', 'start_index': 69},\n",
       "    {'text': '2023c', 'url': 'cite.li2023blip', 'start_index': 80},\n",
       "    {'text': 'Rombachetal .,',\n",
       "     'url': 'cite.rombach2021highresolution',\n",
       "     'start_index': 245},\n",
       "    {'text': '2022b',\n",
       "     'url': 'cite.rombach2021highresolution',\n",
       "     'start_index': 261},\n",
       "    {'text': 'Sharmaetal .,',\n",
       "     'url': 'cite.sharma2018conceptual',\n",
       "     'start_index': 515},\n",
       "    {'text': '2018', 'url': 'cite.sharma2018conceptual', 'start_index': 530},\n",
       "    {'text': 'Huangetal .,',\n",
       "     'url': 'cite.huang2016visual',\n",
       "     'start_index': 543},\n",
       "    {'text': '2016', 'url': 'cite.huang2016visual', 'start_index': 557},\n",
       "    {'text': 'Fengetal .,',\n",
       "     'url': 'cite.feng2022mmdialog',\n",
       "     'start_index': 580},\n",
       "    {'text': '2022', 'url': 'cite.feng2022mmdialog', 'start_index': 593}],\n",
       "   'page_number': 2,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'f3c985c13d008b20c5649d80ae4768bc',\n",
       "  'text': 'In summary, our contributions are primarily threefold:',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 2,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'e22329d68aaa1583c3db75ecfdc3ab41',\n",
       "  'text': 'We introduce a novel framework that leverages “generative vokens” to unify LLMs with Stable Diffusion, facilitating interleaved vision-and-language generation without relying on detailed image descriptions. We bridge the modality gap and improve the generation quality by using the loss of the latent diffusion model, the text generation loss, and the caption alignment loss together during training.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 2,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '453b2637ce4e456ab2c94b81c62cade5',\n",
       "  'text': 'We propose a new two-stage training strategy for description-free multimodal generation. The first stage focuses on extracting high-quality text-aligned visual features from large text-image pairs, while the second stage ensures optimal coordination between visual and textual prompts during generation. The inclusion of classifier-free guidance during training enhances the overall generation quality.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 2,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '99dc08e9a92a7d30b07f9aa09568cfe4',\n",
       "  'text': 'MiniGPT-5 achieves significant improvements over baseline methods on interleaved vision- and-language datasets, including VIST and MMDialog, and comparable results to the state- of-the-art on the single text-image pair dataset, CC3M. The human evaluation further shows that, compared with the two-stage baseline, MiniGPT-5 can provide better generation in perspectives of appropriate texts (55%), high-quality images (53%), and coherent multi- modal outputs (56%).',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 2,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'fe3a08cf7b0ae89bd864e8029526b21d',\n",
       "  'text': '2 RELATED WORK',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 2,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '47645a86118e738fb236b5324bea43e2',\n",
       "  'text': 'Large Language Models As Large Language Models (LLMs) become increasingly impactful and accessible, a growing body of research has emerged to extend these pretrained LLMs into the realm of multimodal comprehension tasks (Zhu et al., 2023; Li et al., 2023c; Dai et al., 2023; OpenAI, 2023; Li et al., 2023a; Alayrac et al., 2022; Li et al., 2023b). For example, to reproduce the impres- sive multimodal comprehension ability in GPT-4 (OpenAI, 2023), MiniGPT-4 (Zhu et al., 2023) proposes a projection layer to align pretrained vision component of BLIP-2 (Li et al., 2023c) with an advanced open-source large language model, Vicuna (Chiang et al., 2023). In our work, we utilize the MiniGPT-4 as the base model and extend the model’s capabilities to multimodal generation.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Zhuetal .,',\n",
       "     'url': 'cite.zhu2023minigpt',\n",
       "     'start_index': 221},\n",
       "    {'text': '2023', 'url': 'cite.zhu2023minigpt', 'start_index': 233},\n",
       "    {'text': 'Lietal .,', 'url': 'cite.li2023blip', 'start_index': 239},\n",
       "    {'text': '2023c', 'url': 'cite.li2023blip', 'start_index': 250},\n",
       "    {'text': 'Daietal .,', 'url': 'cite.instructblip', 'start_index': 257},\n",
       "    {'text': '2023', 'url': 'cite.instructblip', 'start_index': 269},\n",
       "    {'text': 'OpenAI', 'url': 'cite.openai2023gpt4', 'start_index': 275},\n",
       "    {'text': '2023', 'url': 'cite.openai2023gpt4', 'start_index': 283},\n",
       "    {'text': 'Lietal .,', 'url': 'cite.li2023otter', 'start_index': 289},\n",
       "    {'text': '2023a', 'url': 'cite.li2023otter', 'start_index': 300},\n",
       "    {'text': 'Alayracetal .,',\n",
       "     'url': 'cite.alayrac2022flamingo',\n",
       "     'start_index': 307},\n",
       "    {'text': '2022', 'url': 'cite.alayrac2022flamingo', 'start_index': 323},\n",
       "    {'text': 'Lietal .,',\n",
       "     'url': 'cite.li-etal-2023-lavis',\n",
       "     'start_index': 329},\n",
       "    {'text': '2023b', 'url': 'cite.li-etal-2023-lavis', 'start_index': 340},\n",
       "    {'text': 'OpenAI', 'url': 'cite.openai2023gpt4', 'start_index': 434},\n",
       "    {'text': '2023', 'url': 'cite.openai2023gpt4', 'start_index': 442},\n",
       "    {'text': 'Zhuetal .,', 'url': 'cite.zhu2023minigpt', 'start_index': 460},\n",
       "    {'text': '2023', 'url': 'cite.zhu2023minigpt', 'start_index': 472},\n",
       "    {'text': 'Lietal .,', 'url': 'cite.li2023blip', 'start_index': 554},\n",
       "    {'text': '2023c', 'url': 'cite.li2023blip', 'start_index': 565},\n",
       "    {'text': 'Chiangetal .,', 'url': 'cite.vicuna2023', 'start_index': 631},\n",
       "    {'text': '2023', 'url': 'cite.vicuna2023', 'start_index': 646}],\n",
       "   'page_number': 2,\n",
       "   'parent_id': 'fe3a08cf7b0ae89bd864e8029526b21d',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '58f894d32f041f18dbc740f22d6cacc5',\n",
       "  'text': 'Text-to-Image Generation To transform textual descriptions into their corresponding visual repre- sentations, text-to-image models (Reed et al., 2016; Dhariwal & Nichol, 2021; Saharia et al., 2022; Rombach et al., 2022b;a; Gu et al., 2023; Nichol et al., 2021; Ramesh et al., 2021; Yu et al., 2022; Chang et al., 2023) employ complex architectures and sophisticated algorithms, bridging the gap be- tween textual information and visual content. These models are adept at interpreting the semantics of input text and translating them into coherent and pertinent images. A notable recent contribution in this field is Stable Diffusion V2 (Rombach et al., 2022b), which employs a diffusion process to generate conditional image features and subsequently reconstructs images from these features. Our research aims to leverage this pretrained model, enhancing its capabilities to accommodate both multimodal input and output.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Reedetal .,',\n",
       "     'url': 'cite.reed2016generative',\n",
       "     'start_index': 132},\n",
       "    {'text': '2016', 'url': 'cite.reed2016generative', 'start_index': 145},\n",
       "    {'text': 'Dhariwal & Nichol',\n",
       "     'url': 'cite.dhariwal2021diffusion',\n",
       "     'start_index': 151},\n",
       "    {'text': '2021', 'url': 'cite.dhariwal2021diffusion', 'start_index': 170},\n",
       "    {'text': 'Sahariaetal .,',\n",
       "     'url': 'cite.saharia2022photorealistic',\n",
       "     'start_index': 176},\n",
       "    {'text': '2022',\n",
       "     'url': 'cite.saharia2022photorealistic',\n",
       "     'start_index': 192},\n",
       "    {'text': 'Rombachetal .,',\n",
       "     'url': 'cite.rombach2021highresolution',\n",
       "     'start_index': 198},\n",
       "    {'text': '2022b',\n",
       "     'url': 'cite.rombach2021highresolution',\n",
       "     'start_index': 214},\n",
       "    {'text': 'a', 'url': 'cite.rombach2022high', 'start_index': 220},\n",
       "    {'text': 'Guetal .,', 'url': 'cite.gu2023photoswap', 'start_index': 223},\n",
       "    {'text': '2023', 'url': 'cite.gu2023photoswap', 'start_index': 234},\n",
       "    {'text': 'Nicholetal .,',\n",
       "     'url': 'cite.nichol2021glide',\n",
       "     'start_index': 240},\n",
       "    {'text': '2021', 'url': 'cite.nichol2021glide', 'start_index': 255},\n",
       "    {'text': 'Rameshetal .,',\n",
       "     'url': 'cite.ramesh2021zero',\n",
       "     'start_index': 261},\n",
       "    {'text': '2021', 'url': 'cite.ramesh2021zero', 'start_index': 276},\n",
       "    {'text': 'Yuetal .,', 'url': 'cite.yu2022scaling', 'start_index': 282},\n",
       "    {'text': '2022', 'url': 'cite.yu2022scaling', 'start_index': 293},\n",
       "    {'text': 'Changetal .,', 'url': 'cite.chang2023muse', 'start_index': 299},\n",
       "    {'text': '2023', 'url': 'cite.chang2023muse', 'start_index': 313},\n",
       "    {'text': 'Rombachetal .,',\n",
       "     'url': 'cite.rombach2021highresolution',\n",
       "     'start_index': 636},\n",
       "    {'text': '2022b',\n",
       "     'url': 'cite.rombach2021highresolution',\n",
       "     'start_index': 652}],\n",
       "   'page_number': 2,\n",
       "   'parent_id': 'fe3a08cf7b0ae89bd864e8029526b21d',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '4e4e2d076d385269293cbbea412c0d5f',\n",
       "  'text': 'Multimodal Generation with Large Language Models To augment the LLM’s capabilities in seamlessly integrating vision and language generation, recent studies have introduced a variety of',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 2,\n",
       "   'parent_id': 'fe3a08cf7b0ae89bd864e8029526b21d',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Footer',\n",
       "  'element_id': 'd4735e3a265e16eee03f59718b9b5d03',\n",
       "  'text': '2',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 2,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '0a2377651792c7246c23f40ec78599c0',\n",
       "  'text': 'Every one elsearrived soonafter.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 3,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '4dfa18944a291bf9aa00bc5555ef136d',\n",
       "  'text': \"We didn't realizethat there wasmore to be doneand everyonehad their roles.\",\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 3,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '71336acd82746d3006cefc83d4d8b22b',\n",
       "  'text': 'What should happen then?',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 3,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '74fceeb8d8578836dcc7bf90205ab36f',\n",
       "  'text': 'My sister arrivedearly to help mewith the familybar bq.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 3,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'b6fcf5dc5af94913501b399ad75ccbf7',\n",
       "  'text': 'We were gladwhen it was overand relaxed alittle bit.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 3,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'b841779d95fb90f4d9e00d3445cc7112',\n",
       "  'text': 'MiniGPT-5Multimodal InputMultimodal Output',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 3,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'd8eebe48c969e6674ac405f713ca799f',\n",
       "  'text': 'Everyone washungry so we gota lot of food.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 3,\n",
       "   'parent_id': 'b841779d95fb90f4d9e00d3445cc7112',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '817abb362c24597b26b5be00c49297e2',\n",
       "  'text': 'Figure 1: MiniGPT-5 is a unified model for interleaved vision-and-language comprehension and generation. Besides the original multimodal comprehension and text generation abilities, MiniGPT- 5 can provide appropriate, coherent multimodal outputs.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 3,\n",
       "   'parent_id': 'b841779d95fb90f4d9e00d3445cc7112',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'f6b6fc6e21a1b2be35555ecb25574b77',\n",
       "  'text': 'innovative methods (Ge et al., 2023; Sun et al., 2021; Koh et al., 2023; Sun et al., 2023b; Yu et al., 2023; Aiello et al., 2023; Wu et al., 2023c). For instance, CM3Leon (Yu et al., 2023) presents a retrieval-augmented, decoder-only architecture designed for both text-to-image and image-to-text applications. Similarly, Emu (Sun et al., 2023b) employs the pretrained EVA-CLIP (Sun et al., 2023a) model to convert images into one-dimensional features and fine-tunes the LLAMA (Touvron et al., 2023) model to generate cohesive text and image features through autoregressive techniques. On the other hand, NextGPT (Wu et al., 2023c), GILL (Koh et al., 2023) and SEED (Ge et al., 2023) explore the concept of mapping vokens into the text feature space of a pretrained Stable Diffusion model; GILL and NextGPT employ an encoder-decoder framework, while SEED utilizes a trainable Q-Former structure. In contrast to these approaches, our model takes a more direct route by aligning voken features with visual information. Additionally, we introduce several training strategies to enhance image quality and contextual coherence.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Geetal .,',\n",
       "     'url': 'cite.ge2023planting',\n",
       "     'start_index': 20},\n",
       "    {'text': '2023', 'url': 'cite.ge2023planting', 'start_index': 31},\n",
       "    {'text': 'Sunetal .,', 'url': 'cite.sun2021multimodal', 'start_index': 37},\n",
       "    {'text': '2021', 'url': 'cite.sun2021multimodal', 'start_index': 49},\n",
       "    {'text': 'Kohetal .,', 'url': 'cite.koh2023generating', 'start_index': 55},\n",
       "    {'text': '2023', 'url': 'cite.koh2023generating', 'start_index': 67},\n",
       "    {'text': 'Sunetal .,', 'url': 'cite.Emu', 'start_index': 73},\n",
       "    {'text': '2023b', 'url': 'cite.Emu', 'start_index': 85},\n",
       "    {'text': 'Yuetal', 'url': 'cite.yu2023scaling', 'start_index': 92},\n",
       "    {'text': '2023', 'url': 'cite.yu2023scaling', 'start_index': 103},\n",
       "    {'text': 'Aielloetal .,',\n",
       "     'url': 'cite.aiello2023jointly',\n",
       "     'start_index': 109},\n",
       "    {'text': '2023', 'url': 'cite.aiello2023jointly', 'start_index': 124},\n",
       "    {'text': 'Wuetal .,', 'url': 'cite.wu2023nextgpt', 'start_index': 130},\n",
       "    {'text': '2023c', 'url': 'cite.wu2023nextgpt', 'start_index': 141},\n",
       "    {'text': 'Yuetal .,', 'url': 'cite.yu2023scaling', 'start_index': 172},\n",
       "    {'text': '2023', 'url': 'cite.yu2023scaling', 'start_index': 183},\n",
       "    {'text': 'Sunetal .,', 'url': 'cite.Emu', 'start_index': 327},\n",
       "    {'text': '2023b', 'url': 'cite.Emu', 'start_index': 339},\n",
       "    {'text': 'Sunetal', 'url': 'cite.sun2023eva', 'start_index': 379},\n",
       "    {'text': '2023a', 'url': 'cite.sun2023eva', 'start_index': 391},\n",
       "    {'text': '( etal ., 2023 ) modeltogeneratecohesivetextandimagefeaturesthroughautoregressivetechniques',\n",
       "     'url': 'cite.touvron2023llama',\n",
       "     'start_index': 476},\n",
       "    {'text': 'etal .,', 'url': 'cite.touvron2023llama', 'start_index': 485},\n",
       "    {'text': '2023', 'url': 'cite.touvron2023llama', 'start_index': 493},\n",
       "    {'text': 'Wuetal .,', 'url': 'cite.wu2023nextgpt', 'start_index': 613},\n",
       "    {'text': '2023c', 'url': 'cite.wu2023nextgpt', 'start_index': 624},\n",
       "    {'text': 'Kohetal .,',\n",
       "     'url': 'cite.koh2023generating',\n",
       "     'start_index': 638},\n",
       "    {'text': '2023', 'url': 'cite.koh2023generating', 'start_index': 650},\n",
       "    {'text': 'Geetal .,', 'url': 'cite.ge2023planting', 'start_index': 666},\n",
       "    {'text': '2023', 'url': 'cite.ge2023planting', 'start_index': 677}],\n",
       "   'page_number': 3,\n",
       "   'parent_id': 'b841779d95fb90f4d9e00d3445cc7112',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'a694abcba154d7e0f16411f0976b65e5',\n",
       "  'text': '3 METHOD',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 3,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'c08ecef591c8414a37d06432293d11ee',\n",
       "  'text': 'In order to endow Large Language Models with multimodal generation capabilities, we introduce a new framework that integrates pretrained multimodal Large Language Models and text-to-image generation models. Central to our approach is the introduction of “generative vokens”, special visual tokens that effectively bridge the textual and visual domains during the training process. Addition- ally, we implement a two-stage training method combined with a classifier-free guidance strategy to enhance the quality and coherence of generated outputs. Fig. 2 provides an overview of our model structure. MiniGPT-5 primarily consists of two modules: the Integrated Vision-Language Encod- ing Module, utilizing the pretrained multimodal large language model (MiniGPT-4) for handling multimodal inputs, and the Multimodal Output Generation module, employing Stable Diffusion for generating visual outputs.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': '.', 'url': 'figure.caption.2', 'start_index': 549}],\n",
       "   'page_number': 3,\n",
       "   'parent_id': 'a694abcba154d7e0f16411f0976b65e5',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '4cd6157fb0434cf5b78c33f16e886688',\n",
       "  'text': 'Recent advancements in multimodal Large Language Models, such as MiniGPT-4 (Zhu et al., 2023), have primarily concentrated on multimodal comprehension, enabling the processing of images as sequential input. The Integrated Vision-Language Encoding Module is designed to extend the capa- bilities of LLMs from mere comprehension to active generation in multimodal contexts. Generative',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Zhuetal .,',\n",
       "     'url': 'cite.zhu2023minigpt',\n",
       "     'start_index': 76},\n",
       "    {'text': '2023', 'url': 'cite.zhu2023minigpt', 'start_index': 88}],\n",
       "   'page_number': 3,\n",
       "   'parent_id': 'a694abcba154d7e0f16411f0976b65e5',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '621f732f140493538c8f62721e025ad4',\n",
       "  'text': '3.1 MULTIMODAL UNDERSTANDING MODULE',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 3,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Footer',\n",
       "  'element_id': '4e07408562bedb8b60ce05c1decfe3ad',\n",
       "  'text': '3',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 3,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '10b1f6a1b0b515502e58ebbd843ac9a9',\n",
       "  'text': '\"A discus gotstuck up on theroof.\"',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '11d2c29f8b8f0129b92a3f3538c52c24',\n",
       "  'text': 'TransformerDecoder',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '2b5b1f45790b9882d4f9e3f5aa9fbd8e',\n",
       "  'text': 'Linear LayerVoken Features',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '32b7f87982e4e680386ba9ffad76b4eb',\n",
       "  'text': 'TextTokenizer',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '489c85b8190daa50b7704c6411191385',\n",
       "  'text': 'PEFT',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '4be5ba6bb93c77f95d571ae377b3025c',\n",
       "  'text': 'Learnable Queries',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '5197d3c54433ae1b75d526fbf61b6621',\n",
       "  'text': 'SDUnet',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '55e2e545bc2309ddcea8e0f490ac28d3',\n",
       "  'text': 'ImageEncoder',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '8da9e2f989f77d97523346ec9c04db58',\n",
       "  'text': 'TransformerEncoderFeature Mapper',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '92029c3bd7baa4ffc29397858a297bb5',\n",
       "  'text': 'Zt',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '977328c6a44e78eed86f423f7ec0df1b',\n",
       "  'text': '\"Why not try getting it down with a soccerball? [IMG 1] ... [IMG n]\"',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'parent_id': '92029c3bd7baa4ffc29397858a297bb5',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '9ada8e83c1186cd632fb2ac8195abc11',\n",
       "  'text': 'Noise',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'ae35cf8d69f4652fbe9dc56e5e19907f',\n",
       "  'text': 'SD ImageEncoder',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'b9b3d33f80c1dfea793abe269bc4b07d',\n",
       "  'text': 'VokenPositioningLossVokenAlignmentLossGT Output TextMultimodal InputGT Output Image',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'bbeebd879e1dff6918546dc0c179fdde',\n",
       "  'text': 'Z',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'ed6bb5cba943b4cf4134f1d3b271248d',\n",
       "  'text': 'LLM (Vicuna)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'f3eb07f6868904e42886b860ef4218c0',\n",
       "  'text': 'EstimatedNoise',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'fa9f0eeed0805f46f3480f48fec20f6e',\n",
       "  'text': 'Output Hidden State',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'cb76fc605b58fcc6e79316ecab4748b4',\n",
       "  'text': 'Figure 2: The overview structure of MiniGPT-5 pipeline. We leverage the pretrained multimodal large language model (MiniGPT-4) and text-to-image generation model (Stable Diffusion 2.1) to create a unified multimodal generation pipeline. The input image encoder includes a ViT, Qformer, and linear layer, pretrained by MiniGPT-4. The orange blocks include learnable parameters, while the blue blocks are fixed during training. More details can be found in Section 3.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'parent_id': 'fa9f0eeed0805f46f3480f48fec20f6e',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '4f418181e3383f64ceb719d5cd72d548',\n",
       "  'text': 'vokens play a crucial role in this module, enabling the translation of raw visual inputs into a format that LLMs can process and utilize for subsequent generation tasks.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'parent_id': 'fa9f0eeed0805f46f3480f48fec20f6e',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '18e24963d1b854f5dd25e3aecfe6bbcb',\n",
       "  'text': 'Multimodal Encoding Each text token is embedded into a vector etext ∈ Rd, while the pretrained visual encoder transforms each input image into the feature eimg ∈ R32×d. These embeddings are concatenated to create the input prompt features.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'parent_id': 'fa9f0eeed0805f46f3480f48fec20f6e',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '845f88054f9e77f50cb170d00dd73301',\n",
       "  'text': 'Generative Vokens Since the original LLM’s V vocabulary only includes the textual tokens, we need to construct a bridge between the LLM and the generative model. Therefore, we introduce a set of special tokens Vimg = {[IMG1], [IMG2], . . . , [IMGn]} (by default n = 8) as generative vokens into the LLM’s vocabulary V . The LLM’s output hidden state for these vokens is harnessed for subsequent image generation, and the positions of these vokens can represent the insertion of the in- terleaved images. With all pretrained weights θpretrained in MiniGPT-4 fixed, the trainable parameters include extra input embedding θvoken input and output embedding θvoken output.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'parent_id': 'fa9f0eeed0805f46f3480f48fec20f6e',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'b69f4fadb030e84ad561297aa1b45b7c',\n",
       "  'text': 'Parameter-Efficient Fine-Tuning (PEFT) Parameter-efficient fine-tuning (PEFT) (Houlsby et al., 2019; Hu et al., 2021; Li & Liang, 2021) is critical in training Large Language Models (LLMs), employed to adapt LLMs to downstream tasks without the need for extensive retraining. In PEFT, rather than updating all the parameters of a model, only a small subset of parameters is trained. This subset typically includes task-specific components or lightweight layers added to the original model architecture (Zhang et al., 2021; Houlsby et al., 2019; Hu et al., 2021; Dettmers et al., 2023). We apply PEFT to the MiniGPT-4 (Zhu et al., 2023) encoder, enhancing its ability to process and generate multimodal content based on given instructions or prompts. More specifically, this involves the use of prefix tuning (Li & Liang, 2021) and LoRAHu et al. (2021) over the entire language encoder – Vicuna (Chiang et al., 2023) used in MiniGPT-4. Additionally, we implement learnable queries at the input of the transformer decoder, a conventional approach in sequence-to-sequence transformer architectures, to further improve the model’s multimodal generation capabilities. We also adopted learnable queries at the input of the transformer decoder as a conventional setting for sequence-to-sequence transformer architectures (Vaswani et al., 2017a). Learnable queries in the decoder allow the model to have dynamic, adaptable representations for initiating the generation process. This is particularly useful when the model needs to generate outputs based on a mix of visual and textual inputs. Combined with the instruction tuning (Ouyang et al., 2022), it notably amplifies multimodal generation performance across various datasets.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Houlsbyetal',\n",
       "     'url': 'cite.houlsby2019parameter',\n",
       "     'start_index': 76},\n",
       "    {'text': '2019', 'url': 'cite.houlsby2019parameter', 'start_index': 92},\n",
       "    {'text': 'Huetal .,', 'url': 'cite.hu2021lora', 'start_index': 98},\n",
       "    {'text': '2021', 'url': 'cite.hu2021lora', 'start_index': 109},\n",
       "    {'text': 'Li & Liang', 'url': 'cite.li2021prefix', 'start_index': 115},\n",
       "    {'text': '2021', 'url': 'cite.li2021prefix', 'start_index': 127},\n",
       "    {'text': 'Zhangetal .,', 'url': 'cite.tip_adapter', 'start_index': 499},\n",
       "    {'text': '2021', 'url': 'cite.tip_adapter', 'start_index': 513},\n",
       "    {'text': 'Houlsbyetal .,',\n",
       "     'url': 'cite.houlsby2019parameter',\n",
       "     'start_index': 519},\n",
       "    {'text': '2019', 'url': 'cite.houlsby2019parameter', 'start_index': 535},\n",
       "    {'text': 'Huetal .,', 'url': 'cite.hu2021lora', 'start_index': 541},\n",
       "    {'text': '2021', 'url': 'cite.hu2021lora', 'start_index': 552},\n",
       "    {'text': 'Dettmersetal .,',\n",
       "     'url': 'cite.dettmers2023qlora',\n",
       "     'start_index': 558},\n",
       "    {'text': '2023', 'url': 'cite.dettmers2023qlora', 'start_index': 575},\n",
       "    {'text': 'Zhuetal .,', 'url': 'cite.zhu2023minigpt', 'start_index': 614},\n",
       "    {'text': '2023', 'url': 'cite.zhu2023minigpt', 'start_index': 626},\n",
       "    {'text': 'Li & Liang', 'url': 'cite.li2021prefix', 'start_index': 803},\n",
       "    {'text': '2021', 'url': 'cite.li2021prefix', 'start_index': 815},\n",
       "    {'text': '-', 'url': 'cite.hu2021lora', 'start_index': 925},\n",
       "    {'text': '2021', 'url': 'cite.hu2021lora', 'start_index': 840},\n",
       "    {'text': 'Chiangetal .,', 'url': 'cite.vicuna2023', 'start_index': 889},\n",
       "    {'text': '2023', 'url': 'cite.vicuna2023', 'start_index': 904},\n",
       "    {'text': 'Vaswanietal .,', 'url': 'cite.transformer', 'start_index': 1309},\n",
       "    {'text': '2017a', 'url': 'cite.transformer', 'start_index': 1325},\n",
       "    {'text': 'Ouyangetal .,', 'url': 'cite.training_lm', 'start_index': 1616},\n",
       "    {'text': '2022', 'url': 'cite.training_lm', 'start_index': 1631}],\n",
       "   'page_number': 4,\n",
       "   'parent_id': 'fa9f0eeed0805f46f3480f48fec20f6e',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Footer',\n",
       "  'element_id': '4b227777d4dd1fc61c6f884f48641d02',\n",
       "  'text': '4',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 4,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '35ad4b2d88b9b6b1cf0668c4f69f829a',\n",
       "  'text': '3.2 MUTIMODAL GENERATION MODULE',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '284c7be36f3dd00a66013b1884aedbf7',\n",
       "  'text': 'To accurately align the generative vokens with the text-to-image generation models, we formulate a compact mapping module for dimension matching and incorporate several supervised losses, includ- ing voken positioning loss and voken alignment loss. The voken positioning loss assists the model in learning the correct positioning of tokens, while the voken alignment loss directly aligns the vo- kens with the appropriate conditional generation features of the diffusion model. Since the gradients of generative vokens’ features can be directly calculated from images, shown on the right side of Fig. 2, our method does not need comprehensive descriptions of images, leading to description-free learning.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': '2', 'url': 'figure.caption.2', 'start_index': 601}],\n",
       "   'page_number': 5,\n",
       "   'parent_id': '35ad4b2d88b9b6b1cf0668c4f69f829a',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '5550bbfe7ae4e71b5962bcf16c1d9659',\n",
       "  'text': 'Voken Positioning We first jointly generate both text and vokens in the text space by follow- ing next-word prediction in autoregressive language model (Vaswani et al., 2017b). During the training, we append the vokens Vimg to the positions of ground truth images and train the model to predict vokens within text generation. Specifically, the generated tokens are represented as W = {w1, w2, . . . , wm}, where wi ∈ V ∪ Vimg, and the causal language modeling loss is defined as:',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Vaswanietal .,',\n",
       "     'url': 'cite.vaswani2017attention',\n",
       "     'start_index': 152},\n",
       "    {'text': '2017b', 'url': 'cite.vaswani2017attention', 'start_index': 168}],\n",
       "   'page_number': 5,\n",
       "   'parent_id': '35ad4b2d88b9b6b1cf0668c4f69f829a',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '7e94e2aeec2553b8b9ec545aa2f221da',\n",
       "  'text': 'Ltext := −',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'aa8c521d05bdbbfb56c7c2b7bfecb7c5',\n",
       "  'text': 'm (cid:88)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'parent_id': '7e94e2aeec2553b8b9ec545aa2f221da',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '8ed5f55df7e976aa56d3cbf5ac59e5eb',\n",
       "  'text': 'logp(wi|etext, eimg, w1, . . . , wi−1;',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '3762bf925b6f0e5b69f0ab26eb347bd6',\n",
       "  'text': 'i=1',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'parent_id': '8ed5f55df7e976aa56d3cbf5ac59e5eb',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '2942176dcfedc6c9c70ca4cce9838c48',\n",
       "  'text': 'θpretrained, θvoken input, θvoken output), where wi ∈ V ∪ Vimg',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'parent_id': '8ed5f55df7e976aa56d3cbf5ac59e5eb',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '6aaacd9f9e2028dfb27c4131a2876f32',\n",
       "  'text': 'Voken Alignment for Image Generation Next, we align the output hidden state hvoken, shown in Fig. 2, with the conditional feature space of the text-to-image generation model. To map the voken feature hvoken to a feasible image generation conditional feature etext encoder ∈ RL× ˆd (where L is the maximum input length of text-to-image generation text encoder, and ˆd is the dimension of encoder output feature in text-to-image generation model). We construct a feature mapper module, including a two-layer MLP model θMLP, a four-layer encoder-decoder transformer model θenc-dec, and a learnable decoder feature sequence q. The mapping feature ˆhvoken is then given by:',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': '2', 'url': 'figure.caption.2', 'start_index': 98}],\n",
       "   'page_number': 5,\n",
       "   'parent_id': '8ed5f55df7e976aa56d3cbf5ac59e5eb',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '10d5cca801335bb5d82b99de19dca678',\n",
       "  'text': 'ˆhvoken := θenc-dec(θMLP(hvoken), q) ∈ RL× ˆd',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'parent_id': '8ed5f55df7e976aa56d3cbf5ac59e5eb',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'df956ff68f91809eb4e016cb44d9e596',\n",
       "  'text': 'To generate appropriate images, the mapping feature ˆhvoken is used as a conditional input in the denoising process. Intuitively, ˆhvoken should represent the corresponding conditional features that conduct the diffusion model to generate the ground truth image. We employ the latent diffusion model (LDM) loss as voken alignment loss for training the image generation module. During the training, the ground truth image is first converted to latent feature z0 through the pretrained VAE (Variational Autoencoder) (Kingma & Welling, 2013). Then, we obtain the noisy latent feature zt by adding noise ϵ to z0. A pretrained U-Net model ϵθ is used to calculate the conditional LDM loss as: (cid:20)(cid:13) (cid:13) (cid:13)ϵ − ϵθ',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Kingma & Welling',\n",
       "     'url': 'cite.vae',\n",
       "     'start_index': 514},\n",
       "    {'text': '2013', 'url': 'cite.vae', 'start_index': 532}],\n",
       "   'page_number': 5,\n",
       "   'parent_id': '8ed5f55df7e976aa56d3cbf5ac59e5eb',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'a84525e6c73d6a7e8f9eae1c15a94717',\n",
       "  'text': '(cid:21)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'parent_id': '8ed5f55df7e976aa56d3cbf5ac59e5eb',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'b7c91fd010238e0c5ead2bfc2e85d981',\n",
       "  'text': '(cid:17)(cid:13) 2 (cid:13) (cid:13) 2',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'parent_id': '8ed5f55df7e976aa56d3cbf5ac59e5eb',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'ba17d9e81390ecd77cf7542d02d5402b',\n",
       "  'text': '(cid:16)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'parent_id': '8ed5f55df7e976aa56d3cbf5ac59e5eb',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '4879ea55709b1e72c9a339b4a1d41e17',\n",
       "  'text': 'zt, t, ˆhvoken',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'parent_id': '8ed5f55df7e976aa56d3cbf5ac59e5eb',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'afcdc60f3537d95d0d019fff2519134f',\n",
       "  'text': 'LLDM := Eϵ∼N (0,1),t',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'parent_id': '8ed5f55df7e976aa56d3cbf5ac59e5eb',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '091f32993f9d9be8c17c1b72c0e591fb',\n",
       "  'text': 'To summarize, the voken positioning loss enables the model to learn the accurate placement of tokens. Without this component, the model lacks the essential capability to predict when vokens should be generated during inference. Additionally, the voken alignment loss ensures the direct correspondence between vokens and the appropriate conditional generation characteristics of the diffusion model. In the absence of this loss, the model is unable to learn semantic vokens from images directly. This comprehensive approach ensures a coherent understanding and generation of both textual and visual elements, leveraging the capabilities of pretrained models, specialized tokens, and innovative training techniques.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'parent_id': '8ed5f55df7e976aa56d3cbf5ac59e5eb',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'f3a5c4c54a08165e043096fc69b830b3',\n",
       "  'text': '3.3 TRAINING STRATEGY',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'd16feb0593ce1e0f07e83bbdb108e072',\n",
       "  'text': 'Given the non-negligible domain shift between text and image domains, we observe that direct training on a limited interleaved text-and-image dataset can result in misaligning generated texts',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'parent_id': 'f3a5c4c54a08165e043096fc69b830b3',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'fd0ad9026eee596b7072a762941f60be',\n",
       "  'text': '(1)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'parent_id': 'f3a5c4c54a08165e043096fc69b830b3',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '0e77e68ba5473d98840c3212f4a8cb80',\n",
       "  'text': '(2)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'parent_id': 'f3a5c4c54a08165e043096fc69b830b3',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '46f789d1efeefad080846917a6a4a761',\n",
       "  'text': '(3)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'parent_id': 'f3a5c4c54a08165e043096fc69b830b3',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Footer',\n",
       "  'element_id': 'ef2d127de37b942baad06145e54b0c61',\n",
       "  'text': '5',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 5,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'd2ea6c30a691f1c14f2db565488d7858',\n",
       "  'text': 'and images and diminished image quality. Consequently, we adopt a two-stage training strategy: an initial pretraining stage focusing on coarse feature alignment for unimodal generation, followed by a fine-tuning stage dedicated to intricate feature learning for multimodal generation. Furthermore, to amplify the effectiveness of the generative tokens throughout the diffusion process, we incorporate the idea of classifier-free guidance (Ho & Salimans, 2022) technique through the whole training process.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Ho & Salimans',\n",
       "     'url': 'cite.classifier_free_guidance',\n",
       "     'start_index': 437},\n",
       "    {'text': '2022',\n",
       "     'url': 'cite.classifier_free_guidance',\n",
       "     'start_index': 452}],\n",
       "   'page_number': 6,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'cc20e3962f9598e6c680e766ad9aebf0',\n",
       "  'text': 'Two-stage Training Strategy Recognizing the non-trivial domain shift between pure-text gener- ation and text-image generation, we propose a two-stage training strategy: Pretraining Stage and Fine-tuning Stage. Initially, we align the voken feature with image generation features in single text-image pair datasets, such as CC3M, where each data sample only contains one text and one im- age, and the text is usually the caption of the image. During this stage, we utilize captions as LLM input, enabling LLM to generate vokens. Since these datasets include the image descriptive infor- mation, we also introduce an auxiliary loss to aid voken alignment, minimizing the distance between the generative feature ˆhvoken and the caption feature from the text encoder τθ in the text-to-image generation model:',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '3eb8d5fc4cbe455c02cb0b93a7463e3f',\n",
       "  'text': 'LCAP := MSE(ˆhvoken, τθ(c)) The pretraining stage loss is expressed as LPretrain = λ1 ∗Ltext +λ2 ∗LLDM +λ3 ∗LCAP, with selected values λ1 = 0.01, λ2 = 1, λ3 = 0.1 to rescale the loss into a similar numerical range.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'a49997a8730c08c7b3fd3ec137bc5a73',\n",
       "  'text': 'After the pretraining stage, the model is capable of generating images for single text descriptions but struggles with interleaved vision-and-language generation, which includes multiple text-image pairs and requires complicated reasoning for both text and image generation. To address this, in the fine-tuning stage, we further fine-tune our model with PEFT parameters by interleaved vision- and-language datasets, such as VIST, where the data sample has several steps with text-image and texts are sequentially relevant. During this stage, we construct three types of tasks from the dataset, encompassing (1) text-only generation: given the next image, generating the related text; (2) image- only generation: given the next text, generating the related image, and (3) multimodal generation: generating text-image pair by given context. The fine-tuning stage loss is given by LFine-tune = λ1 ∗ Ltext + λ2 ∗ LLDM. More implementation details can be found in Appendix A.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'multimodalgeneration generatingtext - imagepairbygivencontext . Thefine - tuningstagelossisgivenbyLFine - tune λ1 ∗ Ltext + λ2 ∗ LLDM . MoreimplementationdetailscanbefoundinAppendixA',\n",
       "     'url': 'appendix.A',\n",
       "     'start_index': 769}],\n",
       "   'page_number': 6,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '7d407ad1fe53af0b4f9c5cb4370417d3',\n",
       "  'text': 'Classifier-Free Guidance (CFG) To enhance the coherence between the generated text and im- ages, we first leverage the idea of Classifier-free Guidance for multimodal generation. Classifier- free guidance is introduced in the text-to-image diffusion process. This method observes that the generation model Pθ can achieve improved conditional results by training on both conditional and unconditional generation with conditioning dropout. In our context, we want the model to focus directly on the output features hvoken from LLM. Instead of using original stable diffusion uncondi- tional distributions (dropping ˆhvoken), the whole feature mapper also needs to be included during the unconditional process. Therefore, our objective is to accentuate the trainable condition hvoken and the generation model is fixed. During training, we replace hvoken with zero features h0 ∈ 0n×d with a 10% probability, obtaining the unconditional feature ˆh0 = θenc-dec(θMLP(h0), q). During inference, ˆh0 serves as negative prompting, and the refined denoising process is:',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'cbe3b52ccdb46fd15e9f52b372fc95b5',\n",
       "  'text': '(4)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '97ce6126f9bad63aac5ddf4679f0612c',\n",
       "  'text': '(5)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'ba17d9e81390ecd77cf7542d02d5402b',\n",
       "  'text': '(cid:16)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '2244cbd6a8f540a402e0e7a291285607',\n",
       "  'text': 'log (cid:99)Pθ (cid:16)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'adbccba1f4f9f51c98fb2bcaff038706',\n",
       "  'text': 'γ',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'ed058146bab545d3120c2fdf46134680',\n",
       "  'text': 'log Pθ',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '6ecd1d94bfac201a342d8efa4cae843b',\n",
       "  'text': '(cid:17)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'parent_id': 'ed058146bab545d3120c2fdf46134680',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'fa0ef9607fdc9c0a5485ffee93f54678',\n",
       "  'text': '= log Pθ (cid:16)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '0e09f902051a2cc9afb93cdaba4080ff',\n",
       "  'text': '− log Pθ',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'ba17d9e81390ecd77cf7542d02d5402b',\n",
       "  'text': '(cid:16)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'parent_id': '0e09f902051a2cc9afb93cdaba4080ff',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '16201aee4ebe86529c09bb6e19379da9',\n",
       "  'text': 'ϵt | zt+1, ˆh0',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '16201aee4ebe86529c09bb6e19379da9',\n",
       "  'text': 'ϵt | zt+1, ˆh0',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '6ecd1d94bfac201a342d8efa4cae843b',\n",
       "  'text': '(cid:17)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'parent_id': '16201aee4ebe86529c09bb6e19379da9',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '6a1f93315ec0650adf9a35b40571aecd',\n",
       "  'text': '(cid:17)(cid:17)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'parent_id': '16201aee4ebe86529c09bb6e19379da9',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'a318c24216defe206feeb73ef5be0003',\n",
       "  'text': '+',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'parent_id': '16201aee4ebe86529c09bb6e19379da9',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'cad8ea75d9eb562da24b75d67277d806',\n",
       "  'text': 'ϵt | zt+1, ˆhvoken, ˆh0 (cid:17) (cid:16)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '440d337b184e9983ae2a1df67ac76d43',\n",
       "  'text': 'ϵt | zt+1, ˆhvoken',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'parent_id': 'cad8ea75d9eb562da24b75d67277d806',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '4f26edd0d82502405db1ff3abbac5d95',\n",
       "  'text': '4 EXPERIMENTS',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '0aab5cea3fbf4cabf5c85c142d700299',\n",
       "  'text': 'To assess the efficacy of our model, we conducted a series of evaluations across multiple bench- marks. These experiments aim to address several key questions: (1) Can our model generate plausi- ble images and reasonable texts? (2) How does our model compare with state-of-the-art models in both single-turn and multi-turn interleaved vision-and-language generation tasks? (3) What impact does the design of each module have on overall performance? Below we will discuss the experimen- tal setup and present a comprehensive analysis of our model’s performance. We use three datasets: CC3M (Sharma et al., 2018), VIST (Huang et al., 2016), and MMDialog (Feng et al., 2022). More details about datasets and data format can be found in Appendix B.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Sharmaetal .,',\n",
       "     'url': 'cite.sharma2018conceptual',\n",
       "     'start_index': 589},\n",
       "    {'text': '2018', 'url': 'cite.sharma2018conceptual', 'start_index': 604},\n",
       "    {'text': 'Huangetal .,',\n",
       "     'url': 'cite.huang2016visual',\n",
       "     'start_index': 617},\n",
       "    {'text': '2016', 'url': 'cite.huang2016visual', 'start_index': 631},\n",
       "    {'text': 'Fengetal .,',\n",
       "     'url': 'cite.feng2022mmdialog',\n",
       "     'start_index': 652},\n",
       "    {'text': '2022', 'url': 'cite.feng2022mmdialog', 'start_index': 665},\n",
       "    {'text': 'sperformance . Weusethreedatasets CC3M ( Sharmaetal ., 2018 ), VIST ( Huangetal ., 2016 ), andMMDialog ( Fengetal ., 2022 ). detailsaboutdatasetsanddataformatcanbefoundinAppendixB',\n",
       "     'url': 'appendix.B',\n",
       "     'start_index': 545}],\n",
       "   'page_number': 6,\n",
       "   'parent_id': '4f26edd0d82502405db1ff3abbac5d95',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Footer',\n",
       "  'element_id': 'e7f6c011776e8db7cd330b54174fd76f',\n",
       "  'text': '6',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 6,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'dc5e4619a4e67f99db6c5d6f5be5f784',\n",
       "  'text': 'Table 1: Image generation on VIST. Given the historical context, models need to generate im- ages for each step. FID scores evaluate the vi- sual diversities between generated and ground truth images within each story sequence.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "  'text': 'Model',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'ff6f0ce218ddf400a85e5e6aca5f7789',\n",
       "  'text': 'CLIP-I (↑)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'parent_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '0d6339d2b85b7d5ad6801154a96ace83',\n",
       "  'text': 'FID (↓)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'parent_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '3a6e05ee6e5027f1c02c483ce0ec60ac',\n",
       "  'text': 'SD 2.1 (Rombach et al., 2022b) Fine-tuned SD 2.1 Two-stage Baseline GILL (Koh et al., 2023) MiniGPT-5 (Prefix Tuning) MiniGPT-5 (LoRA)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Rombachetal .,',\n",
       "     'url': 'cite.rombach2021highresolution',\n",
       "     'start_index': 8},\n",
       "    {'text': '2022b',\n",
       "     'url': 'cite.rombach2021highresolution',\n",
       "     'start_index': 24},\n",
       "    {'text': 'Kohetal .,', 'url': 'cite.koh2023generating', 'start_index': 74},\n",
       "    {'text': '2023', 'url': 'cite.koh2023generating', 'start_index': 86}],\n",
       "   'page_number': 7,\n",
       "   'parent_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '45660126e2517ac25eb6fbae06b0c87e',\n",
       "  'text': '0.59 0.61 0.57 0.60 0.65 0.66',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'parent_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'e857551f95b9a9224c4784e28d06a037',\n",
       "  'text': '393.49 390.25 403.06 381.88 381.55 366.62',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'parent_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'b811f358a7d2015057ffeef8c06f5e84',\n",
       "  'text': 'Table 2: Narration Generation on VIST. We added LoRA fine-tuning for GILL, MiniGPT- 4, and MiniGPT-5 with the same LoRA config- uration. The results show that adding genera- tive vokens does not hurt the performance on the multimodal comprehension tasks.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'parent_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "  'text': 'Model',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '4de783274939a1bfba725362ac5869e4',\n",
       "  'text': 'S-BERT (↑) Rouge-L (↑) Meteor (↑)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'd103f3454708dddb70a6e2feae2cc2de',\n",
       "  'text': 'GILL (Koh et al., 2023) MiniGPT-4 (Zhu et al., 2023) MiniGPT-5',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Zhuetal .,',\n",
       "     'url': 'cite.zhu2023minigpt',\n",
       "     'start_index': 35},\n",
       "    {'text': '2023', 'url': 'cite.zhu2023minigpt', 'start_index': 47}],\n",
       "   'page_number': 7,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '40437008c91591c8d26c77b505b3d2a7',\n",
       "  'text': '0.3864 0.6273 0.6315',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'parent_id': 'd103f3454708dddb70a6e2feae2cc2de',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '1d0fc6c8b66a2c86bfb2d1f325fbcd94',\n",
       "  'text': '0.1784 0.3401 0.3373',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'parent_id': 'd103f3454708dddb70a6e2feae2cc2de',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'c73776212623012eca79e471ddf9ef9e',\n",
       "  'text': '0.1951 0.3296 0.3263',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'parent_id': 'd103f3454708dddb70a6e2feae2cc2de',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '915c956b56eac6aaf7eaf34e617bca39',\n",
       "  'text': '4.1 EXPERIMENTAL SETUP',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '8f66419e3a9782ec5a789d3b5b6d32a6',\n",
       "  'text': 'Baselines For a comprehensive evaluation of our performance in multimodal generation, we con- the Fine-tuned Unimodal ducted comparative analyses with several prominent baseline models: Generation Models, Two-stage Baseline, GILL, and Divter.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'parent_id': '915c956b56eac6aaf7eaf34e617bca39',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '363834972355ed636ca42fe3a6f44b1b',\n",
       "  'text': 'Fine-tuned Unimodal Generation Models: To facilitate fair comparisons in both image and text generation, we fine-tuned two separate models, Stable Diffusion 2.1 and MiniGPT- 4 (Zhu et al., 2023), utilizing the VIST dataset. Within the Stable Diffusion 2.1 (Rombach et al., 2022b) model, the U-Net parameters were fine-tuned. For MiniGPT-4’s LLM part, LoRA parameters were fine-tuned.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Zhuetal .,',\n",
       "     'url': 'cite.zhu2023minigpt',\n",
       "     'start_index': 178},\n",
       "    {'text': '2023', 'url': 'cite.zhu2023minigpt', 'start_index': 190},\n",
       "    {'text': '( etal ., 2022b ) model , theU - Netparameterswerefine - tuned . ForMiniGPT - 4 ’ sLLMpart',\n",
       "     'url': 'cite.rombach2021highresolution',\n",
       "     'start_index': 257},\n",
       "    {'text': 'etal .,',\n",
       "     'url': 'cite.rombach2021highresolution',\n",
       "     'start_index': 266},\n",
       "    {'text': '2022b',\n",
       "     'url': 'cite.rombach2021highresolution',\n",
       "     'start_index': 274}],\n",
       "   'page_number': 7,\n",
       "   'parent_id': '915c956b56eac6aaf7eaf34e617bca39',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '36c9a59391878be8209a1aa14b108c51',\n",
       "  'text': 'Two-stage Baseline: A common approach in multimodal generation involves first employ- ing Large Language Models (LLMs) to create image captions, which are then fed into text-to-image models for image generation (Wu et al., 2023b). We create such a two-stage baseline for comparison with our end-to-end method by fine-tuning MiniGPT-4 for caption generation and Stable Diffusion 2.1 for text-to-image generation. Given the absence of image descriptions in the VIST dataset, we incorporate a SOTA image captioning model, InstructBLIP-13B (Dai et al., 2023), to generate synthetic captions for supervision.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Wuetal .,',\n",
       "     'url': 'cite.wu2023visual',\n",
       "     'start_index': 213},\n",
       "    {'text': '2023b', 'url': 'cite.wu2023visual', 'start_index': 224},\n",
       "    {'text': 'Daietal .,', 'url': 'cite.instructblip', 'start_index': 537},\n",
       "    {'text': '2023', 'url': 'cite.instructblip', 'start_index': 549}],\n",
       "   'page_number': 7,\n",
       "   'parent_id': '915c956b56eac6aaf7eaf34e617bca39',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': 'f92ddb5c7a68864cad6e3bd3a34ad193',\n",
       "  'text': 'GILL1 (Koh et al., 2023): GILL is a recent innovation that allows the LLM to generate vokens using a pre-trained text-to-image generation model for single-image generation, where GILL minimizes the Mean Squared Error (MSE) loss between the text-to-image text encoding feature and voken features, similar to LCAP in our approach. For fine-tuning on multimodal datasets, since GILL requires image captions for training, we use Descriptions of Images-in-Isolation (DII) (Huang et al., 2016) in the VIST fine-tuning and generate captions for MMDialog fine-tuning. Contrarily, MiniGPT-5 does not related on all caption data during multimodal generation fine-tuning.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': '(', 'url': 'Hfootnote.1', 'start_index': 8},\n",
       "    {'text': 'Kohetal .,', 'url': 'cite.koh2023generating', 'start_index': 9},\n",
       "    {'text': '2023', 'url': 'cite.koh2023generating', 'start_index': 21},\n",
       "    {'text': 'Huangetal .,',\n",
       "     'url': 'cite.huang2016visual',\n",
       "     'start_index': 469},\n",
       "    {'text': '2016', 'url': 'cite.huang2016visual', 'start_index': 483}],\n",
       "   'page_number': 7,\n",
       "   'parent_id': '915c956b56eac6aaf7eaf34e617bca39',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '81a291d0ce51b079ecbb44df8d1e05ef',\n",
       "  'text': 'Divter (Sun et al., 2021): Divter is a state-of-the-art conversational agent developed for multimodal dialogue contexts. It introduces a customized transformer structure for gener- ating multimodal responses. Divter’s methodology includes pretraining on a vast corpus of text-only dialogues and text-image pairs, followed by fine-tuning on a selected set of multimodal response data. The MMDialog dataset regards Divter’s method as the baseline.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Sunetal .,',\n",
       "     'url': 'cite.sun2021multimodal',\n",
       "     'start_index': 10},\n",
       "    {'text': '2021', 'url': 'cite.sun2021multimodal', 'start_index': 22}],\n",
       "   'page_number': 7,\n",
       "   'parent_id': '915c956b56eac6aaf7eaf34e617bca39',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'c71a8464f7e4bbc1905fd28dd0a15e83',\n",
       "  'text': 'Metrics To comprehensively assess the model performance across image, text, and multimodal dimensions, we employ a diverse set of metrics. For evaluating the quality and diversity of generated images, we utilize the Inception Score (IS) (Salimans et al., 2016), and Fr´echet Inception Distance (FID) (Heusel et al., 2017). Textual performance is gauged through metrics such as BLEU (Papineni et al., 2002), Rouge-L (Lin, 2004), METEOR (Banerjee & Lavie, 2005), and Sentence-BERT (S- BERT) (Reimers & Gurevych, 2019) scores.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Salimansetal .,',\n",
       "     'url': 'cite.salimans2016improved',\n",
       "     'start_index': 238},\n",
       "    {'text': '2016', 'url': 'cite.salimans2016improved', 'start_index': 255},\n",
       "    {'text': 'Heuseletal .,',\n",
       "     'url': 'cite.heusel2017gans',\n",
       "     'start_index': 301},\n",
       "    {'text': '2017', 'url': 'cite.heusel2017gans', 'start_index': 316},\n",
       "    {'text': '( etal ., 2002 ), Rouge - L ( Lin , 2004 ), METEOR ( Banerjee & Lavie , 2005 ), andSentence - BERT ( S',\n",
       "     'url': 'cite.papineni2002bleu',\n",
       "     'start_index': 382},\n",
       "    {'text': 'etal .,', 'url': 'cite.papineni2002bleu', 'start_index': 392},\n",
       "    {'text': '2002', 'url': 'cite.papineni2002bleu', 'start_index': 400},\n",
       "    {'text': 'Lin', 'url': 'cite.lin2004rouge', 'start_index': 416},\n",
       "    {'text': '2004', 'url': 'cite.lin2004rouge', 'start_index': 421},\n",
       "    {'text': 'Banerjee & Lavie',\n",
       "     'url': 'cite.banerjee2005meteor',\n",
       "     'start_index': 436},\n",
       "    {'text': '2005', 'url': 'cite.banerjee2005meteor', 'start_index': 454},\n",
       "    {'text': 'Reimers & Gurevych',\n",
       "     'url': 'cite.reimers2019sentence',\n",
       "     'start_index': 490},\n",
       "    {'text': '2019', 'url': 'cite.reimers2019sentence', 'start_index': 510}],\n",
       "   'page_number': 7,\n",
       "   'parent_id': '915c956b56eac6aaf7eaf34e617bca39',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '9c2f2df2e3a24c942f517ee6f3e77608',\n",
       "  'text': 'From the multimodal perspective, we leverage CLIP-based metrics (Rombach et al., 2022b) to assess the similarities between generated content and ground truth. CLIP-I evaluates the similarity between',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Rombachetal .,',\n",
       "     'url': 'cite.rombach2021highresolution',\n",
       "     'start_index': 65},\n",
       "    {'text': '2022b',\n",
       "     'url': 'cite.rombach2021highresolution',\n",
       "     'start_index': 81}],\n",
       "   'page_number': 7,\n",
       "   'parent_id': '915c956b56eac6aaf7eaf34e617bca39',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '76ebab19a4d5f4df604d8b01cef1d378',\n",
       "  'text': '1Given the variations in the valid data within the CC3M dataset, we made adjustments to ensure fair com- parisons. Specifically, we retrained it on our specific CC3M data, following the guidelines in their official implementation (https://github.com/kohjingyu/gill).',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'parent_id': '915c956b56eac6aaf7eaf34e617bca39',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Footer',\n",
       "  'element_id': '7902699be42c8a8e46fbbb4501726517',\n",
       "  'text': '7',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 7,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '38c5f45d77014b3ba4e617ee51e2e38f',\n",
       "  'text': 'Table 3: Multimodal Story Generation. VIST Human Evaluation on 5,000 samples comparing MiniGPT-5 with both Two-stage Baseline and GILL, across Language Continuity, Image Quality, and Multimodal Coherence aspects. The results highlight the superiority of MiniGPT-5 in more than half cases.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '5d30640afdac84ac0ea06b85b734d180',\n",
       "  'text': 'Two-Stage Baseline',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '104a88ba97ba94cb46347d539be6f60e',\n",
       "  'text': 'GILL (Koh et al., 2023)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "  'text': 'Model',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '2659c5fab8f0d32d0ba69a75712f13b0',\n",
       "  'text': 'MiniGPT-5 Baseline',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '127f9c9b8aab555837e0d328bb6f8687',\n",
       "  'text': 'Tie MiniGPT-5 Baseline',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'a66eab2f9c529bfe2f3adcfd5ec310d6',\n",
       "  'text': 'Tie',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '2fcf6eece31ce7e248840647e1ba1c8e',\n",
       "  'text': 'Language Continuity (%) Image Quality (%) Multimodal Coherence (%)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '9d1b710a841983942fff7c968fbfab71',\n",
       "  'text': '55.22 52.43 56.90',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'parent_id': '2fcf6eece31ce7e248840647e1ba1c8e',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '51742d70ffff7360b292faa76162541b',\n",
       "  'text': '34.89 37.79 28.88',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'parent_id': '2fcf6eece31ce7e248840647e1ba1c8e',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'b8b02eb97691901f2412411ca98435d3',\n",
       "  'text': '9.89 9.78 14.22',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'parent_id': '2fcf6eece31ce7e248840647e1ba1c8e',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'fe9405cd417a813634ee96d74b15a151',\n",
       "  'text': '54.18 54.25 55.32',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'parent_id': '2fcf6eece31ce7e248840647e1ba1c8e',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '404eddc677cf23311a782fa38f0ef6d3',\n",
       "  'text': '35.31 35.41 30.34',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'parent_id': '2fcf6eece31ce7e248840647e1ba1c8e',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'bef9f8cdab465d57655b618909a95da0',\n",
       "  'text': '10.51 10.34 14.33',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'parent_id': '2fcf6eece31ce7e248840647e1ba1c8e',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'e24501686c28d2bd1c1529885a7fc40b',\n",
       "  'text': 'generated and ground-truth image features. To address potential misalignments in the multimodal generation, such as when the ground truth is text-only, but the output is multimodal, we utilize MM-Relevance (Feng et al., 2022). This metric calculates the F1 score based on CLIP similarities, providing a nuanced evaluation of multimodal coherence.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Fengetal .,',\n",
       "     'url': 'cite.feng2022mmdialog',\n",
       "     'start_index': 207},\n",
       "    {'text': '2022', 'url': 'cite.feng2022mmdialog', 'start_index': 220}],\n",
       "   'page_number': 8,\n",
       "   'parent_id': '2fcf6eece31ce7e248840647e1ba1c8e',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'b040e457325627e770282970439fcfa0',\n",
       "  'text': 'Recognizing that the generated multimodal output might be meaningful yet differ from the ground truth, we also incorporate human evaluation to assess the model’s performance. We examine the model’s effectiveness from three perspectives: (1) Language Continuity: assessing if the produced text aligns seamlessly with the provided context; (2) Image Quality: evaluating the clarity and rel- evance of the generated image; and (3) Multimodal Coherence: determining if the combined text- image output is consistent with the initial context.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'parent_id': '2fcf6eece31ce7e248840647e1ba1c8e',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'e8bb2c963827ca5b0e8880de55186354',\n",
       "  'text': '4.2 MAIN RESULTS',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '068405df19ee4c39230a793d52bbeef2',\n",
       "  'text': 'In this subsection, we present the performance of different models on the VIST (Huang et al., 2016) and MMDialg (Feng et al., 2022) datasets. Our evaluations span all vision, language, and multi- modality domains to showcase the versatility and robustness of the proposed models.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Huangetal .,',\n",
       "     'url': 'cite.huang2016visual',\n",
       "     'start_index': 80},\n",
       "    {'text': '2016', 'url': 'cite.huang2016visual', 'start_index': 94},\n",
       "    {'text': 'Fengetal .,',\n",
       "     'url': 'cite.feng2022mmdialog',\n",
       "     'start_index': 113},\n",
       "    {'text': '2022', 'url': 'cite.feng2022mmdialog', 'start_index': 126}],\n",
       "   'page_number': 8,\n",
       "   'parent_id': 'e8bb2c963827ca5b0e8880de55186354',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '194efb55089f1417c59949166ffca3f0',\n",
       "  'text': 'Unimodal Generation with Multimodal Input To evaluate the model performance on image gen- eration and text generation, we systematically provide models with prior history context and subse- quently assess the generated images and narrations at each following step. Tables 1 and 2 outline the results of these experiments on the VIST validation set, showing the performance in both image and language metrics, respectively. The findings demonstrate that MiniGPT-5 can generate coher- ent, high-quality images utilizing long-horizontal multimodal input prompts across all data, without compromising the original model’s ability for multimodal comprehension, indicating the efficacy of our model in diverse settings.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': '5cangeneratecoher',\n",
       "     'url': 'table.caption.3',\n",
       "     'start_index': 460},\n",
       "    {'text': ',', 'url': 'table.caption.3', 'start_index': 573}],\n",
       "   'page_number': 8,\n",
       "   'parent_id': 'e8bb2c963827ca5b0e8880de55186354',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '4438578f8fa460d8662eb992979daece',\n",
       "  'text': 'Multimodal Generation with Multimodal Input To assess the quality of multimodal generation, we test both our model and the baselines on the VIST validation set by human evaluation. Given a preceding multimodal sequence, models are tasked with producing the subsequent scenario for each task. We select a random sample of 5,000 sequences, with each requiring evaluation by two workers. These evaluators are tasked with determining the superior multimodal output based on three criteria: Language Continuity, Image Quality, and Multimodal Coherence. This assessment is facilitated using Amazon Mechanical Turk (Crowston, 2012), with a representative example (Fig. 4) provided in the Appendix. As depicted in Table 3, our model, MiniGPT-5, is found to generate more fitting text narrations in around 55% of instances, deliver superior image quality in around 53% of cases, and produce more coherent multimodal outputs in around 56% of the scenarios. This data distinctly showcases its enhanced multimodal generation capabilities compared to the two-stage baseline, which must generate intermediate image captions first.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Crowston',\n",
       "     'url': 'cite.crowston2012amazon',\n",
       "     'start_index': 609},\n",
       "    {'text': '2012', 'url': 'cite.crowston2012amazon', 'start_index': 619},\n",
       "    {'text': '4', 'url': 'figure.caption.11', 'start_index': 662},\n",
       "    {'text': ',', 'url': 'table.caption.4', 'start_index': 713}],\n",
       "   'page_number': 8,\n",
       "   'parent_id': 'e8bb2c963827ca5b0e8880de55186354',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '0f6f49e559c0664eb58c1cbf28043c0a',\n",
       "  'text': 'Multimodal Dialog Generation on MMDialog We conduct an evaluation of our method on the MMDialog dataset to determine the effectiveness of generating precise and appropriate multimodal information in multi-turn conversational scenarios. The model is required to generate either uni- modal or multimodal responses based on the previous turns during the conversations. Our results, as presented in Table 4, demonstrate that MiniGPT-5 outperforms the baseline model Divter in terms of generating more accurate textual responses. While the image qualities of the generated responses are similar, MiniGPT-5 excels in MM-Relevance compared to the baselines. This indicates that our',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': ',', 'url': 'table.caption.5', 'start_index': 402}],\n",
       "   'page_number': 8,\n",
       "   'parent_id': 'e8bb2c963827ca5b0e8880de55186354',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Footer',\n",
       "  'element_id': '2c624232cdd221771294dfbb310aca00',\n",
       "  'text': '8',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 8,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'e505ff8b668df5d73810c52ff5a7cc1d',\n",
       "  'text': 'Table 4: Multimodal generation results on MMDialog test set. In order to compare with their base- line, we use the same metrics reported in MMDialog (Feng et al., 2022).',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "  'text': 'Model',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '15d058fd08ebc2b2a0368cf49b714c54',\n",
       "  'text': 'IS (↑) BLEU-1 (↑) BLEU-2 (↑) Rouge-L (↑) MM-Relevance (↑)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '40415151e39a873053299d2f7977be18',\n",
       "  'text': 'Divter (Sun et al., 2021) GILL (Koh et al., 2023) MiniGPT-5',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Sunetal .,',\n",
       "     'url': 'cite.sun2021multimodal',\n",
       "     'start_index': 8},\n",
       "    {'text': '2021', 'url': 'cite.sun2021multimodal', 'start_index': 20},\n",
       "    {'text': 'Kohetal .,', 'url': 'cite.koh2023generating', 'start_index': 32},\n",
       "    {'text': '2023', 'url': 'cite.koh2023generating', 'start_index': 44}],\n",
       "   'page_number': 9,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'f447adeb5c93c8fb71b55765e0421488',\n",
       "  'text': '20.53 23.78 20.23',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'parent_id': '40415151e39a873053299d2f7977be18',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'e14a0874d6532cec14d77cb5da8b29c9',\n",
       "  'text': '0.0944 0.2912 0.3369',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'parent_id': '40415151e39a873053299d2f7977be18',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'b675ef180c9fb6769c47d4f3ffc9aea2',\n",
       "  'text': '0.0745 0.1945 0.2323',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'parent_id': '40415151e39a873053299d2f7977be18',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '2b2aff58b082cb5e2e080711c77b1155',\n",
       "  'text': '0.1119 0.1207 0.1176',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'parent_id': '40415151e39a873053299d2f7977be18',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '1184c286a82be400b67a7f90d0670c29',\n",
       "  'text': '0.62 0.64 0.67',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'parent_id': '40415151e39a873053299d2f7977be18',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'b6327a44fb7be4cf05914d301846d6e8',\n",
       "  'text': 'Table 5: Evaluation of different method designs for image generation qualities on the CC3M vali- dation set. The results show that all of our designs can help the model better align with the stable diffusion model in the pertaining stage.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'parent_id': '40415151e39a873053299d2f7977be18',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "  'text': 'Model',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'da310f3db024f5d0893f5bfee4a89d71',\n",
       "  'text': 'CLIP-I (↑) CLIP-T (↑)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'parent_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '1c014e95a75860c7f8724d8a2793f18c',\n",
       "  'text': 'IS (↑)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'parent_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '0d6339d2b85b7d5ad6801154a96ace83',\n",
       "  'text': 'FID (↓)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'parent_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'f1641b46c312d47a5f00322db1442dd0',\n",
       "  'text': 'MiniGPT-5 MiniGPT-5 (w/o CFG) MiniGPT-5 (w/o LCAP ) MiniGPT-5 (w/o LLDM )',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '687132481f383775ae290cad7a5b7b0a',\n",
       "  'text': '0.61 0.60 0.54 0.58',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'parent_id': 'f1641b46c312d47a5f00322db1442dd0',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '2f9623c1f0503cf097a736425daec348',\n",
       "  'text': '0.22 0.22 0.16 0.20',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'parent_id': 'f1641b46c312d47a5f00322db1442dd0',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'be91ecadb645d3767fee6d34c4aaf9f7',\n",
       "  'text': '28.09 23.41 21.27 24.79',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'parent_id': 'f1641b46c312d47a5f00322db1442dd0',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '9969ed244719c80ac9fa1ec163aedc0d',\n",
       "  'text': '31.47 33.73 40.24 34.65',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'parent_id': 'f1641b46c312d47a5f00322db1442dd0',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '205ccdb5f3f986dea0cc776aaa1cb8c1',\n",
       "  'text': 'model can better learn how to position image generation and produce highly coherent multimodal responses appropriately.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'parent_id': 'f1641b46c312d47a5f00322db1442dd0',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'f0cb7c6948d35f108f4ecd57926a2b8d',\n",
       "  'text': '4.3 ABLATION STUDIES',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '0414c3857473d38e2b58ce8d987b7916',\n",
       "  'text': 'To further evaluate the effectiveness of our design, we conducted several ablation studies, and more ablation studies can be found in Appendix C.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': ', weconductedseveralablationstudies , ablationstudiescanbefoundinAppendixC',\n",
       "     'url': 'appendix.C',\n",
       "     'start_index': 51}],\n",
       "   'page_number': 9,\n",
       "   'parent_id': 'f0cb7c6948d35f108f4ecd57926a2b8d',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'cd3e48556087518468ed130ee936e853',\n",
       "  'text': 'Evaluation of Classifier-Free Guidance (CFG) To assess the effectiveness of the CFG strategy, we trained our model without CFG dropoff. During inference, the model utilized the original CFG denoising process, which utilized the empty caption feature from Stable Diffusion’s text encoder as negative prompt features. The results in Table 5 demonstrate that all metrics are worse without CFG, indicating that the CFG training strategy improves the image generation quality.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Duringinference',\n",
       "     'url': 'table.caption.7',\n",
       "     'start_index': 135}],\n",
       "   'page_number': 9,\n",
       "   'parent_id': 'f0cb7c6948d35f108f4ecd57926a2b8d',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '86202d2a138f6026702b279967d5db3a',\n",
       "  'text': 'Evaluation of Different Loss Guidance As described in Sec. 3.3, we introduced an auxiliary loss, denoted as LCAP for CC3M training. To assess the impact of this loss and determine if the single caption loss alone can generate high-quality images like GILL, we trained our model without the caption loss LCAP (alignment between the mapped generative voken features and the caption fea- tures from stable diffusion text encoder) and the conditional latent diffusion loss LLDM (alignment between the mapped generative voken features and conditional features for latent diffusion process of ground truth images) separately. The results, as shown in Table 5, indicate that the caption loss significantly aids in generating better images, and the voken alignment loss further enhances coher- ence and image quality performance.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': '3 . 3', 'url': 'subsection.3.3', 'start_index': 59},\n",
       "    {'text': ',', 'url': 'table.caption.7', 'start_index': 652}],\n",
       "   'page_number': 9,\n",
       "   'parent_id': 'f0cb7c6948d35f108f4ecd57926a2b8d',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'e0d71af426e79cf4b3253b1b5c4c298c',\n",
       "  'text': 'Influence of Input Types for Image Generation To assess the impact of various types of input data for image generation, models are tasked with generating the final-step images based on specific prompts and comparing them with ground truth images by CLIP-I metric. All models are fine-tuned on data with full multimodal context and tested on various input types. As indicated in Table 6, the MiniGPT-5 model exhibits exceptional proficiency in producing semantically precise images compared to other models. Furthermore, we observed increased CLIP similarities when more in- formation was provided in the input, signifying the models’ enhanced ability to process diverse, long-horizon multimodal inputs.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': '- ondatawithfullmultimodalcontextandtestedonvariousinputtypes . AsindicatedinTable6',\n",
       "     'url': 'table.caption.8',\n",
       "     'start_index': 279}],\n",
       "   'page_number': 9,\n",
       "   'parent_id': 'f0cb7c6948d35f108f4ecd57926a2b8d',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'c832276247cfc971d7c8970559ef0dd7',\n",
       "  'text': 'Instead of multimodal input, we also test single text-to-image generation qualities on the CC3M validation set, as displayed in Table 7. The results indicate that although our model can have better generation on multi-turn multimodal scenarios, Stable Diffusion 2 achieves the best outcomes across',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': '.', 'url': 'table.caption.9', 'start_index': 135}],\n",
       "   'page_number': 9,\n",
       "   'parent_id': 'f0cb7c6948d35f108f4ecd57926a2b8d',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '8804f95a76096f2c5da86dd4be74cb86',\n",
       "  'text': 'Text-to-Image Generation Qualities on CC3M',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Footer',\n",
       "  'element_id': '19581e27de7ced00ff1ce50b2047e7a5',\n",
       "  'text': '9',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 9,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '1f24392117d47c9f7ac1eba65b8aab07',\n",
       "  'text': 'SD 2',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '1f5c3e14ece5c0d30023b55e0876f074',\n",
       "  'text': 'VSIT -- Image Generation',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '253489fe5558250ef026f513831b92b3',\n",
       "  'text': 'VSIT -- Multimodal Generation',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '2ddf9cf9d7d88fde96b0bb3bd01fb02f',\n",
       "  'text': 'A Maya example,couple comingsoon to 8th-century king andwife, lady fromTikal, dancing.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'parent_id': '253489fe5558250ef026f513831b92b3',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '38de5d67a933ee26518726ceac54ee86',\n",
       "  'text': 'I bought a bookabout the history ofthe museumGILL',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'parent_id': '253489fe5558250ef026f513831b92b3',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '3a04e3f9db9c794d687a5b3194aadc07',\n",
       "  'text': \"MiniGPT-5Two-StageIt's a great place tospend some time in.\",\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'parent_id': '253489fe5558250ef026f513831b92b3',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '3d4173e8fd9c0d5fe9c14e72950753a0',\n",
       "  'text': 'I went to thenatural historymuseum today.their evolution displaywas interesting.They had manyinteresting things ondisplay.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'parent_id': '253489fe5558250ef026f513831b92b3',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '3e6ceff311428e8167efd1484d99da11',\n",
       "  'text': 'first, we wentto the park.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'parent_id': '253489fe5558250ef026f513831b92b3',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '4ecf72da83b5862df91a8d33536dec57',\n",
       "  'text': 'MiniGPT-5GT',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '4ecf72da83b5862df91a8d33536dec57',\n",
       "  'text': 'MiniGPT-5GT',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '7942d4a2b357fd1fce179c4da4b686a3',\n",
       "  'text': 'MMDialog -- Multimodal Dialog Generation',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '7cf98897f87d2463a64df0e9c0f423a3',\n",
       "  'text': \"ID of perfectthough art:complementarity,complicity,simplicity, security.No, it's not a loan. It was foundin the tomb of an 8th centuryMaya king and his wife at Tika!Loan, privatecollection. Addingcolor to gallery!Lovely depiction oftextiles, gestures.\",\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'parent_id': '7942d4a2b357fd1fce179c4da4b686a3',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '7d0fe69f90650c61cc3587767ae1d8cd',\n",
       "  'text': 'They also have a giftshop.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'parent_id': '7942d4a2b357fd1fce179c4da4b686a3',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '89c56c9bfbaffbeec44972dfc9a702ea',\n",
       "  'text': 'GILL',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '9bdbe6c8c1f0b9ce9f23c7b7312e6789',\n",
       "  'text': 'GILLYes, from a loan.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'c7bc7ca4081e6e24c052ec89d69017d5',\n",
       "  'text': 'How gracefullcoming? From aloan?',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'cd749ebefd8c12ef24e30523edf603be',\n",
       "  'text': 'They had an area forcryptozoology.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'parent_id': 'c7bc7ca4081e6e24c052ec89d69017d5',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'f392c4990f5c3ed9bc9cf7af9a7a7317',\n",
       "  'text': 'My favorite was this realcovered wagon from200 years ago.GT',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'parent_id': 'c7bc7ca4081e6e24c052ec89d69017d5',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'f8ed053d2a08ff2217c752dcfba18302',\n",
       "  'text': 'Two-stage',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'fc0eca7bfb8b78d171b34d5caab63362',\n",
       "  'text': 'then, we wentswimmingi looked cooolin my glassesat the poollater, we wentto visit mommywe playeddress up.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'parent_id': 'f8ed053d2a08ff2217c752dcfba18302',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'fb4e59d77bb93fb0baa8eb788df9ab98',\n",
       "  'text': 'Figure 3: Qualitative examples from MiniGPT-5 and baselines on the VIST and MMDialog datasets. The orange blocks indicate the input prompts, while the green blocks include model outputs. The comparisons show that MiniGPT-5 can produce coherent and high-quality multimodal output. We would like to emphasize that MiniGPT-5 does not use any caption data during fine-tuning on VIST and MMDialog, which obeys to our description-free settings. More qualitative examples can be found in the Appendix D.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'parent_id': 'f8ed053d2a08ff2217c752dcfba18302',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'c6661b93bbeed48820a2edc9c2c08797',\n",
       "  'text': 'all metrics for pure text-to-image generation. Since our model attempts to align with the pretrained text encoder of Stable Diffusion 2 in this stage, there is a slight gap in performance due to the limitation of data amount. Compared with the observations on the VIST dataset, we can conclude that MiniGPT-5 is better at extracting features from long-horizontal multimodal information instead',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'parent_id': 'f8ed053d2a08ff2217c752dcfba18302',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Footer',\n",
       "  'element_id': '4a44dc15364204a80fe80e9039455cc1',\n",
       "  'text': '10',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 10,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '46fda47e9a5977079c8d45705003471d',\n",
       "  'text': 'Table 6: Influence of prompts for image generation on CLIP-I metrics on VIST. We establish four distinct conditions for the final-step image generation: ‘No Context’ (solely the last step’s narration), ‘Text Context’ (inclusive of historical textual narrations), ‘Image Context’ (inclusive of historical images), and ‘Image-Text Context’ (inclusive of both historical images and narrations). From the results, MiniGPT-5 can generate more coherent images.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "  'text': 'Model',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '8a4087584c75799357ec7db2e4a4e096',\n",
       "  'text': 'No Context Text Context',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'df0ef4835a6786eb8aa0144a786041f3',\n",
       "  'text': 'Image Context',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '60aaae492a7d458cd227f51e82932d66',\n",
       "  'text': 'Image-Text Context',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '3a6e05ee6e5027f1c02c483ce0ec60ac',\n",
       "  'text': 'SD 2.1 (Rombach et al., 2022b) Fine-tuned SD 2.1 Two-stage Baseline GILL (Koh et al., 2023) MiniGPT-5 (Prefix Tuning) MiniGPT-5 (LoRA)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Rombachetal .,',\n",
       "     'url': 'cite.rombach2021highresolution',\n",
       "     'start_index': 8},\n",
       "    {'text': '2022b',\n",
       "     'url': 'cite.rombach2021highresolution',\n",
       "     'start_index': 24},\n",
       "    {'text': 'Kohetal .,', 'url': 'cite.koh2023generating', 'start_index': 74},\n",
       "    {'text': '2023', 'url': 'cite.koh2023generating', 'start_index': 86}],\n",
       "   'page_number': 11,\n",
       "   'parent_id': '60aaae492a7d458cd227f51e82932d66',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '10b569245fef94493e6ad0f2900c0e76',\n",
       "  'text': '0.57 0.59 0.54 0.56 0.60 0.61',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': '60aaae492a7d458cd227f51e82932d66',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '30d8446542856520fcb70defa99eb461',\n",
       "  'text': '0.59 0.61 0.56 0.59 0.63 0.64',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': '60aaae492a7d458cd227f51e82932d66',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '270fbac44090c98e5fd1a493646b53cf',\n",
       "  'text': '- 0.57 0.60 0.68 0.69',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': '60aaae492a7d458cd227f51e82932d66',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '288ca688585a4a08f0e4260686a70f84',\n",
       "  'text': '- 0.58 0.60 0.70 0.70',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': '60aaae492a7d458cd227f51e82932d66',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '73c9ae7200f159a17e2f10ea1f9930c3',\n",
       "  'text': 'Table 7: Generation Qualities on CC3M and VIST. We find that MiniGPT-5 is better at extracting features from long-horizontal multimodal information than single text input.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': '60aaae492a7d458cd227f51e82932d66',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'e0ba593945c2591d506c3f93ea38b2bf',\n",
       "  'text': 'CC3M',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'a211f1c28c7b52099bd088d491e34b2c',\n",
       "  'text': 'VIST',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "  'text': 'Model',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'ff6f0ce218ddf400a85e5e6aca5f7789',\n",
       "  'text': 'CLIP-I (↑)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '19a7d8591de2c6a4a225c2da0815c997',\n",
       "  'text': 'FID (↓) CLIP-I (↑)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '0d6339d2b85b7d5ad6801154a96ace83',\n",
       "  'text': 'FID (↓)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '279f18ceb06bd30755b7e31e799c313c',\n",
       "  'text': 'Stable Diffusion 2.1 (Rombach et al., 2022b) GILL (Koh et al., 2023) MiniGPT-5',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Rombachetal .,',\n",
       "     'url': 'cite.rombach2021highresolution',\n",
       "     'start_index': 22},\n",
       "    {'text': '2022b',\n",
       "     'url': 'cite.rombach2021highresolution',\n",
       "     'start_index': 38},\n",
       "    {'text': 'Kohetal .,', 'url': 'cite.koh2023generating', 'start_index': 51},\n",
       "    {'text': '2023', 'url': 'cite.koh2023generating', 'start_index': 63}],\n",
       "   'page_number': 11,\n",
       "   'parent_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'd2c0605f6015d2c402876c44472507dd',\n",
       "  'text': '0.64 0.57 0.61',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '1b263ff7c1392e2fc4b07f8a5685d4c5',\n",
       "  'text': '26.39 36.85 31.47',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '5185ecfaaa61aa60530d303e4b78ffc6',\n",
       "  'text': '0.59 0.60 0.66',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '76018e1f0ff1bf81ee6b83f1d634872d',\n",
       "  'text': '393.49 381.88 366.62',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '05807595aae710a7ba60263e3fe8b302',\n",
       "  'text': 'of single text input. This indicates potential future directions on efficiently aligning LLMs with generative models. On the other hand, our model outperforms another state-of-the-art multimodal generation model, GILL, on all metrics, further validating the effectiveness of our design.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'ea96249b7d70bb30292a9876e3569748',\n",
       "  'text': '5 CONCLUSION',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '1c630214ea4defc172eb5c8f55001edc',\n",
       "  'text': 'In this paper, we introduce MiniGPT-5, designed to augment the capabilities of LLMs for multi- modal generation by aligning the LLM with a pretrained text-to-image generation model. Our ap- proach demonstrates substantial improvements, as evidenced by comprehensive experiments. There are still some limitations of MiniGPT-5. For example, we still find the object texture hard to main- tain in the new generation, and the generated image quality still has space to improve. Through this work, we aspire to set a new benchmark for multimodal generative models, opening doors to applications previously deemed challenging due to the disjointed nature of existing image and text synthesis paradigms.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': 'ea96249b7d70bb30292a9876e3569748',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '704d8a18e343aa05fdc15cdefa27e6ac',\n",
       "  'text': 'REFERENCES',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'c277aa97a9f5d71e03ab7f5a3769db22',\n",
       "  'text': 'Emanuele Aiello, Lili Yu, Yixin Nie, Armen Aghajanyan, and Barlas Oguz. Jointly training large',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': '704d8a18e343aa05fdc15cdefa27e6ac',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '78210efff9dff473cce1544fabca3091',\n",
       "  'text': 'autoregressive multimodal models. arXiv preprint arXiv:2309.15564, 2023.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': '704d8a18e343aa05fdc15cdefa27e6ac',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '84690906f797018e8209dfd604fc2176',\n",
       "  'text': 'Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds, et al. Flamingo: a visual language model for few-shot learning. Advances in Neural Information Processing Systems, 35:23716– 23736, 2022.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': '704d8a18e343aa05fdc15cdefa27e6ac',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'e08d2097acd914978f06dbfc434f80b2',\n",
       "  'text': 'Satanjeev Banerjee and Alon Lavie. Meteor: An automatic metric for mt evaluation with improved correlation with human judgments. In Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization, pp. 65–72, 2005.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': '704d8a18e343aa05fdc15cdefa27e6ac',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '843ecb5541c1821813f2d990d0ecb36d',\n",
       "  'text': 'Huiwen Chang, Han Zhang, Jarred Barber, AJ Maschinot, Jose Lezama, Lu Jiang, Ming-Hsuan Yang, Kevin Murphy, William T Freeman, Michael Rubinstein, et al. Muse: Text-to-image gen- eration via masked generative transformers. arXiv preprint arXiv:2301.00704, 2023.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'parent_id': '704d8a18e343aa05fdc15cdefa27e6ac',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Footer',\n",
       "  'element_id': '4fc82b26aecb47d2868c4efbe3581732',\n",
       "  'text': '11',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 11,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '5c4151736a99a37d1a5f1ffee0775443',\n",
       "  'text': 'Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality, March 2023.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'cecc6b97e59bf850fe1061c4bfd30169',\n",
       "  'text': 'Kevin Crowston. Amazon mechanical turk: A research tool for organizations and information sys- In Shaping the Future of ICT Research. Methods and Approaches: IFIP WG tems scholars. 8.2, Working Conference, Tampa, FL, USA, December 13-14, 2012. Proceedings, pp. 210–221. Springer, 2012.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'c0053291f9670e60fd478206a8777dca',\n",
       "  'text': 'Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Junqi Zhao, Weisheng Wang, Boyang Li, Pascale Fung, and Steven Hoi. Instructblip: Towards general-purpose vision-language models with instruction tuning, 2023.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'd419ea39e53019b4d7ff2cb140cc76d2',\n",
       "  'text': 'Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. Qlora: Efficient finetuning',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '05304b3145339bac9ffb5a3aa1a6f2f7',\n",
       "  'text': 'of quantized llms. arXiv preprint arXiv:2305.14314, 2023.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '9770fc92f1e291e3aabc8416286c1f0f',\n",
       "  'text': 'Prafulla Dhariwal and Alexander Nichol. Diffusion models beat gans on image synthesis. Advances',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '437ee4d0ab2fb28f5d289bb871c95ef5',\n",
       "  'text': 'in neural information processing systems, 34:8780–8794, 2021.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'fecfe9130958f6fc3ed9494c40a39f6c',\n",
       "  'text': 'Jiazhan Feng, Qingfeng Sun, Can Xu, Pu Zhao, Yaming Yang, Chongyang Tao, Dongyan Zhao, and Qingwei Lin. Mmdialog: A large-scale multi-turn dialogue dataset towards multi-modal open-domain conversation. arXiv preprint arXiv:2211.05719, 2022.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '9e5a34b67f04bc404143fa9d68f11208',\n",
       "  'text': 'Yuying Ge, Yixiao Ge, Ziyun Zeng, Xintao Wang, and Ying Shan. Planting a seed of vision in large',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'd71055b03d28fcdb86cd182918da97fe',\n",
       "  'text': 'language model. arXiv preprint arXiv:2307.08041, 2023.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '0a9aed00721192b42865b80e33e55e42',\n",
       "  'text': 'Jing Gu, Yilin Wang, Nanxuan Zhao, Tsu-Jui Fu, Wei Xiong, Qing Liu, Zhifei Zhang, He Zhang, Jianming Zhang, HyunJoon Jung, and Xin Eric Wang. Photoswap: Personalized subject swapping in images, 2023.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'parent_id': 'd71055b03d28fcdb86cd182918da97fe',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'acf85de82023256f64525c6a1d5bf521',\n",
       "  'text': 'Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilibrium. Advances in neural information processing systems, 30, 2017.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'parent_id': 'd71055b03d28fcdb86cd182918da97fe',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'c6d7a678875c4171834dfb47cbe2b3c5',\n",
       "  'text': 'Jonathan Ho and Tim Salimans.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '8837592dbbd8865379515edc02688a99',\n",
       "  'text': 'Classifier-free diffusion guidance.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'd8c1c5a4c7da832c74b0f77d5453d20c',\n",
       "  'text': 'arXiv preprint',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '5711522c1c3cbad7f05c180cc492aac5',\n",
       "  'text': 'arXiv:2207.12598, 2022.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'parent_id': 'd8c1c5a4c7da832c74b0f77d5453d20c',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'd11603050717c4ebcfe6d175d916c5ff',\n",
       "  'text': 'Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De Laroussilhe, An- drea Gesmundo, Mona Attariyan, and Sylvain Gelly. Parameter-efficient transfer learning for nlp. In International Conference on Machine Learning, pp. 2790–2799. PMLR, 2019.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'parent_id': 'd8c1c5a4c7da832c74b0f77d5453d20c',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'c88069dee3cf213e8bb3ee07de9f7ee4',\n",
       "  'text': 'Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, arXiv preprint',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'parent_id': 'd8c1c5a4c7da832c74b0f77d5453d20c',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'b80bc31812cc242154ab759e48f33b9e',\n",
       "  'text': 'and Weizhu Chen. Lora: Low-rank adaptation of large language models. arXiv:2106.09685, 2021.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'parent_id': 'd8c1c5a4c7da832c74b0f77d5453d20c',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'e808d4023b6016ba38078064d981df1f',\n",
       "  'text': 'Ting-Hao K. Huang, Francis Ferraro, Nasrin Mostafazadeh, Ishan Misra, Jacob Devlin, Aishwarya Agrawal, Ross Girshick, Xiaodong He, Pushmeet Kohli, Dhruv Batra, et al. Visual storytelling. In 15th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL 2016), 2016.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'parent_id': 'd8c1c5a4c7da832c74b0f77d5453d20c',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '3b6a19f2899b876a17be5b83b5b1fb13',\n",
       "  'text': 'Diederik P Kingma and Max Welling. Auto-encoding variational bayes.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'parent_id': 'd8c1c5a4c7da832c74b0f77d5453d20c',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'd8c1c5a4c7da832c74b0f77d5453d20c',\n",
       "  'text': 'arXiv preprint',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '43c8d8b9d3562917a273d90a23694521',\n",
       "  'text': 'arXiv:1312.6114, 2013.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'parent_id': 'd8c1c5a4c7da832c74b0f77d5453d20c',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'ae6bc396b3152d26b9c8466c3a35e003',\n",
       "  'text': 'Jing Yu Koh, Daniel Fried, and Ruslan Salakhutdinov. Generating images with multimodal language',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'parent_id': 'd8c1c5a4c7da832c74b0f77d5453d20c',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'a3f767bfc4c0317be4b61498b5e06282',\n",
       "  'text': 'models. arXiv preprint arXiv:2305.17216, 2023.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '05e0f004dc6ef3aa2519a8c44ce8418c',\n",
       "  'text': 'Bo Li, Yuanhan Zhang, Liangyu Chen, Jinghao Wang, Jingkang Yang, and Ziwei Liu. Otter: A multi-modal model with in-context instruction tuning. arXiv preprint arXiv:2305.03726, 2023a.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'parent_id': 'a3f767bfc4c0317be4b61498b5e06282',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '9b231d876e94a81e97a32226f03d465f',\n",
       "  'text': 'Dongxu Li, Junnan Li, Hung Le, Guangsen Wang, Silvio Savarese, and Steven C.H. Hoi. LAVIS: A one-stop library for language-vision intelligence. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations), pp. 31– 41, Toronto, Canada, July 2023b. Association for Computational Linguistics. URL https: //aclanthology.org/2023.acl-demo.3.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': '), pp . 31 41 , Toronto , Canada , July2023b . AssociationforComputationalLinguistics . URLhttps',\n",
       "     'url': 'https://aclanthology.org/2023.acl-demo.3',\n",
       "     'start_index': 267},\n",
       "    {'text': '// aclanthology . org / 2023 . acl - demo . 3',\n",
       "     'url': 'https://aclanthology.org/2023.acl-demo.3',\n",
       "     'start_index': 365}],\n",
       "   'page_number': 12,\n",
       "   'parent_id': 'a3f767bfc4c0317be4b61498b5e06282',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Footer',\n",
       "  'element_id': '6b51d431df5d7f141cbececcf79edf3d',\n",
       "  'text': '12',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 12,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'f3aeae637a20affa1824daef686c5921',\n",
       "  'text': 'Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi. Blip-2: Bootstrapping language- arXiv preprint',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'cdf182b8d21931a20bf9efd3650af568',\n",
       "  'text': 'image pre-training with frozen image encoders and large language models. arXiv:2301.12597, 2023c.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'f63fd3e30b750e4a5b6d1c1c2869d00f',\n",
       "  'text': 'Xiang Lisa Li and Percy Liang. Prefix-tuning: Optimizing continuous prompts for generation. arXiv',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'parent_id': 'cdf182b8d21931a20bf9efd3650af568',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '1712418d0c8aa28cbed565e9879b4225',\n",
       "  'text': 'preprint arXiv:2101.00190, 2021.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'parent_id': 'cdf182b8d21931a20bf9efd3650af568',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '24545c21db875eda84224c2e65303d69',\n",
       "  'text': 'Chin-Yew Lin. Rouge: A package for automatic evaluation of summaries. In Text summarization',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'parent_id': 'cdf182b8d21931a20bf9efd3650af568',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'cca1ea1d9fe8332b25e7ab478dcca369',\n",
       "  'text': 'branches out, pp. 74–81, 2004.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '5156fa171b52686bd1ae6078c8611880',\n",
       "  'text': 'Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, and Mark Chen. Glide: Towards photorealistic image generation and editing with text-guided diffusion models. arXiv preprint arXiv:2112.10741, 2021.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'parent_id': 'cca1ea1d9fe8332b25e7ab478dcca369',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'e729b9c2f95313ec04f7616b35b78371',\n",
       "  'text': 'OpenAI. Gpt-4 technical report, 2023.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '0217348c97ca2b0ef20000920556ba47',\n",
       "  'text': 'Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems, 35: 27730–27744, 2022.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'parent_id': 'e729b9c2f95313ec04f7616b35b78371',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'e26da38961abc4040c565a5f9897a180',\n",
       "  'text': 'Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting on association for computational linguistics, pp. 311–318. Association for Computational Linguistics, 2002.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'parent_id': 'e729b9c2f95313ec04f7616b35b78371',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '6c0738662deb5549b362886233a5db4b',\n",
       "  'text': 'Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever. Zero-shot text-to-image generation. In International Conference on Machine Learning, pp. 8821–8831. PMLR, 2021.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'parent_id': 'e729b9c2f95313ec04f7616b35b78371',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'cbea1fff8b8b0ab42bbde7075635390d',\n",
       "  'text': 'Scott Reed, Zeynep Akata, Xinchen Yan, Lajanugen Logeswaran, Bernt Schiele, and Honglak Lee. Generative adversarial text to image synthesis. In International conference on machine learning, pp. 1060–1069. PMLR, 2016.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'parent_id': 'e729b9c2f95313ec04f7616b35b78371',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'b681472ed3f84b7cd39ac1f33cd9140c',\n",
       "  'text': 'Nils Reimers and Iryna Gurevych. Sentence-bert: Sentence embeddings using siamese bert-',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'parent_id': 'e729b9c2f95313ec04f7616b35b78371',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '2b1e3066c13131bf353722899c75ed3d',\n",
       "  'text': 'networks. arXiv preprint arXiv:1908.10084, 2019.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'c1ffcb72b8a6893c1517538d8b4adacd',\n",
       "  'text': 'Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj¨orn Ommer. High- resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF confer- ence on computer vision and pattern recognition, pp. 10684–10695, 2022a.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'parent_id': '2b1e3066c13131bf353722899c75ed3d',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'adada18c39a4137f73cb5aa36264ca56',\n",
       "  'text': 'Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj¨orn Ommer. High-',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '366e26eeb6f5396e8d65cb75533ede0d',\n",
       "  'text': 'resolution image synthesis with latent diffusion models. In CVPR, 2022b.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'parent_id': 'adada18c39a4137f73cb5aa36264ca56',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '9bb007434f1d9d8581506139c79e32e6',\n",
       "  'text': 'Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily L Denton, Kamyar Ghasemipour, Raphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans, et al. Photorealistic text-to-image diffusion models with deep language understanding. Advances in Neural Informa- tion Processing Systems, 35:36479–36494, 2022.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'parent_id': 'adada18c39a4137f73cb5aa36264ca56',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '3653fc968f8238c80452231525447ab1',\n",
       "  'text': 'Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved techniques for training gans. Advances in neural information processing systems, 29, 2016.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'parent_id': 'adada18c39a4137f73cb5aa36264ca56',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'c2f1e958f9aafdb9c1a24925072055d1',\n",
       "  'text': 'Piyush Sharma, Nan Ding, Sebastian Goodman, and Radu Soricut. Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 2556–2565, 2018.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'parent_id': 'adada18c39a4137f73cb5aa36264ca56',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'ef13b6eee95f98a517ec58ebfca782e4',\n",
       "  'text': 'Qingfeng Sun, Yujing Wang, Can Xu, Kai Zheng, Yaming Yang, Huang Hu, Fei Xu, Jessica Zhang, Xiubo Geng, and Daxin Jiang. Multimodal dialogue response generation. arXiv preprint arXiv:2110.08515, 2021.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'parent_id': 'adada18c39a4137f73cb5aa36264ca56',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'b3c3a2cce6183cf7c3de5d9bdd707f6d',\n",
       "  'text': 'Quan Sun, Yuxin Fang, Ledell Wu, Xinlong Wang, and Yue Cao. Eva-clip: Improved training',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'parent_id': 'adada18c39a4137f73cb5aa36264ca56',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '099adc4ba1a37d2668ad03cd47ee6d5b',\n",
       "  'text': 'techniques for clip at scale. arXiv preprint arXiv:2303.15389, 2023a.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'parent_id': 'adada18c39a4137f73cb5aa36264ca56',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Footer',\n",
       "  'element_id': '3fdba35f04dc8c462986c992bcf87554',\n",
       "  'text': '13',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 13,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'de5dc25c299b3be8f6253acccc6738d1',\n",
       "  'text': 'Quan Sun, Qiying Yu, Yufeng Cui, Fan Zhang, Xiaosong Zhang, Yueze Wang, Hongcheng Gao, Jingjing Liu, Tiejun Huang, and Xinlong Wang. Generative pretraining in multimodality. 2023b.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'f8889177a86ffbc7300290259c5190fd',\n",
       "  'text': 'Hao Tan and Mohit Bansal. Vokenization: Improving language understanding with contextualized,',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'd31eaf4d7761647903bde404773db5ff',\n",
       "  'text': 'visual-grounded supervision. arXiv preprint arXiv:2010.06775, 2020.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'd4a6af662ae72818291ff04648e7a6d0',\n",
       "  'text': 'Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth´ee Lacroix, Baptiste Rozi`ere, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971, 2023.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'parent_id': 'd31eaf4d7761647903bde404773db5ff',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '84224568483b039e934200fe30489bc0',\n",
       "  'text': 'Maria Tsimpoukelli, Jacob L Menick, Serkan Cabi, SM Eslami, Oriol Vinyals, and Felix Hill. Mul- timodal few-shot learning with frozen language models. Advances in Neural Information Pro- cessing Systems, 34:200–212, 2021.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'parent_id': 'd31eaf4d7761647903bde404773db5ff',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '206d306ff335bd9360da2fe1736c39bf',\n",
       "  'text': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural informa- tion processing systems, 30, 2017a.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'parent_id': 'd31eaf4d7761647903bde404773db5ff',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '05c1b75d1030f27af961d5f25622159f',\n",
       "  'text': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural informa- tion processing systems, pp. 5998–6008, 2017b.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'parent_id': 'd31eaf4d7761647903bde404773db5ff',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '492d418a731b3df00ed3ae1ff4c97cc5',\n",
       "  'text': 'Chenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, and Nan Duan. Vi- arXiv preprint',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'parent_id': 'd31eaf4d7761647903bde404773db5ff',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'a34633378b3afe733f91b0b59243f720',\n",
       "  'text': 'sual chatgpt: Talking, drawing and editing with visual foundation models. arXiv:2303.04671, 2023a.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'parent_id': 'd31eaf4d7761647903bde404773db5ff',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '492d418a731b3df00ed3ae1ff4c97cc5',\n",
       "  'text': 'Chenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, and Nan Duan. Vi- arXiv preprint',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'parent_id': 'd31eaf4d7761647903bde404773db5ff',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'a06e5178358cbffddc783b6a6f191068',\n",
       "  'text': 'sual chatgpt: Talking, drawing and editing with visual foundation models. arXiv:2303.04671, 2023b.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'parent_id': 'd31eaf4d7761647903bde404773db5ff',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'a030e13f3c2c6c8915749a73bc939c54',\n",
       "  'text': 'Shengqiong Wu, Hao Fei, Leigang Qu, Wei Ji, and Tat-Seng Chua. Next-gpt: Any-to-any multi-',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'parent_id': 'd31eaf4d7761647903bde404773db5ff',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '2f908ba77b4de4483f76e63e048ac516',\n",
       "  'text': 'modal llm, 2023c.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'e8a6ff4b779d156d49223389391ab068',\n",
       "  'text': 'Jiahui Yu, Yuanzhong Xu, Jing Yu Koh, Thang Luong, Gunjan Baid, Zirui Wang, Vijay Vasudevan, Alexander Ku, Yinfei Yang, Burcu Karagol Ayan, et al. Scaling autoregressive models for content- rich text-to-image generation. arXiv preprint arXiv:2206.10789, 2(3):5, 2022.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'parent_id': '2f908ba77b4de4483f76e63e048ac516',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'd7edba67f49477aaeb1e8b5a214b0eb6',\n",
       "  'text': 'Lili Yu, Bowen Shi, Ramakanth Pasunuru, Benjamin Muller, Olga Golovneva, Tianlu Wang, Arun Babu, Binh Tang, Brian Karrer, Shelly Sheynin, et al. Scaling autoregressive multi-modal models: Pretraining and instruction tuning. arXiv preprint arXiv:2309.02591, 2023.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'parent_id': '2f908ba77b4de4483f76e63e048ac516',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'ef41ff8dd2bddf9c88869b1bb13840f7',\n",
       "  'text': 'Renrui Zhang, Rongyao Fang, Peng Gao, Wei Zhang, Kunchang Li, Jifeng Dai, Yu Qiao, and Hong- sheng Li. Tip-adapter: Training-free clip-adapter for better vision-language modeling. arXiv preprint arXiv:2111.03930, 2021.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'parent_id': '2f908ba77b4de4483f76e63e048ac516',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'a797ced1b68073cb7191ce0f9aab8c8c',\n",
       "  'text': 'Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny. Minigpt-4: En- hancing vision-language understanding with advanced large language models. arXiv preprint arXiv:2304.10592, 2023.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'parent_id': '2f908ba77b4de4483f76e63e048ac516',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Footer',\n",
       "  'element_id': '8527a891e224136950ff32ca212b45bc',\n",
       "  'text': '14',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 14,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '4f18f0e6cc72b450f8e7371deff559f4',\n",
       "  'text': 'A IMPLEMENTATION DETAILS',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '59dbcedae609fb6bdb9dfcf15c3304f3',\n",
       "  'text': 'In the pretraining stage, we introduce additional voken embeddings at both the input and out- put layers of the Vicuna-7B model, while keeping the embeddings of other tokens fixed. These new embeddings – denoted as θvoken input and θvoken output – along with the feature mapper module (θMLP, θenc dec, q) are jointly trained on the CC3M dataset, which consists of single text-image pairs. Training is conducted using the AdamW optimizer over two epochs, with a batch size of 48, amount- ing to over 110,000 steps, and a learning rate of 2 × 10−4.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'parent_id': '4f18f0e6cc72b450f8e7371deff559f4',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '3bdc15130d4d2bc428e9f807f2126f67',\n",
       "  'text': 'In the subsequent fine-tuning stage, we incorporate LoRA modules – denoted as θLoRA – into Vicuna for the generation of both tokens and vokens. We keep the MLP model θMLP and decoder query q fixed. The model is then fine-tuned on interleaved vision-and-language datasets, like VIST and MMDialog. The trainable parameters for this stage are θ = {θvoken input, θvoken output, θLoRA, θenc dec}. Training is carried out using the AdamW optimizer over four epochs, with a batch size of 32 and a learning rate of 2 × 10−5. Trainable parameters are nearly 6.6 million, and all training can be completed on a server equipped with 4 A6000 GPUs.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'parent_id': '4f18f0e6cc72b450f8e7371deff559f4',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '062e0c05395c182757a6f48fec0c8822',\n",
       "  'text': 'B EXPERIMENTAL SETTINGS',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '5a93b3819997804dfff3393e122783f8',\n",
       "  'text': 'B.1 DATASETS',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '04f226ce045a5958a1781384bf99865c',\n",
       "  'text': 'CC3M (Sharma et al., 2018): Conceptual Captions (CC3M) dataset represents a remarkable col- lection of high-quality image captions, amassing approximately 3.3 million pairs of text and images from the internet. The CC3M dataset’s diverse content, quality assurance, and support for multi- modal learning make it a valuable asset for researchers and AI enthusiasts. Each dataset sample consists of an image accompanied by a corresponding text description, reflecting the richness of human language and visual perception. However, after accounting for license restrictions and elim- inating invalid image links, the dataset comprises approximately 2.2 million data pairs suitable for training purposes and 10 thousand data pairs designated for validation.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Sharmaetal .,',\n",
       "     'url': 'cite.sharma2018conceptual',\n",
       "     'start_index': 6},\n",
       "    {'text': '2018', 'url': 'cite.sharma2018conceptual', 'start_index': 21}],\n",
       "   'page_number': 15,\n",
       "   'parent_id': '5a93b3819997804dfff3393e122783f8',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '2979e3ed29dacc7eea366d5752ab4e87',\n",
       "  'text': 'VIST (Huang et al., 2016): Visual Storytelling (VIST) dataset is an innovative compilation of visual narratives. The VIST dataset’s engaging content, narrative structure, and emphasis on se- quential understanding position it as an essential resource for researchers focusing on sequential image understanding. Each sequence within this dataset consists of five images accompanied by corresponding textual narratives, showcasing the intricate interplay between visual imagery and sto- rytelling. Designed to foster creativity and challenge conventional image-captioning models, the dataset provides a platform for training and validating algorithms capable of generating coherent and contextually relevant stories. After eliminating the invalid image links, we got over 65 thou- sand unique photos organized into more than 34 thousand storytelling sequences for training and 4 thousand sequences with 8 thousand images for validation.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Huangetal .,',\n",
       "     'url': 'cite.huang2016visual',\n",
       "     'start_index': 6},\n",
       "    {'text': '2016', 'url': 'cite.huang2016visual', 'start_index': 20}],\n",
       "   'page_number': 15,\n",
       "   'parent_id': '5a93b3819997804dfff3393e122783f8',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '17270241fb5be8258a3c2db7a96fc223',\n",
       "  'text': 'MMDialog (Feng et al., 2022): Multi-Modal Dialogue (MMDialog) dataset stands as the largest collection of multimodal conversation dialogues. The MMDialog dataset’s extensive scale, real human-human chat content, and emphasis on multimodal open-domain conversations position it as an unparalleled asset for researchers and practitioners in artificial intelligence. Each dialogue within this dataset typically includes 2.59 images, integrated anywhere within the conversation, showcasing the complex interplay between text and visual elements. Designed to mirror real-world conversational dynamics, the dataset is a robust platform for developing, training, and validating algorithms capable of understanding and generating coherent dialogues that seamlessly blend textual and visual information.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Fengetal .,',\n",
       "     'url': 'cite.feng2022mmdialog',\n",
       "     'start_index': 10},\n",
       "    {'text': '2022', 'url': 'cite.feng2022mmdialog', 'start_index': 23}],\n",
       "   'page_number': 15,\n",
       "   'parent_id': '5a93b3819997804dfff3393e122783f8',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'e7d9ca6c37a55242928c3f2db7a87a96',\n",
       "  'text': 'B.2 DATA FORMAT',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '4e81c56efd1bef8bf9c740b875e25795',\n",
       "  'text': 'Pretraining Stage In the pretraining stage, we aim to synchronize the generative voken with the text-to-image model’s conditional feature, focusing on single-turn text-image pairs. To achieve this, we utilize data from the CC3M dataset, constructing training samples by appending vokens as image placeholders after the captions, such as “a big black dog [IMG1] . . . [IMGn].” The Language Model (LLM) is then tasked with only generating these placeholders for text creation, and the correspond-',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'parent_id': 'e7d9ca6c37a55242928c3f2db7a87a96',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Footer',\n",
       "  'element_id': 'e629fa6598d732768f7c726b4b621285',\n",
       "  'text': '15',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 15,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '4c4f271789570df7924729a78fa97f1e',\n",
       "  'text': 'ing output hidden features are further employed to compute the conditional generation loss with the ground truth image.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'ade4266b1f2bf86bdab73d2c960f79a4',\n",
       "  'text': 'Fine-tuning Stage In this stage, we utilize the VIST and MMDialog datasets, which contain multi-turn multimodal data. During training, we integrate placeholders for input images, such as ’<Img><ImageHere></Img>’, into the input text prompts when applicable. These prompts also encompass various instructions corresponding to different task types, with outputs manifesting as pure-text, pure-voken, or text-voken combinations. Below, we present example templates in the VIST dataset to illustrate the different task types:',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '15684154df4acaf0570fbeffda4ee11d',\n",
       "  'text': 'Text Generation: Input: “<History Context> What happens in the next scene image: <Img><ImageHere></Img>”; Output: “<Text Description>”',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '36273b7cb4b1620e5e5d494f588a316b',\n",
       "  'text': 'Image Generation: Input: “<History Context> Generate an image with the scene de- scription: [Text Description]”; Output: “[IMG1]...[IMGn]”',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'ListItem',\n",
       "  'element_id': '4ccddae04d312ae7e712cd081ff70dde',\n",
       "  'text': 'Text-Image Generation: Input: “<History Context> What should happen then?”; Output: “<Text Description> [IMG1]...[IMGn]”',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'e2fcd0b5ff6a2d0dfcfc791edf60a374',\n",
       "  'text': 'By structuring the input and output in this manner, we create a flexible framework that accommo- dates various multimodal tasks, enhancing the model’s ability to interpret and generate textual and visual content. The history context in the VIST dataset includes all previous story steps with texts and images. In the MMDialog dataset, due to the limitation of computational resources, we only use up to one previous turn as the history context, and all data are formatted into the dialog.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '3f9f93f7a7569fef1f1581fadb1ce640',\n",
       "  'text': 'C MORE EXPERIMENTS',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '580e71b952089fac440e26429ad3b751',\n",
       "  'text': 'C.1 EVALUATION OF GUIDANCE SCALE',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'e97528e0c605d809998a913eb98328d2',\n",
       "  'text': 'Since our model incorporates CFG, evaluating how different guidance scales affect image generation is crucial. Therefore, we plotted several line charts in Fig 5 to depict the changes in metrics with varying guidance scales. The figures reveal that the stable diffusion model and our model generate better images as the guidance scale increases. However, when the scale exceeds 10, the image semantic coherence stabilizes while the image quality declines. This suggests that the guidance scale should be set within a reasonable range for optimal image generation.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'whenthescaleexceeds10',\n",
       "     'url': 'figure.caption.12',\n",
       "     'start_index': 354}],\n",
       "   'page_number': 16,\n",
       "   'parent_id': '580e71b952089fac440e26429ad3b751',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '0f45004b38c4bbe65bf6be1335371606',\n",
       "  'text': 'C.2 EVALUATION OF VOKEN NUMBER',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '034a6e08e4cf2b354e4b15aa76a4b77e',\n",
       "  'text': 'The voken features in our model are directly utilized as conditions in the text-to-image model, leading to the expectation that an increase in the number of vokens would enhance the model’s representative capabilities. To validate this hypothesis, we experimented by training the model with varying numbers of vokens, ranging from 1 to 8. As illustrated in Fig 6, the model’s performance consistently improves with adding more vokens. This improvement is particularly noticeable when the number of vokens is increased from 1 to 4, highlighting the significant role that vokens play in enhancing the model’s effectiveness.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': ',', 'url': 'figure.caption.14', 'start_index': 362}],\n",
       "   'page_number': 16,\n",
       "   'parent_id': '0f45004b38c4bbe65bf6be1335371606',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '48b0cd2cac353a47b882e6400109e585',\n",
       "  'text': 'C.3 ABLATION OF MODEL DESIGNS',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'e9d5a1432b7d695316386fcbe3003b96',\n",
       "  'text': 'This section explores alternatives to the transformer encoder/decoder architecture discussed in the main paper. Specifically, we experimented with two additional settings: Fixed Queries, and Decoder-Only model where learnable queries are fed into the transformer decoder. For the fixed queries design, we initialize queries the same as learnable queries experiments in the main paper and keep them fixed during training. In the decoder-only approach, we utilize solely the transformer decoder and apply padding to the decoder’s output, ensuring that the token length reaches 77. This length adjustment allows the output to be compatible with the Stable Diffusion encoder. The results of these experiments are detailed in Table 8. From the results of MiniGPT-5 with fixed queries, we find there exists a slight trade-off between image-text coherence and image qualities, where fixed queries can lead to higher image metrics (IS and FID) but lower CLIP similarities. Meanwhile, MiniGPT-5 consistently outperforms the Decoder-Only results in all four evaluation metrics, vali- dating the robustness and efficacy of MiniGPT-5’s transformer encoder/decoder architecture design.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': '.', 'url': 'table.caption.13', 'start_index': 725}],\n",
       "   'page_number': 16,\n",
       "   'parent_id': '48b0cd2cac353a47b882e6400109e585',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Footer',\n",
       "  'element_id': 'b17ef6d19c7a5b1ee83b907c595526dc',\n",
       "  'text': '16',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 16,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'd09a9b966c0556635fd92554d712dfd9',\n",
       "  'text': 'Figure 4: Screenshot for human evaluation interface on the Amazon Mechanical Turk crowdsource evaluation platform. Output 1 is generated by MiniGPT-5, while output 2 is generated by the two- stage baseline.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 17,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "  'text': 'Model',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 17,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'da310f3db024f5d0893f5bfee4a89d71',\n",
       "  'text': 'CLIP-I (↑) CLIP-T (↑)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 17,\n",
       "   'parent_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '1c014e95a75860c7f8724d8a2793f18c',\n",
       "  'text': 'IS (↑)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 17,\n",
       "   'parent_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '0d6339d2b85b7d5ad6801154a96ace83',\n",
       "  'text': 'FID (↓)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 17,\n",
       "   'parent_id': '5e2c614c23f02239bc03c6c04fcb6819',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '77603e74fdccc1ddb7aabf116fdd84cc',\n",
       "  'text': 'MiniGPT-5 MiniGPT-5 (Fixed Queries) MiniGPT-5 (Decoder-Only)',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 17,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '4b7bd146e800aa65da2a46040864bc2f',\n",
       "  'text': '0.61 0.60 0.58',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 17,\n",
       "   'parent_id': '77603e74fdccc1ddb7aabf116fdd84cc',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '006e5fefd06da5ae6c91d695422df6c6',\n",
       "  'text': '0.22 0.21 0.20',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 17,\n",
       "   'parent_id': '77603e74fdccc1ddb7aabf116fdd84cc',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '9cb58245ab0263d9862f0cd768246069',\n",
       "  'text': '28.09 28.55 24.74',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 17,\n",
       "   'parent_id': '77603e74fdccc1ddb7aabf116fdd84cc',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'b2a86141a2f0a82e764d369327fbc5cf',\n",
       "  'text': '31.47 30.56 34.88',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 17,\n",
       "   'parent_id': '77603e74fdccc1ddb7aabf116fdd84cc',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'bd813f4f06254b33e8d6d147a98e5cf0',\n",
       "  'text': 'Table 8: Evaluation of different model designs for image generation qualities on the CC3M valida- tion set.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 17,\n",
       "   'parent_id': '77603e74fdccc1ddb7aabf116fdd84cc',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '3998d6318d4a2c160c89db7f86edd08b',\n",
       "  'text': 'D MORE QUALITATIVE EXAMPLES',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 17,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'a970be082a3f3af3fe9d8bea6771b9dc',\n",
       "  'text': 'In this section, we provide additional qualitative examples to further demonstrate the capabilities of MiniGPT-5. Figures 7,8,9, and 10 showcase these examples across various datasets and settings.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': ',', 'url': 'figure.caption.15', 'start_index': 123},\n",
       "    {'text': '8', 'url': 'figure.caption.16', 'start_index': 124},\n",
       "    {'text': '9', 'url': 'figure.caption.17', 'start_index': 126},\n",
       "    {'text': 'and10showcasetheseexamplesacrossvariousdatasetsandsettings',\n",
       "     'url': 'figure.caption.18',\n",
       "     'start_index': 129}],\n",
       "   'page_number': 17,\n",
       "   'parent_id': '3998d6318d4a2c160c89db7f86edd08b',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '44c9be24d9d85843a02e3f2e939e9798',\n",
       "  'text': 'Figure 7 presents a comparative analysis on the VIST validation set, illustrating how MiniGPT-5 outperforms baseline models in terms of image generation quality and alignment with multimodal inputs. The examples highlight the superiority of MiniGPT-5 in generating images that closely match the given text prompts.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': '.', 'url': 'figure.caption.15', 'start_index': 197}],\n",
       "   'page_number': 17,\n",
       "   'parent_id': '3998d6318d4a2c160c89db7f86edd08b',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Footer',\n",
       "  'element_id': '4523540f1504cd17100c4835e85b7eef',\n",
       "  'text': '17',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 17,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '853a10e958cb62eb97934ca2c05485aa',\n",
       "  'text': '(a) FID vs CFG Scale',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '23910f8217782ea2c8defe3dcdfd93fa',\n",
       "  'text': '(b) IS vs CFG Scale',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '6b5badbd04252a861aa7c30ff50628d6',\n",
       "  'text': '(c) CLIP-T vs CFG Scale',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '713a2db4869cc2e5aeb731aa69504fb2',\n",
       "  'text': '(d) CLIP-I vs CFG Scale',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '0848d02fff63145c777bf9705faea1f9',\n",
       "  'text': 'Figure 5: Line charts for various metrics vs Classifier-free Guidance (CFG) scale on CC3M. The results suggest that our CFG strategy can exhibit comparable effectiveness to the CFG strategy employed in SD2, with the appropriate CFG scale significantly enhancing both image quality and coherence.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'parent_id': '713a2db4869cc2e5aeb731aa69504fb2',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '9f398a0024d8a355470508355dcbab9a',\n",
       "  'text': '(a) FID vs nvoken',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '3442e57e6abb8214cde9e98d1e6e6c97',\n",
       "  'text': '(b) IS vs nvoken',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'parent_id': '9f398a0024d8a355470508355dcbab9a',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'ff9072398e9948062f35cfd8145219f5',\n",
       "  'text': '(c) CLIP-T vs nvoken',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'e9b3a85650d02cc24e3240952f7e0a1b',\n",
       "  'text': '(d) CLIP-I vs nvoken',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '5fe5e15dc571343c9277343bbd3d9e04',\n",
       "  'text': 'Figure 6: Line charts for various metrics vs the number of vokens on CC3M. As the number of vokens increases, the image quality and CLIP scores improve. In this work, our default voken number is 8.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'parent_id': 'e9b3a85650d02cc24e3240952f7e0a1b',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '9646848ac4c2657dbad3f8b9885d3cc5',\n",
       "  'text': 'In Figure 8, we focus on the performance of MiniGPT-5 in free multimodal generation scenarios. The results clearly indicate an improvement over the Two-Stage baseline, emphasizing MiniGPT-5’s ability to perform consistent and creative multimodal generation.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': ',', 'url': 'figure.caption.16', 'start_index': 11}],\n",
       "   'page_number': 18,\n",
       "   'parent_id': 'e9b3a85650d02cc24e3240952f7e0a1b',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Footer',\n",
       "  'element_id': '4ec9599fc203d176a301536c2e091a19',\n",
       "  'text': '18',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 18,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '8609d00619cebe9cc4e02992de118291',\n",
       "  'text': 'Figure 9 showcases the application of MiniGPT-5 in the context of the MMDialog test set. Here, the emphasis is on free multimodal dialog generation, with MiniGPT-5 displaying a decent performance in generating coherent and contextually relevant multimodal dialogues.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Figure9showcasestheapplicationofMiniGPT',\n",
       "     'url': 'figure.caption.17',\n",
       "     'start_index': 0}],\n",
       "   'page_number': 19,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '0c3a4d2b2bdbadb425dbf17289531a67',\n",
       "  'text': 'Lastly, Figure 10 highlights MiniGPT-5’s performance in single text-to-image generation tasks on the CC3M validation set. The examples underline the model’s proficiency in generating visually accurate and contextually appropriate images from textual descriptions, surpassing the performance of baseline models.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'links': [{'text': 'Figure10highlightsMiniGPT - 5 ’ sperformanceinsingletext - to - theCC3Mvalidationset',\n",
       "     'url': 'figure.caption.18',\n",
       "     'start_index': 8}],\n",
       "   'page_number': 19,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'dc33b6468123b1e5db89270d60182d39',\n",
       "  'text': 'Each figure includes a clear depiction of input prompts (indicated in orange blocks) and the corre- sponding model outputs (in green blocks), providing a comprehensive view of MiniGPT-5’s capa- bilities across different multimodal generation tasks.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 19,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Footer',\n",
       "  'element_id': '9400f1b21cb527d7fa3d3eabba93557a',\n",
       "  'text': '19',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 19,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '4f2de210b0fdfdb3f62f72151ccbd3c5',\n",
       "  'text': 'i took my wife outfor our anniversarydinner.our first coursewas a light butdelicious salad.following oursalad we hadsquash bisquefor our main coursewe had a beautifullyplated salmon.to end ourwonderfulnight we had aparfait fordessert.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '5462f0b66ae570a295ff5477e7058d66',\n",
       "  'text': 'GILLSD 2Two-stageMiniGPT-5GT',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '5462f0b66ae570a295ff5477e7058d66',\n",
       "  'text': 'GILLSD 2Two-stageMiniGPT-5GT',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '5462f0b66ae570a295ff5477e7058d66',\n",
       "  'text': 'GILLSD 2Two-stageMiniGPT-5GT',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'a7a55ad59be0b2966793830a50f28b48',\n",
       "  'text': \"we didn't expectsuch beautyoutdoors.the bridge wasall i thought itwould be.the view of thewater wereamazing.the bridge wasbreath taking.we all agreedthe food wasfantastic.\",\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'parent_id': '5462f0b66ae570a295ff5477e7058d66',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'd19a15f87189e1d24584c7cad98a7437',\n",
       "  'text': \"i had a photosession with myfavorite doll.she is sophilosophicalsometimes.the cat likesher too, theywere having agood time.the cat really likesher, he even gaveher a kiss !she finishedthe sessionposing withher guitar,she's such agoodmusician.\",\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'parent_id': '5462f0b66ae570a295ff5477e7058d66',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '4f2bc83c319ab644f57658af0fec7ad4',\n",
       "  'text': 'Figure 7: Comparative examples from MiniGPT-5 and baselines on the VIST validation set for image generation with multimodal input. Orange blocks denote input prompts, while green blocks show model outputs.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'parent_id': '5462f0b66ae570a295ff5477e7058d66',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Footer',\n",
       "  'element_id': 'f5ca38f748a1d6eaf726b8a42fb575c3',\n",
       "  'text': '20',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 20,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '082e847dfb57207126932fff1b51a9d0',\n",
       "  'text': 'Jacob and his son.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '2cf1de29f4f6d9167423051b15b19cb8',\n",
       "  'text': 'Everyone was ingreate spirits',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '082e847dfb57207126932fff1b51a9d0',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '3b6e3e588cb964f7b55b17ceaf3ed548',\n",
       "  'text': 'MiniGPT-5Two-StageThis book was aboutanimals and it had lots ofpictures too.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '082e847dfb57207126932fff1b51a9d0',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '45dc296ae9ad9938735ba6cdf141665d',\n",
       "  'text': 'The happy coupleenjoying theirengagement.GTThis is the crew righthere.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '082e847dfb57207126932fff1b51a9d0',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '52dfc4ee5a6ee87e3a96a67b234a3d6d',\n",
       "  'text': 'The first book I readhad lots of coolpictures in it.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '082e847dfb57207126932fff1b51a9d0',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '542f7b830325d21f868f7c34b9404255',\n",
       "  'text': 'Celebrating with all ofour friendsHer best friend evencame.Even my dad got inon the act.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '082e847dfb57207126932fff1b51a9d0',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '5ea50ee9933655dea5bea024506a222f',\n",
       "  'text': 'I really enjoyedreading the book.GILL',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '082e847dfb57207126932fff1b51a9d0',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '7bd7984b8e53e57aecdb85800566c4f5',\n",
       "  'text': 'MiniGPT-5Two-StageEven the guy behind uswas great and fun to bearound.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '082e847dfb57207126932fff1b51a9d0',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '7eb04b11f584d3e85c0b90dfa8c87db4',\n",
       "  'text': 'The meeting was veryinformative and welearned a lot.GILL',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '082e847dfb57207126932fff1b51a9d0',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '96715370e3674efdd7d4fbc3148b347c',\n",
       "  'text': 'All of the kids were soexcited to read newbooks',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '082e847dfb57207126932fff1b51a9d0',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '9c1b3c05a4442ab7545d29429f3609aa',\n",
       "  'text': 'We had a greattime.GILL',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': '082e847dfb57207126932fff1b51a9d0',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'a58606c89caa5f9bd69c676835641cff',\n",
       "  'text': 'One of my friendsread us a story fromone of the books.GT',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'ba5663c7210e6d9a677d7dae17ab754f',\n",
       "  'text': 'Me and tanner takinga selfie together afterthe meeting.GTMe bondrit duringintermission.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': 'a58606c89caa5f9bd69c676835641cff',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'd7927b9704b2ff9ddc9d2fbe0ea11dea',\n",
       "  'text': \"We got to the town hallmeeting early and therewere a lot of people.Here's us watchingthe introduction.Everyone had a lot ofquestions and themeeting was very long\",\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': 'a58606c89caa5f9bd69c676835641cff',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'db253e1c3b2deea0059f427a4fd2b601',\n",
       "  'text': 'On our class trip we allwore our school uniformsI got to read manydifferent book that Ihad never read before.I really enjoyed beingon this trip',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': 'a58606c89caa5f9bd69c676835641cff',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'db3aef08717c6a92ffcbc9c3525004c0',\n",
       "  'text': 'MiniGPT-5Two-StageWe all gathered todiscuss the program',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': 'a58606c89caa5f9bd69c676835641cff',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': '80c2c112151be3197e2f62c4bd214410',\n",
       "  'text': 'Figure 8: More qualitative examples from MiniGPT-5 and baselines on VIST validation set for free multimodal generation.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'parent_id': 'a58606c89caa5f9bd69c676835641cff',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Footer',\n",
       "  'element_id': '6f4b6612125fb3a0daecd2799dfd6c9c',\n",
       "  'text': '21',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 21,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '0492afdea7c22dee896c4a11314b87f5',\n",
       "  'text': \"So cute!! I'm justabout to get into bedand finish off theGoblet of Fire for themillionth time!\",\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '205615eca7803162b454770aad7d9a50',\n",
       "  'text': 'Travelfaves2019 we have seenquite a number of gorgeousAfrica',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '2783597e6cc82fed8580917db125fe32',\n",
       "  'text': \"Haha I know what youmean! I'm just about tofinish the last Harry Potterbook! I'm so excited forthe next one!GILL\",\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '32c6ab477f221fed1da34ff4544a186a',\n",
       "  'text': \"What I find so funnyis everyone has astrong opinion of meand no one realisesI'm actually a soppy,over dramatic buggerthat :growing_heart:Harry PotterI've read all the books at least 10times each!Harry PotterHaha he has the full box setand home and at his Nanna's:) he even tries to head butthis lamp like dobby:face_with_tears_of_joy::see-no-evil_monkey:MiniGPT-5GT\",\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '776e34ede441181c32569fe04fc8ea11',\n",
       "  'text': 'You would get on withmy 3 year old then heis obsessed withHarry potter haha',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '7d713a1d5b0bded254d8d33281fc92c9',\n",
       "  'text': \"Our travelfaves2019what's yoursThe Greate Wall of ChinaGILL\",\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'aec69fb94ba9e2ef3f097eda62f58415',\n",
       "  'text': 'It the final FlashbackFridayz of 2019and we are looking back with a themeof TravelFaves2019. Tag and retweetyour hosts and guest hosts; Shareyous and tag you friends.Travelfaves2019 ours is thegorgeous waterfall in Costa RicaLuxurious views! Throwback toour trip to New Orleans lastJanuary where we stopped by theTabasco Factory in Avery IslandMiniGPT-5GT',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'd3a0c00ba63e17ae9857c906588079a6',\n",
       "  'text': 'Figure 9: More qualitative examples from MiniGPT-5 on MMDialog test set for free multimodal dialog generation.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Footer',\n",
       "  'element_id': '785f3ec7eb32f30b90cd0fcf3657d388',\n",
       "  'text': '22',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 22,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '191ef12e0e9cc5d987983cce9553d2ab',\n",
       "  'text': 'MiniGPT-5SD 2GILLGT',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '191ef12e0e9cc5d987983cce9553d2ab',\n",
       "  'text': 'MiniGPT-5SD 2GILLGT',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '191ef12e0e9cc5d987983cce9553d2ab',\n",
       "  'text': 'MiniGPT-5SD 2GILLGT',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '191ef12e0e9cc5d987983cce9553d2ab',\n",
       "  'text': 'MiniGPT-5SD 2GILLGT',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '2c382e96cff133ea91f1511fbe168ecd',\n",
       "  'text': 'womens handssprinkle a doughwith ﬂour close up',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '191ef12e0e9cc5d987983cce9553d2ab',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': '7759dfdb37d32a93b0b5257ea612f005',\n",
       "  'text': 'we all knowsuperman , comicbook characters ,but history is full ofless impressiveheroes',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': '191ef12e0e9cc5d987983cce9553d2ab',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': 'ae542a05033cf21803bb2f27faee8f01',\n",
       "  'text': 'MiniGPT-5 SD 2GILLGT',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'bef3c90b2a19e0f27282d50e4b09f128',\n",
       "  'text': 'happy youngbusinessman with afolder running up adrawn stairs along aconcrete wall',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': 'ae542a05033cf21803bb2f27faee8f01',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'd00437afd77caba2d33687bae934a7f3',\n",
       "  'text': 'sunﬂowers have adeep sentimentalmeaning for me',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': 'ae542a05033cf21803bb2f27faee8f01',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'NarrativeText',\n",
       "  'element_id': 'e9b8aeaf844bf5f64b398bd407759616',\n",
       "  'text': 'boy looking in theencyclopediathrough amagnifying glass',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': 'ae542a05033cf21803bb2f27faee8f01',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'UncategorizedText',\n",
       "  'element_id': 'cd20872a19e9ea726bf7651677ddb670',\n",
       "  'text': 'Figure 10: More qualitative examples from MiniGPT-5 and baselines on CC3M validation set for single text-to-image generation.',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'parent_id': 'ae542a05033cf21803bb2f27faee8f01',\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}},\n",
       " {'type': 'Footer',\n",
       "  'element_id': '535fa30d7e25dd8a49f1536779734ec8',\n",
       "  'text': '23',\n",
       "  'metadata': {'languages': ['eng'],\n",
       "   'page_number': 23,\n",
       "   'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "   'filetype': 'application/pdf'}}]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "417"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(resp.elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Title',\n",
       " 'element_id': 'd99ad376d3c673278a6c8b90e4facb15',\n",
       " 'text': 'MINIGPT-5: INTERLEAVED VISION-AND-LANGUAGE GENERATION VIA GENERATIVE VOKENS',\n",
       " 'metadata': {'languages': ['eng'],\n",
       "  'page_number': 1,\n",
       "  'filename': 'data\\\\MINIGPT_5.pdf',\n",
       "  'filetype': 'application/pdf'}}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.elements[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'UncategorizedText', 'ListItem', 'NarrativeText', 'Title', 'Footer'}\n"
     ]
    }
   ],
   "source": [
    "unique_types = set()\n",
    "\n",
    "for item in resp.elements:\n",
    "    unique_types.add(item['type'])\n",
    "\n",
    "print(unique_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the Unstructured API from the Unstructured open source library\n",
    "import os\n",
    "\n",
    "# Load base URL from .env file\n",
    "base_url = saas_server_url\n",
    "\n",
    "# Remaining part of the API URL\n",
    "remaining_url = \"/general/v0/general\"\n",
    "\n",
    "# Concatenate base URL with the remaining URL\n",
    "api_url = base_url + remaining_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.api import partition_via_api\n",
    "\n",
    "filename = \"data\\MINIGPT_5.pdf\"\n",
    "\n",
    "elements = partition_via_api(\n",
    "  filename=filename,\n",
    "  api_key=saas_api_key_auth,\n",
    "  api_url=api_url\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<unstructured.documents.elements.Title at 0x14d1567c250>,\n",
       " <unstructured.documents.elements.Title at 0x14d1567cca0>,\n",
       " <unstructured.documents.elements.Title at 0x14d1567cc10>,\n",
       " <unstructured.documents.elements.Text at 0x14d1567ce80>,\n",
       " <unstructured.documents.elements.Title at 0x14d1567c610>,\n",
       " <unstructured.documents.elements.Text at 0x14d156eac40>,\n",
       " <unstructured.documents.elements.Text at 0x14d156eaa30>,\n",
       " <unstructured.documents.elements.Title at 0x14d156ea700>,\n",
       " <unstructured.documents.elements.Text at 0x14d156ea7c0>,\n",
       " <unstructured.documents.elements.Title at 0x14d156ea580>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d156ea4c0>,\n",
       " <unstructured.documents.elements.Text at 0x14d156ea6d0>,\n",
       " <unstructured.documents.elements.Title at 0x14d156ea970>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d156eaf10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d156ea400>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d156ea820>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d156ea220>,\n",
       " <unstructured.documents.elements.Footer at 0x14d156eabe0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d156ea490>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d156ea370>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15700070>,\n",
       " <unstructured.documents.elements.ListItem at 0x14d15700f70>,\n",
       " <unstructured.documents.elements.ListItem at 0x14d15700190>,\n",
       " <unstructured.documents.elements.ListItem at 0x14d15700040>,\n",
       " <unstructured.documents.elements.Title at 0x14d15700ca0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d157007f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15700d00>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d157007c0>,\n",
       " <unstructured.documents.elements.Footer at 0x14d15700fa0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15700670>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d157002b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15700af0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15700b20>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15700d90>,\n",
       " <unstructured.documents.elements.Title at 0x14d15700520>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d157001c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15700910>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15700f40>,\n",
       " <unstructured.documents.elements.Title at 0x14d15700760>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15700a30>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d157005b0>,\n",
       " <unstructured.documents.elements.Title at 0x14d15700790>,\n",
       " <unstructured.documents.elements.Footer at 0x14d15700250>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15700fd0>,\n",
       " <unstructured.documents.elements.Title at 0x14d15700340>,\n",
       " <unstructured.documents.elements.Title at 0x14d15700160>,\n",
       " <unstructured.documents.elements.Title at 0x14d157003d0>,\n",
       " <unstructured.documents.elements.Title at 0x14d150522e0>,\n",
       " <unstructured.documents.elements.Title at 0x14d150523a0>,\n",
       " <unstructured.documents.elements.Title at 0x14d15052bb0>,\n",
       " <unstructured.documents.elements.Title at 0x14d150521c0>,\n",
       " <unstructured.documents.elements.Title at 0x14d15052a30>,\n",
       " <unstructured.documents.elements.Title at 0x14d150520a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15052970>,\n",
       " <unstructured.documents.elements.Title at 0x14d150529a0>,\n",
       " <unstructured.documents.elements.Title at 0x14d150522b0>,\n",
       " <unstructured.documents.elements.Title at 0x14d15052700>,\n",
       " <unstructured.documents.elements.Title at 0x14d150523d0>,\n",
       " <unstructured.documents.elements.Title at 0x14d15052a60>,\n",
       " <unstructured.documents.elements.Title at 0x14d15599c40>,\n",
       " <unstructured.documents.elements.Title at 0x14d15599c70>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d155997c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d155993d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15599f10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15599310>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15599130>,\n",
       " <unstructured.documents.elements.Footer at 0x14d15599df0>,\n",
       " <unstructured.documents.elements.Title at 0x14d15599d30>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15599250>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15599af0>,\n",
       " <unstructured.documents.elements.Title at 0x14d15599dc0>,\n",
       " <unstructured.documents.elements.Text at 0x14d15599ee0>,\n",
       " <unstructured.documents.elements.Title at 0x14d15599e20>,\n",
       " <unstructured.documents.elements.Text at 0x14d15599190>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15599430>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15599220>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15599be0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15599fd0>,\n",
       " <unstructured.documents.elements.Text at 0x14d158d2c10>,\n",
       " <unstructured.documents.elements.Text at 0x14d158d2d90>,\n",
       " <unstructured.documents.elements.Text at 0x14d158d2370>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158d27f0>,\n",
       " <unstructured.documents.elements.Text at 0x14d158d24c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158d2f40>,\n",
       " <unstructured.documents.elements.Title at 0x14d158d2310>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158d2a60>,\n",
       " <unstructured.documents.elements.Text at 0x14d158d20d0>,\n",
       " <unstructured.documents.elements.Text at 0x14d158d2700>,\n",
       " <unstructured.documents.elements.Text at 0x14d158d2460>,\n",
       " <unstructured.documents.elements.Footer at 0x14d158d22e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158d2af0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158d2d60>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d158d2130>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1570a790>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1570a910>,\n",
       " <unstructured.documents.elements.Text at 0x14d1570ad00>,\n",
       " <unstructured.documents.elements.Text at 0x14d1570a880>,\n",
       " <unstructured.documents.elements.Text at 0x14d1570a6d0>,\n",
       " <unstructured.documents.elements.Title at 0x14d1570a1c0>,\n",
       " <unstructured.documents.elements.Title at 0x14d1570a520>,\n",
       " <unstructured.documents.elements.Title at 0x14d1570a2e0>,\n",
       " <unstructured.documents.elements.Text at 0x14d1570a190>,\n",
       " <unstructured.documents.elements.Title at 0x14d1570a430>,\n",
       " <unstructured.documents.elements.Title at 0x14d1570a6a0>,\n",
       " <unstructured.documents.elements.Text at 0x14d1570afd0>,\n",
       " <unstructured.documents.elements.Title at 0x14d1570a340>,\n",
       " <unstructured.documents.elements.Title at 0x14d1570a670>,\n",
       " <unstructured.documents.elements.Text at 0x14d1570aac0>,\n",
       " <unstructured.documents.elements.Text at 0x14d1570a1f0>,\n",
       " <unstructured.documents.elements.Text at 0x14d1570a2b0>,\n",
       " <unstructured.documents.elements.Title at 0x14d1570ae50>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1570af10>,\n",
       " <unstructured.documents.elements.Title at 0x14d1570aa90>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d0886d670>,\n",
       " <unstructured.documents.elements.Footer at 0x14d0886d4f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d0886db80>,\n",
       " <unstructured.documents.elements.Title at 0x14d0886d700>,\n",
       " <unstructured.documents.elements.Text at 0x14d0886d1c0>,\n",
       " <unstructured.documents.elements.Text at 0x14d0886d850>,\n",
       " <unstructured.documents.elements.Text at 0x14d0886d8e0>,\n",
       " <unstructured.documents.elements.Text at 0x14d0886dbe0>,\n",
       " <unstructured.documents.elements.Text at 0x14d0886d250>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d155c1280>,\n",
       " <unstructured.documents.elements.Title at 0x14d155c1160>,\n",
       " <unstructured.documents.elements.Title at 0x14d155c1be0>,\n",
       " <unstructured.documents.elements.Title at 0x14d155c1940>,\n",
       " <unstructured.documents.elements.Text at 0x14d155c11c0>,\n",
       " <unstructured.documents.elements.Text at 0x14d155c1190>,\n",
       " <unstructured.documents.elements.Text at 0x14d155c1ca0>,\n",
       " <unstructured.documents.elements.Title at 0x14d155c13a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d155c15e0>,\n",
       " <unstructured.documents.elements.ListItem at 0x14d155c1460>,\n",
       " <unstructured.documents.elements.ListItem at 0x14d155c1c40>,\n",
       " <unstructured.documents.elements.ListItem at 0x14d155c1e80>,\n",
       " <unstructured.documents.elements.ListItem at 0x14d155c1e20>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1594ff40>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1594fbb0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1594fcd0>,\n",
       " <unstructured.documents.elements.Footer at 0x14d1594fc70>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d1594fe80>,\n",
       " <unstructured.documents.elements.Title at 0x14d1594fc40>,\n",
       " <unstructured.documents.elements.Title at 0x14d1594ffa0>,\n",
       " <unstructured.documents.elements.Title at 0x14d1594f520>,\n",
       " <unstructured.documents.elements.Title at 0x14d1594f1c0>,\n",
       " <unstructured.documents.elements.Title at 0x14d1594fb50>,\n",
       " <unstructured.documents.elements.Title at 0x14d1594f3a0>,\n",
       " <unstructured.documents.elements.Title at 0x14d1594f850>,\n",
       " <unstructured.documents.elements.Text at 0x14d1594f220>,\n",
       " <unstructured.documents.elements.Text at 0x14d1594f340>,\n",
       " <unstructured.documents.elements.Text at 0x14d1594f400>,\n",
       " <unstructured.documents.elements.Text at 0x14d153bb040>,\n",
       " <unstructured.documents.elements.Text at 0x14d15648f70>,\n",
       " <unstructured.documents.elements.Text at 0x14d156483d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d0d961790>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d0d961af0>,\n",
       " <unstructured.documents.elements.Title at 0x14d0d961910>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d0d961400>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d0d961e80>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d0d961520>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d0d961820>,\n",
       " <unstructured.documents.elements.Footer at 0x14d0d9614f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d0d9618b0>,\n",
       " <unstructured.documents.elements.Title at 0x14d0d961490>,\n",
       " <unstructured.documents.elements.Title at 0x14d0d961df0>,\n",
       " <unstructured.documents.elements.Title at 0x14d0d961880>,\n",
       " <unstructured.documents.elements.Text at 0x14d0d9611c0>,\n",
       " <unstructured.documents.elements.Text at 0x14d0d9610a0>,\n",
       " <unstructured.documents.elements.Text at 0x14d0d961280>,\n",
       " <unstructured.documents.elements.Text at 0x14d0d961580>,\n",
       " <unstructured.documents.elements.Text at 0x14d0d961b20>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d0d9614c0>,\n",
       " <unstructured.documents.elements.Title at 0x14d0d9611f0>,\n",
       " <unstructured.documents.elements.Text at 0x14d0d961ac0>,\n",
       " <unstructured.documents.elements.Text at 0x14d15936310>,\n",
       " <unstructured.documents.elements.Text at 0x14d15936460>,\n",
       " <unstructured.documents.elements.Title at 0x14d15936370>,\n",
       " <unstructured.documents.elements.Text at 0x14d15936610>,\n",
       " <unstructured.documents.elements.Text at 0x14d15936e50>,\n",
       " <unstructured.documents.elements.Text at 0x14d159364c0>,\n",
       " <unstructured.documents.elements.Text at 0x14d15936550>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d159360d0>,\n",
       " <unstructured.documents.elements.Title at 0x14d159366d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15936cd0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15936640>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d159365b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d159362b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d159368e0>,\n",
       " <unstructured.documents.elements.Title at 0x14d159367f0>,\n",
       " <unstructured.documents.elements.Footer at 0x14d15936160>,\n",
       " <unstructured.documents.elements.Title at 0x14d15936790>,\n",
       " <unstructured.documents.elements.Title at 0x14d15936970>,\n",
       " <unstructured.documents.elements.Title at 0x14d15936e80>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d159361c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15936d90>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15936d60>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15936730>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15936190>,\n",
       " <unstructured.documents.elements.Title at 0x14d07be8d00>,\n",
       " <unstructured.documents.elements.Title at 0x14d07be8280>,\n",
       " <unstructured.documents.elements.Title at 0x14d07be8850>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d07be88e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d07be89a0>,\n",
       " <unstructured.documents.elements.Title at 0x14d07be8ee0>,\n",
       " <unstructured.documents.elements.Title at 0x14d07be8550>,\n",
       " <unstructured.documents.elements.Title at 0x14d07be87f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d07be8580>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d07be8040>,\n",
       " <unstructured.documents.elements.Title at 0x14d07be8b20>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d07be8c70>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d07be8a60>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d07be82e0>,\n",
       " <unstructured.documents.elements.Footer at 0x14d07be86d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d07be8220>,\n",
       " <unstructured.documents.elements.Title at 0x14d07be8f40>,\n",
       " <unstructured.documents.elements.Title at 0x14d07be8a00>,\n",
       " <unstructured.documents.elements.Title at 0x14d07be85b0>,\n",
       " <unstructured.documents.elements.Title at 0x14d07be8a30>,\n",
       " <unstructured.documents.elements.Text at 0x14d07be8df0>,\n",
       " <unstructured.documents.elements.Text at 0x14d07be8250>,\n",
       " <unstructured.documents.elements.Text at 0x14d152e93d0>,\n",
       " <unstructured.documents.elements.ListItem at 0x14d152e9fa0>,\n",
       " <unstructured.documents.elements.ListItem at 0x14d152e9670>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d152e9640>,\n",
       " <unstructured.documents.elements.Title at 0x14d152e99d0>,\n",
       " <unstructured.documents.elements.Title at 0x14d152e9730>,\n",
       " <unstructured.documents.elements.Title at 0x14d08857280>,\n",
       " <unstructured.documents.elements.Text at 0x14d08857e20>,\n",
       " <unstructured.documents.elements.Text at 0x14d08857a60>,\n",
       " <unstructured.documents.elements.Text at 0x14d08857400>,\n",
       " <unstructured.documents.elements.Text at 0x14d08857220>,\n",
       " <unstructured.documents.elements.Text at 0x14d08857160>,\n",
       " <unstructured.documents.elements.Text at 0x14d088574f0>,\n",
       " <unstructured.documents.elements.Text at 0x14d08857eb0>,\n",
       " <unstructured.documents.elements.Text at 0x14d088570d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d08857ac0>,\n",
       " <unstructured.documents.elements.Title at 0x14d08857670>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d08857e50>,\n",
       " <unstructured.documents.elements.Title at 0x14d088579a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d088577f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d088578b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d08857190>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d08857ee0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d08857d60>,\n",
       " <unstructured.documents.elements.Footer at 0x14d08857a00>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d08857fd0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d08857310>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d08857130>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d08857460>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d08857f40>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d155e52e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d155e5f70>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d155e5f10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d155e51f0>,\n",
       " <unstructured.documents.elements.Title at 0x14d155e5a90>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d155e5bb0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d155e5eb0>,\n",
       " <unstructured.documents.elements.Title at 0x14d155e5e50>,\n",
       " <unstructured.documents.elements.Title at 0x14d155e5a00>,\n",
       " <unstructured.documents.elements.Title at 0x14d155e5e20>,\n",
       " <unstructured.documents.elements.Text at 0x14d155e5be0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d155e56d0>,\n",
       " <unstructured.documents.elements.Text at 0x14d155e5640>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d155e5d00>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d155e5820>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15206550>,\n",
       " <unstructured.documents.elements.Title at 0x14d15206760>,\n",
       " <unstructured.documents.elements.Text at 0x14d152069d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15206370>,\n",
       " <unstructured.documents.elements.Title at 0x14d15206d60>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15206df0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15206a60>,\n",
       " <unstructured.documents.elements.Footer at 0x14d15206ca0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15206a90>,\n",
       " <unstructured.documents.elements.Title at 0x14d15206e50>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15206160>,\n",
       " <unstructured.documents.elements.Text at 0x14d15206b80>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15206340>,\n",
       " <unstructured.documents.elements.Title at 0x14d152060d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d152061f0>,\n",
       " <unstructured.documents.elements.Title at 0x14d15206910>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15206100>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d152069a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15206310>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15206610>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15206250>,\n",
       " <unstructured.documents.elements.Title at 0x14d15206c40>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d089bdfa0>,\n",
       " <unstructured.documents.elements.Title at 0x14d15639a90>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d088bc610>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15686d00>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15686400>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15686ac0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d156863a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15686070>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15686b20>,\n",
       " <unstructured.documents.elements.Footer at 0x14d156865b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15686040>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15686e50>,\n",
       " <unstructured.documents.elements.Title at 0x14d15686ee0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15686d60>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15686b80>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15686910>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15686850>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15686340>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d156864f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15686610>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15686550>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15686160>,\n",
       " <unstructured.documents.elements.Title at 0x14d155a9d30>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d155a9bb0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d155a9790>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d155a90d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d155a90a0>,\n",
       " <unstructured.documents.elements.Footer at 0x14d155a9340>,\n",
       " <unstructured.documents.elements.Title at 0x14d155a9520>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d155a9a30>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d155a9af0>,\n",
       " <unstructured.documents.elements.Title at 0x14d155a92b0>,\n",
       " <unstructured.documents.elements.Title at 0x14d155a9970>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d155a9640>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d155a9220>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d155a92e0>,\n",
       " <unstructured.documents.elements.Title at 0x14d155a9730>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d155a9370>,\n",
       " <unstructured.documents.elements.Footer at 0x14d155a9160>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d155a9ac0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d155a9100>,\n",
       " <unstructured.documents.elements.ListItem at 0x14d155a91c0>,\n",
       " <unstructured.documents.elements.ListItem at 0x14d089400a0>,\n",
       " <unstructured.documents.elements.ListItem at 0x14d089401f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15631fd0>,\n",
       " <unstructured.documents.elements.Title at 0x14d15631ac0>,\n",
       " <unstructured.documents.elements.Title at 0x14d15631460>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15631250>,\n",
       " <unstructured.documents.elements.Title at 0x14d15631430>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15631f10>,\n",
       " <unstructured.documents.elements.Title at 0x14d15631bb0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15631d60>,\n",
       " <unstructured.documents.elements.Footer at 0x14d07c64eb0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d05db9340>,\n",
       " <unstructured.documents.elements.Title at 0x14d05db9970>,\n",
       " <unstructured.documents.elements.Text at 0x14d08872e80>,\n",
       " <unstructured.documents.elements.Text at 0x14d1525fb50>,\n",
       " <unstructured.documents.elements.Text at 0x14d1525f610>,\n",
       " <unstructured.documents.elements.Title at 0x14d1525f760>,\n",
       " <unstructured.documents.elements.Text at 0x14d1563c970>,\n",
       " <unstructured.documents.elements.Text at 0x14d1563c580>,\n",
       " <unstructured.documents.elements.Text at 0x14d1563ce50>,\n",
       " <unstructured.documents.elements.Text at 0x14d1563cf40>,\n",
       " <unstructured.documents.elements.Text at 0x14d1563cc10>,\n",
       " <unstructured.documents.elements.Title at 0x14d14d6fbb0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d14d6f190>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d14d6f130>,\n",
       " <unstructured.documents.elements.Footer at 0x14d14d6fa00>,\n",
       " <unstructured.documents.elements.Title at 0x14d14d6f610>,\n",
       " <unstructured.documents.elements.Title at 0x14d14d6f1f0>,\n",
       " <unstructured.documents.elements.Title at 0x14d15669cd0>,\n",
       " <unstructured.documents.elements.Title at 0x14d156693d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15669670>,\n",
       " <unstructured.documents.elements.Title at 0x14d15669e20>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d156690d0>,\n",
       " <unstructured.documents.elements.Title at 0x14d156691c0>,\n",
       " <unstructured.documents.elements.Title at 0x14d15669be0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15669a60>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d156697c0>,\n",
       " <unstructured.documents.elements.Footer at 0x14d15669580>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15669a00>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15669100>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15669160>,\n",
       " <unstructured.documents.elements.Footer at 0x14d15669970>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15669eb0>,\n",
       " <unstructured.documents.elements.Title at 0x14d156698b0>,\n",
       " <unstructured.documents.elements.Title at 0x14d15669190>,\n",
       " <unstructured.documents.elements.Title at 0x14d15669370>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15669fa0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15669910>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d156696d0>,\n",
       " <unstructured.documents.elements.Footer at 0x14d156693a0>,\n",
       " <unstructured.documents.elements.Title at 0x14d15669850>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15669a30>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15669b20>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15669070>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d15669c40>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d05eda1f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d05eda7f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d05edad30>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d05eda4c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d05eda490>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d05eda8b0>,\n",
       " <unstructured.documents.elements.Title at 0x14d05edac10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d05edaee0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d05eda340>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d05eda6a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d05eda2e0>,\n",
       " <unstructured.documents.elements.Text at 0x14d05eda670>,\n",
       " <unstructured.documents.elements.Footer at 0x14d05edac40>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d07c857c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d07c85910>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d07c85790>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d07c855b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d07c85580>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d07c852b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d07c85d00>,\n",
       " <unstructured.documents.elements.Text at 0x14d07c85190>,\n",
       " <unstructured.documents.elements.Footer at 0x14d07c85d30>,\n",
       " <unstructured.documents.elements.Title at 0x14d07c85070>,\n",
       " <unstructured.documents.elements.Title at 0x14d07c85130>,\n",
       " <unstructured.documents.elements.Title at 0x14d07c850d0>,\n",
       " <unstructured.documents.elements.Title at 0x14d07c857f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d07c85d90>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d07c85670>,\n",
       " <unstructured.documents.elements.Title at 0x14d07c852e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d07c85e20>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d07c85370>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x14d153865b0>,\n",
       " <unstructured.documents.elements.Text at 0x14d15386880>,\n",
       " <unstructured.documents.elements.Footer at 0x14d15386fa0>]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "417"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Reading document from string ...\n",
      "INFO: Reading document ...\n",
      "[\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"30087720a972284a598a826227c001b9\",\n",
      "    \"text\": \"\\ud83d\\udc68\\ud83c\\udffe\\u200d\\ud83d\\udcbb GitHub \\u2b50\\ufe0f| \\ud83d\\udc26 Twitter | \\ud83d\\udcf9 YouTube | \\ud83d\\udc54LinkedIn | \\u2615\\ufe0fKo-fi\",\n",
      "    \"metadata\": {\n",
      "      \"category_depth\": 0,\n",
      "      \"last_modified\": \"2024-05-06T10:45:09\",\n",
      "      \"link_texts\": [\n",
      "        \"GitHub\",\n",
      "        \"Twitter\",\n",
      "        \"YouTube\",\n",
      "        \"LinkedIn\",\n",
      "        \"Ko-fi\"\n",
      "      ],\n",
      "      \"link_urls\": [\n",
      "        \"https://github.com/sudarshan-koirala\",\n",
      "        \"https://twitter.com/mesudarshan\",\n",
      "        \"https://www.youtube.com/@datasciencebasics\",\n",
      "        \"https://www.linkedin.com/in/sudarshan-koirala/\",\n",
      "        \"http://ko-fi.com/datasciencebasics\"\n",
      "      ],\n",
      "      \"link_start_indexes\": [\n",
      "        5,\n",
      "        18,\n",
      "        30,\n",
      "        41,\n",
      "        54\n",
      "      ],\n",
      "      \"page_number\": 1,\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"robust_rag.html\",\n",
      "      \"filetype\": \"text/html\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"8632cb1c804cb70709769109f3a4ebb1\",\n",
      "    \"text\": \"Retrieval Augmented Regeneration (RAG) is everywhere and most of the companies claim they do AI but literally what they are doing is creating a RAG application, classic, right \\ud83d\\ude00\",\n",
      "    \"metadata\": {\n",
      "      \"last_modified\": \"2024-05-06T10:45:09\",\n",
      "      \"page_number\": 1,\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"parent_id\": \"30087720a972284a598a826227c001b9\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"robust_rag.html\",\n",
      "      \"filetype\": \"text/html\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"61274f17b84dca6484ae7ef888d4a0eb\",\n",
      "    \"text\": \"We want is to create a robust RAG but most of the time we might be just following the basic approaches to create RAG and get frustrated. In this blogpost, I will point out some of the approaches you could try so you get better RAG experience. Taking step by step approach is good instead of dumping all your knowledge and start thinking which step performs better.\",\n",
      "    \"metadata\": {\n",
      "      \"last_modified\": \"2024-05-06T10:45:09\",\n",
      "      \"page_number\": 1,\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"parent_id\": \"30087720a972284a598a826227c001b9\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"robust_rag.html\",\n",
      "      \"filetype\": \"text/html\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"b64d375d8254ded16f91bd8a4d035a08\",\n",
      "    \"text\": \"Here are some of things, I want you to try,\",\n",
      "    \"metadata\": {\n",
      "      \"last_modified\": \"2024-05-06T10:45:09\",\n",
      "      \"page_number\": 1,\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"parent_id\": \"30087720a972284a598a826227c001b9\",\n",
      "      \"file_directory\": \"data\",\n",
      "      \"filename\": \"robust_rag.html\",\n",
      "      \"filetype\": \"text/html\"\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from unstructured.partition.html import partition_html\n",
    "import json\n",
    "\n",
    "# Define the filename\n",
    "filename = \"data/robust_rag.html\"\n",
    "\n",
    "# Partition the HTML file into elements\n",
    "elements = partition_html(filename=filename)\n",
    "\n",
    "# Convert each element into a dictionary\n",
    "element_dict = [el.to_dict() for el in elements]\n",
    "\n",
    "# Extract the 12th to 15th elements and convert them to a JSON string\n",
    "example_output = json.dumps(element_dict[11:15], indent=2)\n",
    "\n",
    "# Print the JSON string\n",
    "print(example_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<unstructured.documents.html.HTMLTitle at 0x14d158ef280>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d158ef0d0>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d158efee0>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d15450280>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d0e65acd0>,\n",
       " <unstructured.documents.html.HTMLNarrativeText at 0x14d0e65ab50>,\n",
       " <unstructured.documents.html.HTMLText at 0x14d0e65a130>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d15638e20>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d15638580>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d15638bb0>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d15638970>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d15638910>,\n",
       " <unstructured.documents.html.HTMLNarrativeText at 0x14d14f7a5b0>,\n",
       " <unstructured.documents.html.HTMLNarrativeText at 0x14d154d4610>,\n",
       " <unstructured.documents.html.HTMLNarrativeText at 0x14d15638520>,\n",
       " <unstructured.documents.html.HTMLListItem at 0x14d15386310>,\n",
       " <unstructured.documents.html.HTMLListItem at 0x14d15386d90>,\n",
       " <unstructured.documents.html.HTMLListItem at 0x14d15386d00>,\n",
       " <unstructured.documents.html.HTMLListItem at 0x14d15386400>,\n",
       " <unstructured.documents.html.HTMLListItem at 0x14d153863d0>,\n",
       " <unstructured.documents.html.HTMLListItem at 0x14d15386c10>,\n",
       " <unstructured.documents.html.HTMLNarrativeText at 0x14d15386b80>,\n",
       " <unstructured.documents.html.HTMLNarrativeText at 0x14d15386a00>,\n",
       " <unstructured.documents.html.HTMLNarrativeText at 0x14d15386f10>,\n",
       " <unstructured.documents.html.HTMLNarrativeText at 0x14d15386af0>,\n",
       " <unstructured.documents.html.HTMLNarrativeText at 0x14d15386100>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d15386370>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d15386430>,\n",
       " <unstructured.documents.html.HTMLListItem at 0x14d15386160>,\n",
       " <unstructured.documents.html.HTMLListItem at 0x14d10fb34c0>,\n",
       " <unstructured.documents.html.HTMLListItem at 0x14d10fb38b0>,\n",
       " <unstructured.documents.html.HTMLListItem at 0x14d10fb38e0>,\n",
       " <unstructured.documents.html.HTMLNarrativeText at 0x14d10fb3760>,\n",
       " <unstructured.documents.html.HTMLNarrativeText at 0x14d10fb3190>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d10fb3160>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d10fb33a0>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d10fb3280>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d10fb36d0>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d10fb3580>,\n",
       " <unstructured.documents.html.HTMLText at 0x14d10fb3c40>,\n",
       " <unstructured.documents.html.HTMLText at 0x14d10fb3a00>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d10fb3850>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d10fb3070>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d10fb3c10>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d10fb3640>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d10fb3af0>,\n",
       " <unstructured.documents.html.HTMLText at 0x14d10fb3c70>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d10fb36a0>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d156dd400>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d156dd220>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d156dd430>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d156dd610>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d156dd6d0>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d156dd8e0>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d156dd940>,\n",
       " <unstructured.documents.html.HTMLNarrativeText at 0x14d156dd9a0>,\n",
       " <unstructured.documents.html.HTMLTitle at 0x14d156dd970>]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(elements)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
